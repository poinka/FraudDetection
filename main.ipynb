{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "... bla bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Classifiers\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Additional encoders\n",
    "import category_encoders as ce\n",
    "\n",
    "# Stats\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Dimensionality reduction\n",
    "from sklearn.decomposition import (\n",
    "    PCA,\n",
    "    KernelPCA, \n",
    "    FastICA,\n",
    "    TruncatedSVD\n",
    ")\n",
    "\n",
    "# PSO\n",
    "from pyswarm import pso\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Overview\n",
    "\n",
    "The IEEE-CIS Fraud Detection dataset, sourced from Kaggle, comprises 590,540 transactions, with approximately 3.5% flagged as fraudulent. It includes two main components: transaction data (e.g., amount, time, product code) and identity data (e.g., device type, email domain), linked via 'TransactionID'. The high dimensionality (over 400 features) and class imbalance make it an ideal testbed for comparing feature selection and dimensionality reduction strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First and foremost, merge two dbs into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_transaction \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/train_transaction.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m train_identity \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/train_identity.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Merge both dataframes on 'TransactionID'\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen codecs>:331\u001b[0m, in \u001b[0;36mgetstate\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_transaction = pd.read_csv(\"data/train_transaction.csv\")\n",
    "train_identity = pd.read_csv(\"data/train_identity.csv\")\n",
    "\n",
    "# Merge both dataframes on 'TransactionID'\n",
    "train = pd.merge(train_transaction, train_identity, on=\"TransactionID\", how=\"left\")\n",
    "\n",
    "print(f\"Rows in merged training set: {train.shape[0]}\")\n",
    "print(f\"Columns in merged training set: {train.shape[1]}\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Download testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_identity = pd.read_csv(\"data/test_identity.csv\")\n",
    "test_transaction = pd.read_csv(\"data/test_transaction.csv\")\n",
    "test = pd.merge(test_transaction, test_identity, on=\"TransactionID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns = test.columns.str.replace('-', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perform an initial exploratory data analysis (EDA) by checking missing value percentages and examining the target distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make pandas show full output\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing percentages per column:\n",
      "id_24            99.196159\n",
      "id_25            99.130965\n",
      "id_07            99.127070\n",
      "id_08            99.127070\n",
      "id_21            99.126393\n",
      "id_26            99.125715\n",
      "id_27            99.124699\n",
      "id_23            99.124699\n",
      "id_22            99.124699\n",
      "dist2            93.628374\n",
      "D7               93.409930\n",
      "id_18            92.360721\n",
      "D13              89.509263\n",
      "D14              89.469469\n",
      "D12              89.041047\n",
      "id_03            88.768923\n",
      "id_04            88.768923\n",
      "D6               87.606767\n",
      "id_33            87.589494\n",
      "id_10            87.312290\n",
      "id_09            87.312290\n",
      "D9               87.312290\n",
      "D8               87.312290\n",
      "id_30            86.865411\n",
      "id_32            86.861855\n",
      "id_34            86.824771\n",
      "id_14            86.445626\n",
      "V142             86.123717\n",
      "V158             86.123717\n",
      "V140             86.123717\n",
      "V162             86.123717\n",
      "V141             86.123717\n",
      "V161             86.123717\n",
      "V157             86.123717\n",
      "V146             86.123717\n",
      "V156             86.123717\n",
      "V155             86.123717\n",
      "V154             86.123717\n",
      "V153             86.123717\n",
      "V149             86.123717\n",
      "V147             86.123717\n",
      "V148             86.123717\n",
      "V163             86.123717\n",
      "V139             86.123717\n",
      "V138             86.123717\n",
      "V160             86.122701\n",
      "V151             86.122701\n",
      "V152             86.122701\n",
      "V145             86.122701\n",
      "V144             86.122701\n",
      "V143             86.122701\n",
      "V159             86.122701\n",
      "V164             86.122701\n",
      "V165             86.122701\n",
      "V166             86.122701\n",
      "V150             86.122701\n",
      "V337             86.054967\n",
      "V333             86.054967\n",
      "V336             86.054967\n",
      "V335             86.054967\n",
      "V334             86.054967\n",
      "V338             86.054967\n",
      "V339             86.054967\n",
      "V324             86.054967\n",
      "V332             86.054967\n",
      "V325             86.054967\n",
      "V330             86.054967\n",
      "V329             86.054967\n",
      "V328             86.054967\n",
      "V327             86.054967\n",
      "V326             86.054967\n",
      "V322             86.054967\n",
      "V323             86.054967\n",
      "V331             86.054967\n",
      "DeviceInfo       79.905510\n",
      "id_13            78.440072\n",
      "id_16            78.098012\n",
      "V278             77.913435\n",
      "V277             77.913435\n",
      "V252             77.913435\n",
      "V253             77.913435\n",
      "V254             77.913435\n",
      "V257             77.913435\n",
      "V258             77.913435\n",
      "V242             77.913435\n",
      "V261             77.913435\n",
      "V262             77.913435\n",
      "V263             77.913435\n",
      "V264             77.913435\n",
      "V249             77.913435\n",
      "V266             77.913435\n",
      "V267             77.913435\n",
      "V268             77.913435\n",
      "V269             77.913435\n",
      "V273             77.913435\n",
      "V274             77.913435\n",
      "V275             77.913435\n",
      "V276             77.913435\n",
      "V265             77.913435\n",
      "V260             77.913435\n",
      "V247             77.913435\n",
      "V246             77.913435\n",
      "V240             77.913435\n",
      "V237             77.913435\n",
      "V236             77.913435\n",
      "V235             77.913435\n",
      "V233             77.913435\n",
      "V232             77.913435\n",
      "V231             77.913435\n",
      "V230             77.913435\n",
      "V229             77.913435\n",
      "V228             77.913435\n",
      "V226             77.913435\n",
      "V225             77.913435\n",
      "V224             77.913435\n",
      "V223             77.913435\n",
      "V219             77.913435\n",
      "V218             77.913435\n",
      "V217             77.913435\n",
      "V243             77.913435\n",
      "V244             77.913435\n",
      "V248             77.913435\n",
      "V241             77.913435\n",
      "id_05            76.823755\n",
      "id_06            76.823755\n",
      "R_emaildomain    76.751617\n",
      "id_20            76.418024\n",
      "id_19            76.408372\n",
      "id_17            76.399736\n",
      "V212             76.355370\n",
      "V211             76.355370\n",
      "V214             76.355370\n",
      "V213             76.355370\n",
      "V196             76.355370\n",
      "V205             76.355370\n",
      "V183             76.355370\n",
      "V216             76.355370\n",
      "V206             76.355370\n",
      "V186             76.355370\n",
      "V187             76.355370\n",
      "V192             76.355370\n",
      "V207             76.355370\n",
      "V215             76.355370\n",
      "V181             76.355370\n",
      "V182             76.355370\n",
      "V191             76.355370\n",
      "V167             76.355370\n",
      "V168             76.355370\n",
      "V199             76.355370\n",
      "V193             76.355370\n",
      "V172             76.355370\n",
      "V173             76.355370\n",
      "V202             76.355370\n",
      "V203             76.355370\n",
      "V176             76.355370\n",
      "V177             76.355370\n",
      "V178             76.355370\n",
      "V179             76.355370\n",
      "V204             76.355370\n",
      "V190             76.355370\n",
      "V194             76.323534\n",
      "V200             76.323534\n",
      "V189             76.323534\n",
      "V188             76.323534\n",
      "V185             76.323534\n",
      "V184             76.323534\n",
      "V180             76.323534\n",
      "V175             76.323534\n",
      "V174             76.323534\n",
      "V171             76.323534\n",
      "V170             76.323534\n",
      "V169             76.323534\n",
      "V195             76.323534\n",
      "V201             76.323534\n",
      "V197             76.323534\n",
      "V198             76.323534\n",
      "V209             76.323534\n",
      "V208             76.323534\n",
      "V210             76.323534\n",
      "id_31            76.245132\n",
      "DeviceType       76.155722\n",
      "id_02            76.145223\n",
      "id_29            76.127273\n",
      "id_11            76.127273\n",
      "id_28            76.127273\n",
      "id_37            76.126088\n",
      "id_36            76.126088\n",
      "id_15            76.126088\n",
      "id_35            76.126088\n",
      "id_38            76.126088\n",
      "V245             76.053104\n",
      "V271             76.053104\n",
      "V234             76.053104\n",
      "V222             76.053104\n",
      "V238             76.053104\n",
      "V239             76.053104\n",
      "V227             76.053104\n",
      "V250             76.053104\n",
      "V272             76.053104\n",
      "V270             76.053104\n",
      "V251             76.053104\n",
      "V220             76.053104\n",
      "V255             76.053104\n",
      "V256             76.053104\n",
      "V259             76.053104\n",
      "V221             76.053104\n",
      "id_01            75.576083\n",
      "id_12            75.576083\n",
      "dist1            59.652352\n",
      "M5               59.349409\n",
      "M7               58.635317\n",
      "M9               58.633115\n",
      "M8               58.633115\n",
      "D5               52.467403\n",
      "M4               47.658753\n",
      "D2               47.549192\n",
      "V3               47.293494\n",
      "V9               47.293494\n",
      "V5               47.293494\n",
      "V11              47.293494\n",
      "V10              47.293494\n",
      "V8               47.293494\n",
      "V7               47.293494\n",
      "D11              47.293494\n",
      "V6               47.293494\n",
      "V4               47.293494\n",
      "V2               47.293494\n",
      "V1               47.293494\n",
      "M2               45.907136\n",
      "M3               45.907136\n",
      "M1               45.907136\n",
      "D3               44.514851\n",
      "M6               28.678836\n",
      "V35              28.612626\n",
      "V40              28.612626\n",
      "V41              28.612626\n",
      "V39              28.612626\n",
      "V38              28.612626\n",
      "V51              28.612626\n",
      "V37              28.612626\n",
      "V52              28.612626\n",
      "V36              28.612626\n",
      "V50              28.612626\n",
      "V48              28.612626\n",
      "V42              28.612626\n",
      "V43              28.612626\n",
      "V44              28.612626\n",
      "V46              28.612626\n",
      "V47              28.612626\n",
      "V45              28.612626\n",
      "V49              28.612626\n",
      "D4               28.604667\n",
      "P_emaildomain    15.994852\n",
      "V80              15.098723\n",
      "V87              15.098723\n",
      "V88              15.098723\n",
      "V89              15.098723\n",
      "V90              15.098723\n",
      "V91              15.098723\n",
      "V92              15.098723\n",
      "V93              15.098723\n",
      "V94              15.098723\n",
      "V86              15.098723\n",
      "V79              15.098723\n",
      "V85              15.098723\n",
      "V75              15.098723\n",
      "V84              15.098723\n",
      "V77              15.098723\n",
      "V83              15.098723\n",
      "V78              15.098723\n",
      "V82              15.098723\n",
      "V81              15.098723\n",
      "V76              15.098723\n",
      "D15              15.090087\n",
      "V72              13.055170\n",
      "V74              13.055170\n",
      "V73              13.055170\n",
      "V71              13.055170\n",
      "V65              13.055170\n",
      "V68              13.055170\n",
      "V58              13.055170\n",
      "V70              13.055170\n",
      "V53              13.055170\n",
      "V54              13.055170\n",
      "V55              13.055170\n",
      "V56              13.055170\n",
      "V57              13.055170\n",
      "V59              13.055170\n",
      "V67              13.055170\n",
      "V60              13.055170\n",
      "V61              13.055170\n",
      "V62              13.055170\n",
      "V63              13.055170\n",
      "V64              13.055170\n",
      "V66              13.055170\n",
      "V69              13.055170\n",
      "V21              12.881939\n",
      "V22              12.881939\n",
      "V23              12.881939\n",
      "V34              12.881939\n",
      "V33              12.881939\n",
      "V32              12.881939\n",
      "V31              12.881939\n",
      "V30              12.881939\n",
      "V29              12.881939\n",
      "V28              12.881939\n",
      "V27              12.881939\n",
      "V25              12.881939\n",
      "V24              12.881939\n",
      "V26              12.881939\n",
      "V16              12.881939\n",
      "V15              12.881939\n",
      "V20              12.881939\n",
      "V14              12.881939\n",
      "V19              12.881939\n",
      "V18              12.881939\n",
      "V17              12.881939\n",
      "V12              12.881939\n",
      "V13              12.881939\n",
      "D10              12.873302\n",
      "addr1            11.126427\n",
      "addr2            11.126427\n",
      "card2             1.512683\n",
      "card5             0.721204\n",
      "card4             0.267044\n",
      "card6             0.266028\n",
      "card3             0.265012\n",
      "V296              0.214888\n",
      "V289              0.214888\n",
      "V288              0.214888\n",
      "V283              0.214888\n",
      "V282              0.214888\n",
      "V281              0.214888\n",
      "V300              0.214888\n",
      "V301              0.214888\n",
      "V313              0.214888\n",
      "V314              0.214888\n",
      "V315              0.214888\n",
      "D1                0.214888\n",
      "V104              0.053172\n",
      "V109              0.053172\n",
      "V110              0.053172\n",
      "V111              0.053172\n",
      "V112              0.053172\n",
      "V106              0.053172\n",
      "V105              0.053172\n",
      "V102              0.053172\n",
      "V103              0.053172\n",
      "V96               0.053172\n",
      "V101              0.053172\n",
      "V100              0.053172\n",
      "V99               0.053172\n",
      "V98               0.053172\n",
      "V97               0.053172\n",
      "V95               0.053172\n",
      "V135              0.053172\n",
      "V134              0.053172\n",
      "V107              0.053172\n",
      "V133              0.053172\n",
      "V132              0.053172\n",
      "V131              0.053172\n",
      "V130              0.053172\n",
      "V129              0.053172\n",
      "V128              0.053172\n",
      "V127              0.053172\n",
      "V126              0.053172\n",
      "V125              0.053172\n",
      "V124              0.053172\n",
      "V123              0.053172\n",
      "V122              0.053172\n",
      "V121              0.053172\n",
      "V120              0.053172\n",
      "V119              0.053172\n",
      "V118              0.053172\n",
      "V117              0.053172\n",
      "V116              0.053172\n",
      "V115              0.053172\n",
      "V114              0.053172\n",
      "V113              0.053172\n",
      "V136              0.053172\n",
      "V137              0.053172\n",
      "V108              0.053172\n",
      "V311              0.002032\n",
      "V321              0.002032\n",
      "V294              0.002032\n",
      "V306              0.002032\n",
      "V305              0.002032\n",
      "V304              0.002032\n",
      "V303              0.002032\n",
      "V302              0.002032\n",
      "V299              0.002032\n",
      "V298              0.002032\n",
      "V297              0.002032\n",
      "V295              0.002032\n",
      "V293              0.002032\n",
      "V308              0.002032\n",
      "V292              0.002032\n",
      "V291              0.002032\n",
      "V290              0.002032\n",
      "V287              0.002032\n",
      "V286              0.002032\n",
      "V285              0.002032\n",
      "V284              0.002032\n",
      "V280              0.002032\n",
      "V279              0.002032\n",
      "V320              0.002032\n",
      "V307              0.002032\n",
      "V309              0.002032\n",
      "V312              0.002032\n",
      "V316              0.002032\n",
      "V317              0.002032\n",
      "V318              0.002032\n",
      "V319              0.002032\n",
      "V310              0.002032\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Missing value percentages per column\n",
    "missing_percent = (train.isnull().sum() / len(train)) * 100\n",
    "missing_percent = missing_percent.sort_values(ascending=False)\n",
    "print(\"Missing percentages per column:\")\n",
    "print(missing_percent[missing_percent > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAHCCAYAAADGjTzUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFwElEQVR4nO3deVxVdf7H8Tcgm+AFEQRNEhVTccFERUzNhaTCitQZdUzRtCZTU8lSW1yoGRsrl3KdaRLHyVJbrDQxA5epmEyMXCadbNzKAM0AV0A4vz96cH5cQVk8isjr+Xjcx8N7zud+z4dzz728PRsOhmEYAgAAwFVxrOoGAAAAbgaEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoSqm8jMmTPl4OBwXZbVs2dP9ezZ03y+detWOTg46N13370uyx8xYoSCgoKuy7Iq68yZMxo9erQCAgLk4OCgiRMnVnVLV6XoPd66dWuFX3v48GE5ODgoISHB8r5w87qa77SEhAQ5ODjo8OHD1jYFy13P313XGqHqBlX0hVD0cHNzU8OGDRUVFaXXXntNp0+ftmQ5x48f18yZM5WWlmbJeFa6kXsrjz//+c9KSEjQmDFjtHLlSg0bNuyytUFBQXbvd/HHhQsXrmPX1dvixYtvmOBWFCQdHBz03nvvlZhf9Ivk5MmTVdrbpY8uXbpc936qq3PnzmnmzJnl+o/GlT7jxR83yvZrtYqsq+qsVlU3gCuLj49XkyZNlJ+fr/T0dG3dulUTJ07U3Llz9dFHH6ldu3Zm7XPPPaepU6dWaPzjx49r1qxZCgoKUvv27cv9uk8//bRCy6mMK/X2t7/9TYWFhde8h6uRnJysLl26aMaMGeWqb9++vZ588skS011cXKxu7aa1ePFi+fr6asSIEVXdip34+Hj179//hvvf+JAhQ3TvvffaTfPz86uibqqfc+fOadasWZJkt+e+NPPnz9eZM2fM55988onefvttzZs3T76+vub0rl27XpNeq9qV1lVlfnfdqAhVN7h77rlHHTt2NJ9PmzZNycnJ6tevn+6//3599913cnd3lyTVqlVLtWpd27f03Llzql27dpX/ond2dq7S5ZdHZmamQkJCyl1/yy236KGHHip3fdF7gRtb+/btlZaWpg8++ED9+/ev6nbsdOjQodzbXGFhofLy8uTm5naNu7o5xcTE2D1PT0/X22+/rZiYmCueynD27Fl5eHhc2+aq2PX43XW9cPivGurdu7eef/55HTlyRP/85z/N6aUdl968ebO6desmb29veXp6qkWLFnrmmWck/XaOTKdOnSRJI0eOLLH7uWfPnmrTpo1SU1PVo0cP1a5d23ztpedUFSkoKNAzzzyjgIAAeXh46P7779exY8fsaoKCgkrdk1B8zLJ6K+2cqrNnz+rJJ59UYGCgXF1d1aJFC73yyisyDMOuzsHBQePGjdO6devUpk0bubq6qnXr1kpMTCx9hV8iMzNTo0aNkr+/v9zc3BQaGqoVK1aY84vOPTp06JA2bNhg9n4153Zc6b348MMPFR0drYYNG8rV1VXNmjXTCy+8oIKCArsxyrPei/z444+KiYmRh4eH6tevr0mTJik3N7fEaysyZmn279+vgQMHysfHR25uburYsaM++ugju5qiQ+FffPGF4uLi5OfnJw8PDz344IM6ceKEXS/79u3Ttm3bzHV+uR7y8/Pl4+OjkSNHlpiXk5MjNzc3TZ482Zz2+uuvq3Xr1qpdu7bq1q2rjh07atWqVWX+fJI0ePBg3XbbbYqPjy+xLZZm7dq1CgsLk7u7u3x9ffXQQw/pp59+sqsZMWKEPD099dNPPykmJkaenp7y8/PT5MmTS7zvlVX0OXnrrbfUunVrubq6mp+RV155RV27dlW9evXk7u6usLCwEudTXuk8OgcHB82cOdNu2ueff65OnTrJzc1NzZo107Jly0q8rqJjlmbjxo3q3r27PDw8VKdOHUVHR2vfvn12NeVZv4cPHzb36s2aNcvc5srTw+UULfeHH37Qvffeqzp16mjo0KGSpH/961/63e9+p1tvvVWurq4KDAzUpEmTdP78+Qr3XuSdd95RWFiY6tSpI5vNprZt22rBggXm/FOnTmny5Mlq27atPD09ZbPZdM899+jbb78t0fuFCxc0c+ZM3XbbbXJzc1ODBg3Uv39//fDDD2Wuq9J+d128eFEvvPCCmjVrJldXVwUFBemZZ54p8T0UFBSkfv366fPPP1fnzp3l5uampk2b6h//+IddXX5+vmbNmqXmzZvLzc1N9erVU7du3bR58+YKvENluzmiYQ00bNgwPfPMM/r000/1yCOPlFqzb98+9evXT+3atVN8fLxcXV118OBBffHFF5KkVq1aKT4+XtOnT9ejjz6q7t27S7Lf/fzLL7/onnvu0eDBg/XQQw/J39//in396U9/koODg6ZMmaLMzEzNnz9fkZGRSktLM/eolUd5eivOMAzdf//92rJli0aNGqX27dtr06ZNeuqpp/TTTz9p3rx5dvWff/653n//fT3++OOqU6eOXnvtNQ0YMEBHjx5VvXr1LtvX+fPn1bNnTx08eFDjxo1TkyZNtHbtWo0YMUJZWVmaMGGCWrVqpZUrV2rSpElq1KiReUivrMMq+fn5Jc6vqV27trk36nLvRUJCgjw9PRUXFydPT08lJydr+vTpysnJ0csvv3zFZV7uZ+zTp4+OHj2qJ554Qg0bNtTKlSuVnJxc4bGuZN++fbrjjjt0yy23aOrUqfLw8NCaNWsUExOj9957Tw8++KBd/fjx41W3bl3NmDFDhw8f1vz58zVu3DitXr1a0m+HV8aPHy9PT089++yzknTZ7dXZ2VkPPvig3n//fS1btsxuz+u6deuUm5urwYMHS/rtUPMTTzyhgQMHasKECbpw4YJ2796tr776Sn/4wx/K/DmdnJz03HPPafjw4WXurUpISNDIkSPVqVMnzZ49WxkZGVqwYIG++OILffPNN/L29jZrCwoKFBUVpfDwcL3yyiv67LPP9Oqrr6pZs2YaM2ZMmX1Jv+3tvHSb8/LyMvcEJycna82aNRo3bpx8fX3N/8gsWLBA999/v4YOHaq8vDy98847+t3vfqf169crOjq6XMsubs+ePerbt6/8/Pw0c+ZMXbx4UTNmzCjz+6aiVq5cqdjYWEVFRekvf/mLzp07pyVLlqhbt2765ptv7P6jVtb69fPz05IlSzRmzBg9+OCD5vta/JSMyrh48aKioqLUrVs3vfLKK+bnf+3atTp37pzGjBmjevXqaceOHXr99df1448/au3atXZjlGfb2Lx5s4YMGaI+ffroL3/5iyTpu+++0xdffKEJEyZIkv73v/9p3bp1+t3vfqcmTZooIyNDy5Yt05133qn//Oc/atiwobm8fv36KSkpSYMHD9aECRN0+vRpbd68WXv37lVkZGSF19Xo0aO1YsUKDRw4UE8++aS++uorzZ49W999950++OADu9qDBw9q4MCBGjVqlGJjY/Xmm29qxIgRCgsLU+vWrSX9Ftxmz56t0aNHq3PnzsrJydHOnTu1a9cu3XXXXVf1ntkxcENavny5Icn4+uuvL1vj5eVl3H777ebzGTNmGMXf0nnz5hmSjBMnTlx2jK+//tqQZCxfvrzEvDvvvNOQZCxdurTUeXfeeaf5fMuWLYYk45ZbbjFycnLM6WvWrDEkGQsWLDCnNW7c2IiNjS1zzCv1FhsbazRu3Nh8vm7dOkOS8eKLL9rVDRw40HBwcDAOHjxoTpNkuLi42E379ttvDUnG66+/XmJZxc2fP9+QZPzzn/80p+Xl5RkRERGGp6en3c/euHFjIzo6+orjFa+VVOIxY8YMwzCu/F6cO3euxLQ//vGPRu3atY0LFy7YLaM8673oZ1yzZo057ezZs0ZwcLAhydiyZUuFxzx06FCJ97JPnz5G27Zt7XosLCw0unbtajRv3tycVvRZiIyMNAoLC83pkyZNMpycnIysrCxzWuvWre2WeyWbNm0yJBkff/yx3fR7773XaNq0qfn8gQceMFq3bl2uMYsr+plffvll4+LFi0bz5s2N0NBQ82co+rwWfT7z8vKM+vXrG23atDHOnz9vjrN+/XpDkjF9+nRzWmxsrCHJiI+Pt1vm7bffboSFhZW7t9IeRe+vJMPR0dHYt29fiddfus3l5eUZbdq0MXr37l1iGaV9fotv24ZhGDExMYabm5tx5MgRc9p//vMfw8nJye47rSJjFm03hw4dMgzDME6fPm14e3sbjzzyiN3r0tPTDS8vL7vp5V2/J06cKLHc8nr55Zft+iu+3KlTp5aoL+1zPnv2bMPBwcFuvZW39wkTJhg2m824ePHiZXu8cOGCUVBQYDft0KFDhqurq934b775piHJmDt3bokxirb3K62rS393paWlGZKM0aNH29VNnjzZkGQkJyeb04q+O7dv325Oy8zMNFxdXY0nn3zSnBYaGlru7+OrweG/aszT0/OKVwEW/a/2ww8/rPRJ3a6urqUeIrmc4cOHq06dOubzgQMHqkGDBvrkk08qtfzy+uSTT+Tk5KQnnnjCbvqTTz4pwzC0ceNGu+mRkZFq1qyZ+bxdu3ay2Wz63//+V+ZyAgICNGTIEHOas7OznnjiCZ05c0bbtm2r9M8QHh6uzZs32z2GDx9uzr/ce1F8D+Dp06d18uRJde/eXefOndP+/fsr3Mcnn3yiBg0aaODAgea02rVr69FHH63wWJdz6tQpJScn6/e//73Z88mTJ/XLL78oKipK33//fYlDXo8++qjdIYLu3buroKBAR44cqVQPvXv3lq+vr7mnS5J+/fVXbd68WYMGDTKneXt768cff9TXX39dqeVI/7+36ttvv9W6detKrdm5c6cyMzP1+OOP2523FB0drZYtW2rDhg0lXvPYY4/ZPe/evXuZ23Bxjz76aIltLjQ01Jx/5513lnpeYPFt7tdff1V2dra6d++uXbt2lXvZRQoKCrRp0ybFxMTo1ltvNae3atVKUVFRFR7vcjZv3qysrCwNGTLE3N5OnjwpJycnhYeHa8uWLSVec7Xrt7JK29NYfJ2fPXtWJ0+eVNeuXWUYhr755psS9WX17u3trbNnz17x8Jerq6scHX+LCQUFBfrll1/M00iKv9fvvfeefH19NX78+BJjVObijKLfF3FxcXbTi/b6X/pZCAkJMY9mSL8dFWjRokWJn3ffvn36/vvvK9xPRRCqqrEzZ87YBZhLDRo0SHfccYdGjx4tf39/DR48WGvWrKlQwLrlllsqdFJ68+bN7Z47ODgoODj4mt8r5siRI2rYsGGJ9dGqVStzfnHFv7yL1K1bV7/++muZy2nevLn5RVPWcirC19dXkZGRdo+mTZua8y/3Xuzbt08PPvigvLy8ZLPZ5OfnZ558nJ2dXeE+jhw5ouDg4BJfhi1atKjwWJdz8OBBGYah559/Xn5+fnaPoqslMzMz7V5z6XtWt25dSSrzPbucWrVqacCAAfrwww/N8zTef/995efn24WqKVOmyNPTU507d1bz5s01duxY8xB6RQwdOlTBwcGXPbeqaNspbT23bNmyxLbl5uZW4pDypdvwiRMnlJ6ebj6KX30m/fZ5vXSbK1qvktSkSZNSf5b169erS5cucnNzk4+Pj3korDLb24kTJ3T+/PkS3x2Stdtc0S/T3r17l9jmPv300xLbW3nW77VQq1YtNWrUqMT0o0ePasSIEfLx8THPk7rzzjsllfycl6f3xx9/XLfddpvuueceNWrUSA8//HCJ80oLCws1b948NW/eXK6urvL19ZWfn592795tt8wffvhBLVq0sOxk8yNHjsjR0VHBwcF20wMCAuTt7V2p7/P4+HhlZWXptttuU9u2bfXUU09p9+7dlvRbHOdUVVM//vijsrOzS2x0xbm7u2v79u3asmWLNmzYoMTERK1evVq9e/fWp59+KicnpzKXU5HzoMrrcv9zKSgoKFdPVrjcckr7ZXejKO29yMrK0p133imbzab4+Hg1a9ZMbm5u2rVrl6ZMmWIXoK/Feq/smEV9TZ48+bJ7Iy7dtq/FezZ48GAtW7ZMGzduVExMjNasWaOWLVva7a1p1aqVDhw4oPXr1ysxMVHvvfeeFi9erOnTp5uXiJdH0d6qESNG6MMPP6x0z8XHK0unTp3sfgHNmDGjQidSl7bN/etf/9L999+vHj16aPHixWrQoIGcnZ21fPlyu5P3r7RtVNbVjFm0za1cuVIBAQEl5l8aCK7Xd9Gliu8dKlJQUKC77rpLp06d0pQpU9SyZUt5eHjop59+0ogRI0r8R7k8vdevX19paWnatGmTNm7cqI0bN2r58uUaPny4eeHNn//8Zz3//PN6+OGH9cILL8jHx0eOjo6aOHHidbmlTXn3cpXnu6FHjx764Ycf9OGHH+rTTz/VG2+8oXnz5mnp0qUaPXq0Jf1KhKpqa+XKlZJU5u5xR0dH9enTR3369NHcuXP15z//Wc8++6y2bNmiyMhIy++bc+muVcMwdPDgQbsTEuvWrausrKwSrz1y5IjdnpmK9Na4cWN99tlnOn36tN3eqqLDX40bNy73WGUtZ/fu3SosLLT74rN6OeW1detW/fLLL3r//ffVo0cPc/qhQ4dK1JZ3vTdu3Fh79+6VYRh278GBAwcqPealiuY5OzsrMjLysnUVVdHtuUePHmrQoIFWr16tbt26KTk52TzJvTgPDw8NGjRIgwYNUl5envr3768//elPmjZtWoVuMfDQQw/pxRdf1KxZs3T//ffbzSvadg4cOKDevXvbzTtw4ECltq233nrL7uqwK70n5fXee+/Jzc1NmzZtkqurqzl9+fLldnVFe7wu3T4u3cvg5+cnd3f3Ug/LXLrNlXfM0hQd7q9fv75l29z1uu/Ynj179N///lcrVqywOyXgaq9cc3Fx0X333af77rtPhYWFevzxx7Vs2TI9//zzCg4O1rvvvqtevXrp73//u93rsrKy7O6t1axZM3311VfKz8+/7O1uKvp9XlhYqO+//948CiBJGRkZysrKqvT3bNEVvyNHjtSZM2fUo0cPzZw509JQxeG/aig5OVkvvPCCmjRpYl5uW5pTp06VmFZ0E82iwx1F9z8p7RdjZfzjH/+wO8/r3Xff1c8//6x77rnHnNasWTP9+9//Vl5enjlt/fr1JW69UJHe7r33XhUUFGjhwoV20+fNmycHBwe75V+Ne++9V+np6Xbn4Vy8eFGvv/66PD09zd3x10vR/9CK/48sLy9PixcvLlFb3vV+77336vjx43aXyJ87d05//etfKz3mperXr6+ePXtq2bJl+vnnn0vML36rhIrw8PCo0Lbs6OiogQMH6uOPP9bKlSt18eJFu0N/0m9XXRbn4uKikJAQGYah/Pz8CvVXtLcqLS2txK0jOnbsqPr162vp0qV2l41v3LhR3333XaWuqrvjjjsuezi5spycnOTg4GC3d+jw4cMlzhWz2Wzy9fXV9u3b7aZfum06OTkpKipK69at09GjR83p3333nTZt2lSpMUsTFRUlm82mP//5z6W+b5XZ5oquzLPq+/NySvucG4Zhd/uDirp0u3Z0dDT/81u0/Tk5OZXYE7x27doS5zsOGDBAJ0+eLPH9W7zniqyrohvSzp8/32763LlzJalSn4VLf15PT08FBweXequYq8Geqhvcxo0btX//fl28eFEZGRlKTk7W5s2b1bhxY3300UdX/F9yfHy8tm/frujoaDVu3FiZmZlavHixGjVqpG7dukn67Zeit7e3li5dqjp16sjDw0Ph4eGXPZeiLD4+PurWrZtGjhypjIwMzZ8/X8HBwXa3fRg9erTeffdd3X333fr973+vH374Qf/85z/tThyvaG/33XefevXqpWeffVaHDx9WaGioPv30U3344YeaOHFiibEr69FHH9WyZcs0YsQIpaamKigoSO+++66++OILzZ8//4rnuF0LXbt2Vd26dRUbG6snnnhCDg4OWrlyZamHxMq73h955BEtXLhQw4cPV2pqqho0aKCVK1eWeqPR8o5ZmkWLFqlbt25q27atHnnkETVt2lQZGRlKSUnRjz/+WOq9cMoSFhamJUuW6MUXX1RwcLDq169fYq/PpQYNGqTXX39dM2bMUNu2be3+ZyxJffv2VUBAgO644w75+/vru+++08KFCxUdHV2p93vo0KF64YUXSvz5JWdnZ/3lL3/RyJEjdeedd2rIkCHmLRWCgoI0adKkCi/rWoiOjtbcuXN199136w9/+IMyMzO1aNEiBQcHlzhHZfTo0XrppZc0evRodezYUdu3b9d///vfEmPOmjVLiYmJ6t69ux5//HHzPyqtW7eu9JiXstlsWrJkiYYNG6YOHTpo8ODB8vPz09GjR7VhwwbdcccdpYaCK3F3d1dISIhWr16t2267TT4+PmrTpo3atGlToXHK0rJlSzVr1kyTJ0/WTz/9JJvNpvfee++qzu8aPXq0Tp06pd69e6tRo0Y6cuSIXn/9dbVv3978DPTr10/x8fEaOXKkunbtqj179uitt94qEc6HDx+uf/zjH4qLi9OOHTvUvXt3nT17Vp999pkef/xxPfDAAxVaV6GhoYqNjdVf//pX8xSHHTt2aMWKFYqJiVGvXr0q/POGhISoZ8+eCgsLk4+Pj3bu3Kl3331X48aNq9wKvJxrfn0hKqXocuCih4uLixEQEGDcddddxoIFC+wu3S9y6WWpSUlJxgMPPGA0bNjQcHFxMRo2bGgMGTLE+O9//2v3ug8//NAICQkxatWqZXe58p133nnZS8kvd0uFt99+25g2bZpRv359w93d3YiOjra73LfIq6++atxyyy2Gq6urcccddxg7d+4sMeaVerv0lgqG8dsl05MmTTIaNmxoODs7G82bNzdefvllu8vwDeO3S6/Hjh1boqfL3R7gUhkZGcbIkSMNX19fw8XFxWjbtm2pl3hX9JYKV6q90nvxxRdfGF26dDHc3d2Nhg0bGk8//bR5u4Ditz8wjPKv9yNHjhj333+/Ubt2bcPX19eYMGGCkZiYWOkxL3cp/A8//GAMHz7cCAgIMJydnY1bbrnF6Nevn/Huu++aNZe7vUjRNle8n/T0dCM6OtqoU6eOIalct1coLCw0AgMDS70lh2EYxrJly4wePXoY9erVM1xdXY1mzZoZTz31lJGdnX3FcYvfUuFSxT/fl97yZPXq1cbtt99uuLq6Gj4+PsbQoUONH3/80a4mNjbW8PDwKDHupd8BlemtyOU+J4ZhGH//+9+N5s2bG66urkbLli2N5cuXl7rsc+fOGaNGjTK8vLyMOnXqGL///e+NzMzMUi+t37ZtmxEWFma4uLgYTZs2NZYuXXpVY156S4UiW7ZsMaKiogwvLy/Dzc3NaNasmTFixAhj586dZk1F1u+XX35p9l3az3U5l7ulQmnLNYzfbjERGRlpeHp6Gr6+vsYjjzxi3gqm+OeqvL2/++67Rt++fY369esbLi4uxq233mr88Y9/NH7++Wez5sKFC8aTTz5pNGjQwHB3dzfuuOMOIyUlpdTvjHPnzhnPPvus0aRJE8PZ2dkICAgwBg4caPzwww9lrqvS1mt+fr4xa9Ysc7zAwEBj2rRpdrdgMYzLf3de2uOLL75odO7c2fD29jbc3d2Nli1bGn/605+MvLy8Utd3ZTkYxg18Zi4AAEA1wTlVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAm39eR4WFhTp+/Ljq1Klz3f68AQAAuDqGYej06dNq2LBhib/NWByh6jo6fvy4AgMDq7oNAABQCceOHVOjRo0uO59QdR0V/UmLY8eOyWazVXE3AACgPHJychQYGFjmn6YiVF1HRYf8bDYboQoAgGqmrFN3OFEdAADAAoQqAAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALFCrqhtAzRA0dUNVt4Dr6PBL0VXdAgBcd+ypAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALECoAgAAsAChCgAAwAJVGqpmzpwpBwcHu0fLli3N+RcuXNDYsWNVr149eXp6asCAAcrIyLAb4+jRo4qOjlbt2rVVv359PfXUU7p48aJdzdatW9WhQwe5uroqODhYCQkJJXpZtGiRgoKC5ObmpvDwcO3YscNufnl6AQAANVeV76lq3bq1fv75Z/Px+eefm/MmTZqkjz/+WGvXrtW2bdt0/Phx9e/f35xfUFCg6Oho5eXl6csvv9SKFSuUkJCg6dOnmzWHDh1SdHS0evXqpbS0NE2cOFGjR4/Wpk2bzJrVq1crLi5OM2bM0K5duxQaGqqoqChlZmaWuxcAAFCzORiGYVTVwmfOnKl169YpLS2txLzs7Gz5+flp1apVGjhwoCRp//79atWqlVJSUtSlSxdt3LhR/fr10/Hjx+Xv7y9JWrp0qaZMmaITJ07IxcVFU6ZM0YYNG7R3715z7MGDBysrK0uJiYmSpPDwcHXq1EkLFy6UJBUWFiowMFDjx4/X1KlTy9VLeeTk5MjLy0vZ2dmy2WyVXm/VUdDUDVXdAq6jwy9FV3ULAGCZ8v7+rvI9Vd9//70aNmyopk2baujQoTp69KgkKTU1Vfn5+YqMjDRrW7ZsqVtvvVUpKSmSpJSUFLVt29YMVJIUFRWlnJwc7du3z6wpPkZRTdEYeXl5Sk1NtatxdHRUZGSkWVOeXkqTm5urnJwcuwcAALg5VWmoCg8PV0JCghITE7VkyRIdOnRI3bt31+nTp5Weni4XFxd5e3vbvcbf31/p6emSpPT0dLtAVTS/aN6VanJycnT+/HmdPHlSBQUFpdYUH6OsXkoze/ZseXl5mY/AwMDyrRgAAFDt1KrKhd9zzz3mv9u1a6fw8HA1btxYa9askbu7exV2Zo1p06YpLi7OfJ6Tk0OwAgDgJlXlh/+K8/b21m233aaDBw8qICBAeXl5ysrKsqvJyMhQQECAJCkgIKDEFXhFz8uqsdlscnd3l6+vr5ycnEqtKT5GWb2UxtXVVTabze4BAABuTjdUqDpz5ox++OEHNWjQQGFhYXJ2dlZSUpI5/8CBAzp69KgiIiIkSREREdqzZ4/dVXqbN2+WzWZTSEiIWVN8jKKaojFcXFwUFhZmV1NYWKikpCSzpjy9AACAmq1KD/9NnjxZ9913nxo3bqzjx49rxowZcnJy0pAhQ+Tl5aVRo0YpLi5OPj4+stlsGj9+vCIiIsyr7fr27auQkBANGzZMc+bMUXp6up577jmNHTtWrq6ukqTHHntMCxcu1NNPP62HH35YycnJWrNmjTZs+P+r0eLi4hQbG6uOHTuqc+fOmj9/vs6ePauRI0dKUrl6AQAANVuVhqoff/xRQ4YM0S+//CI/Pz9169ZN//73v+Xn5ydJmjdvnhwdHTVgwADl5uYqKipKixcvNl/v5OSk9evXa8yYMYqIiJCHh4diY2MVHx9v1jRp0kQbNmzQpEmTtGDBAjVq1EhvvPGGoqKizJpBgwbpxIkTmj59utLT09W+fXslJibanbxeVi8AAKBmq9L7VNU03KcKNQX3qQJwM6k296kCAAC4GRCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALHDDhKqXXnpJDg4OmjhxojntwoULGjt2rOrVqydPT08NGDBAGRkZdq87evSooqOjVbt2bdWvX19PPfWULl68aFezdetWdejQQa6urgoODlZCQkKJ5S9atEhBQUFyc3NTeHi4duzYYTe/PL0AAICa64YIVV9//bWWLVumdu3a2U2fNGmSPv74Y61du1bbtm3T8ePH1b9/f3N+QUGBoqOjlZeXpy+//FIrVqxQQkKCpk+fbtYcOnRI0dHR6tWrl9LS0jRx4kSNHj1amzZtMmtWr16tuLg4zZgxQ7t27VJoaKiioqKUmZlZ7l4AAEDN5mAYhlGVDZw5c0YdOnTQ4sWL9eKLL6p9+/aaP3++srOz5efnp1WrVmngwIGSpP3796tVq1ZKSUlRly5dtHHjRvXr10/Hjx+Xv7+/JGnp0qWaMmWKTpw4IRcXF02ZMkUbNmzQ3r17zWUOHjxYWVlZSkxMlCSFh4erU6dOWrhwoSSpsLBQgYGBGj9+vKZOnVquXsojJydHXl5eys7Ols1ms2wdVgdBUzdUdQu4jg6/FF3VLQCAZcr7+7vK91SNHTtW0dHRioyMtJuempqq/Px8u+ktW7bUrbfeqpSUFElSSkqK2rZtawYqSYqKilJOTo727dtn1lw6dlRUlDlGXl6eUlNT7WocHR0VGRlp1pSnFwAAULPVqsqFv/POO9q1a5e+/vrrEvPS09Pl4uIib29vu+n+/v5KT083a4oHqqL5RfOuVJOTk6Pz58/r119/VUFBQak1+/fvL3cvpcnNzVVubq75PCcn57K1AACgequyPVXHjh3ThAkT9NZbb8nNza2q2rimZs+eLS8vL/MRGBhY1S0BAIBrpMpCVWpqqjIzM9WhQwfVqlVLtWrV0rZt2/Taa6+pVq1a8vf3V15enrKysuxel5GRoYCAAElSQEBAiSvwip6XVWOz2eTu7i5fX185OTmVWlN8jLJ6Kc20adOUnZ1tPo4dO1a+lQMAAKqdKgtVffr00Z49e5SWlmY+OnbsqKFDh5r/dnZ2VlJSkvmaAwcO6OjRo4qIiJAkRUREaM+ePXZX6W3evFk2m00hISFmTfEximqKxnBxcVFYWJhdTWFhoZKSksyasLCwMnspjaurq2w2m90DAADcnKrsnKo6deqoTZs2dtM8PDxUr149c/qoUaMUFxcnHx8f2Ww2jR8/XhEREebVdn379lVISIiGDRumOXPmKD09Xc8995zGjh0rV1dXSdJjjz2mhQsX6umnn9bDDz+s5ORkrVmzRhs2/P/VaHFxcYqNjVXHjh3VuXNnzZ8/X2fPntXIkSMlSV5eXmX2AgAAarYqPVG9LPPmzZOjo6MGDBig3NxcRUVFafHixeZ8JycnrV+/XmPGjFFERIQ8PDwUGxur+Ph4s6ZJkybasGGDJk2apAULFqhRo0Z64403FBUVZdYMGjRIJ06c0PTp05Wenq727dsrMTHR7uT1snoBAAA1W5Xfp6om4T5VqCm4TxWAm0m1uU8VAADAzYBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYIFKhaqmTZvql19+KTE9KytLTZs2veqmAAAAqptKharDhw+roKCgxPTc3Fz99NNPV90UAABAdVOrIsUfffSR+e9NmzbJy8vLfF5QUKCkpCQFBQVZ1hwAAEB1UaFQFRMTI0lycHBQbGys3TxnZ2cFBQXp1Vdftaw5AACA6qJCoaqwsFCS1KRJE3399dfy9fW9Jk0BAABUNxUKVUUOHTpkdR8AAADVWqVClSQlJSUpKSlJmZmZ5h6sIm+++eZVNwYAAFCdVCpUzZo1S/Hx8erYsaMaNGggBwcHq/sCAACoVioVqpYuXaqEhAQNGzbM6n4AAACqpUrdpyovL09du3a1uhcAAIBqq1KhavTo0Vq1apXVvQAAAFRblTr8d+HCBf31r3/VZ599pnbt2snZ2dlu/ty5cy1pDgAAoLqoVKjavXu32rdvL0nau3ev3TxOWgcAADVRpQ7/bdmy5bKP5OTkco+zZMkStWvXTjabTTabTREREdq4caM5/8KFCxo7dqzq1asnT09PDRgwQBkZGXZjHD16VNHR0apdu7bq16+vp556ShcvXrSr2bp1qzp06CBXV1cFBwcrISGhRC+LFi1SUFCQ3NzcFB4erh07dtjNL08vAACg5qpUqLJKo0aN9NJLLyk1NVU7d+5U79699cADD2jfvn2SpEmTJunjjz/W2rVrtW3bNh0/flz9+/c3X19QUKDo6Gjl5eXpyy+/1IoVK5SQkKDp06ebNYcOHVJ0dLR69eqltLQ0TZw4UaNHj9amTZvMmtWrVysuLk4zZszQrl27FBoaqqioKGVmZpo1ZfUCAABqNgfDMIyKvqhXr15XPMxXkb1Vl/Lx8dHLL7+sgQMHys/PT6tWrdLAgQMlSfv371erVq2UkpKiLl26aOPGjerXr5+OHz8uf39/Sb/d7mHKlCk6ceKEXFxcNGXKFG3YsMHuMOXgwYOVlZWlxMRESVJ4eLg6deqkhQsXSvrtz/EEBgZq/Pjxmjp1qrKzs8vspTxycnLk5eWl7Oxs2Wy2Sq+j6iho6oaqbgHX0eGXoqu6BQCwTHl/f1dqT1X79u0VGhpqPkJCQpSXl6ddu3apbdu2lWq4oKBA77zzjs6ePauIiAilpqYqPz9fkZGRZk3Lli116623KiUlRZKUkpKitm3bmoFKkqKiopSTk2Pu7UpJSbEbo6imaIy8vDylpqba1Tg6OioyMtKsKU8vAACgZqvUierz5s0rdfrMmTN15syZCo21Z88eRURE6MKFC/L09NQHH3ygkJAQpaWlycXFRd7e3nb1/v7+Sk9PlySlp6fbBaqi+UXzrlSTk5Oj8+fP69dff1VBQUGpNfv37zfHKKuX0uTm5io3N9d8npOTU8baAAAA1ZWl51Q99NBDFf67fy1atFBaWpq++uorjRkzRrGxsfrPf/5jZVtVZvbs2fLy8jIfgYGBVd0SAAC4RiwNVSkpKXJzc6vQa1xcXBQcHKywsDDNnj1boaGhWrBggQICApSXl6esrCy7+oyMDAUEBEiSAgICSlyBV/S8rBqbzSZ3d3f5+vrKycmp1JriY5TVS2mmTZum7Oxs83Hs2LHyrRQAAFDtVOrw36VXvRmGoZ9//lk7d+7U888/f1UNFRYWKjc3V2FhYXJ2dlZSUpIGDBggSTpw4ICOHj2qiIgISVJERIT+9Kc/KTMzU/Xr15ckbd68WTabTSEhIWbNJ598YreMzZs3m2O4uLgoLCxMSUlJiomJMXtISkrSuHHjJKlcvZTG1dVVrq6uV7U+AABA9VCpUOXl5WX33NHRUS1atFB8fLz69u1b7nGmTZume+65R7feeqtOnz6tVatWaevWrdq0aZO8vLw0atQoxcXFycfHRzabTePHj1dERIR5tV3fvn0VEhKiYcOGac6cOUpPT9dzzz2nsWPHmmHmscce08KFC/X000/r4YcfVnJystasWaMNG/7/arS4uDjFxsaqY8eO6ty5s+bPn6+zZ89q5MiR5s9bVi8AAKBmq1SoWr58uSULz8zM1PDhw/Xzzz/Ly8tL7dq106ZNm3TXXXdJ+u2EeEdHRw0YMEC5ubmKiorS4sWLzdc7OTlp/fr1GjNmjCIiIuTh4aHY2FjFx8ebNU2aNNGGDRs0adIkLViwQI0aNdIbb7yhqKgos2bQoEE6ceKEpk+frvT0dLVv316JiYl2J6+X1QsAAKjZKnWfqiKpqan67rvvJEmtW7fW7bffblljNyPuU4WagvtUAbiZlPf3d6X2VGVmZmrw4MHaunWreZuBrKws9erVS++88478/Pwq1TQAAEB1Vamr/8aPH6/Tp09r3759OnXqlE6dOqW9e/cqJydHTzzxhNU9AgAA3PAqtacqMTFRn332mVq1amVOCwkJ0aJFiyp0ojoAAMDNolJ7qgoLC+Xs7FxiurOzswoLC6+6KQAAgOqmUqGqd+/emjBhgo4fP25O++mnnzRp0iT16dPHsuYAAACqi0qFqoULFyonJ0dBQUFq1qyZmjVrpiZNmignJ0evv/661T0CAADc8Cp1TlVgYKB27dqlzz77zPyjw61atVJkZKSlzQEAAFQXFdpTlZycrJCQEOXk5MjBwUF33XWXxo8fr/Hjx6tTp05q3bq1/vWvf12rXgEAAG5YFQpV8+fP1yOPPFLqja+8vLz0xz/+UXPnzrWsOQAAgOqiQqHq22+/1d13333Z+X379lVqaupVNwUAAFDdVChUZWRklHorhSK1atXSiRMnrropAACA6qZCoeqWW27R3r17Lzt/9+7datCgwVU3BQAAUN1UKFTde++9ev7553XhwoUS886fP68ZM2aoX79+ljUHAABQXVTolgrPPfec3n//fd12220aN26cWrRoIUnav3+/Fi1apIKCAj377LPXpFEAAIAbWYVClb+/v7788kuNGTNG06ZNk2EYkiQHBwdFRUVp0aJF8vf3vyaNAgAA3MgqfPPPxo0b65NPPtGvv/6qgwcPyjAMNW/eXHXr1r0W/QEAAFQLlbqjuiTVrVtXnTp1srIXAACAaqtSf/sPAAAA9ghVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWqNJQNXv2bHXq1El16tRR/fr1FRMTowMHDtjVXLhwQWPHjlW9evXk6empAQMGKCMjw67m6NGjio6OVu3atVW/fn099dRTunjxol3N1q1b1aFDB7m6uio4OFgJCQkl+lm0aJGCgoLk5uam8PBw7dixo8K9AACAmqlKQ9W2bds0duxY/fvf/9bmzZuVn5+vvn376uzZs2bNpEmT9PHHH2vt2rXatm2bjh8/rv79+5vzCwoKFB0drby8PH355ZdasWKFEhISNH36dLPm0KFDio6OVq9evZSWlqaJEydq9OjR2rRpk1mzevVqxcXFacaMGdq1a5dCQ0MVFRWlzMzMcvcCAABqLgfDMIyqbqLIiRMnVL9+fW3btk09evRQdna2/Pz8tGrVKg0cOFCStH//frVq1UopKSnq0qWLNm7cqH79+un48ePy9/eXJC1dulRTpkzRiRMn5OLioilTpmjDhg3au3evuazBgwcrKytLiYmJkqTw8HB16tRJCxculCQVFhYqMDBQ48eP19SpU8vVS1lycnLk5eWl7Oxs2Ww2S9fdjS5o6oaqbgHX0eGXoqu6BQCwTHl/f99Q51RlZ2dLknx8fCRJqampys/PV2RkpFnTsmVL3XrrrUpJSZEkpaSkqG3btmagkqSoqCjl5ORo3759Zk3xMYpqisbIy8tTamqqXY2jo6MiIyPNmvL0cqnc3Fzl5OTYPQAAwM3phglVhYWFmjhxou644w61adNGkpSeni4XFxd5e3vb1fr7+ys9Pd2sKR6oiuYXzbtSTU5Ojs6fP6+TJ0+qoKCg1JriY5TVy6Vmz54tLy8v8xEYGFjOtQEAAKqbGyZUjR07Vnv37tU777xT1a1YZtq0acrOzjYfx44dq+qWAADANVKrqhuQpHHjxmn9+vXavn27GjVqZE4PCAhQXl6esrKy7PYQZWRkKCAgwKy59Cq9oivyitdcepVeRkaGbDab3N3d5eTkJCcnp1Jrio9RVi+XcnV1laurawXWBAAAqK6qdE+VYRgaN26cPvjgAyUnJ6tJkyZ288PCwuTs7KykpCRz2oEDB3T06FFFRERIkiIiIrRnzx67q/Q2b94sm82mkJAQs6b4GEU1RWO4uLgoLCzMrqawsFBJSUlmTXl6AQAANVeV7qkaO3asVq1apQ8//FB16tQxz03y8vKSu7u7vLy8NGrUKMXFxcnHx0c2m03jx49XRESEebVd3759FRISomHDhmnOnDlKT0/Xc889p7Fjx5p7iR577DEtXLhQTz/9tB5++GElJydrzZo12rDh/69Ii4uLU2xsrDp27KjOnTtr/vz5Onv2rEaOHGn2VFYvAACg5qrSULVkyRJJUs+ePe2mL1++XCNGjJAkzZs3T46OjhowYIByc3MVFRWlxYsXm7VOTk5av369xowZo4iICHl4eCg2Nlbx8fFmTZMmTbRhwwZNmjRJCxYsUKNGjfTGG28oKirKrBk0aJBOnDih6dOnKz09Xe3bt1diYqLdyetl9QIAAGquG+o+VTc77lOFmoL7VAG4mVTL+1QBAABUV4QqAAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALFCloWr79u2677771LBhQzk4OGjdunV28w3D0PTp09WgQQO5u7srMjJS33//vV3NqVOnNHToUNlsNnl7e2vUqFE6c+aMXc3u3bvVvXt3ubm5KTAwUHPmzCnRy9q1a9WyZUu5ubmpbdu2+uSTTyrcCwAAqLmqNFSdPXtWoaGhWrRoUanz58yZo9dee01Lly7VV199JQ8PD0VFRenChQtmzdChQ7Vv3z5t3rxZ69ev1/bt2/Xoo4+a83NyctS3b181btxYqampevnllzVz5kz99a9/NWu+/PJLDRkyRKNGjdI333yjmJgYxcTEaO/evRXqBQAA1FwOhmEYVd2EJDk4OOiDDz5QTEyMpN/2DDVs2FBPPvmkJk+eLEnKzs6Wv7+/EhISNHjwYH333XcKCQnR119/rY4dO0qSEhMTde+99+rHH39Uw4YNtWTJEj377LNKT0+Xi4uLJGnq1Klat26d9u/fL0kaNGiQzp49q/Xr15v9dOnSRe3bt9fSpUvL1Ut55OTkyMvLS9nZ2bLZbJast+oiaOqGqm4B19Hhl6KrugUAsEx5f3/fsOdUHTp0SOnp6YqMjDSneXl5KTw8XCkpKZKklJQUeXt7m4FKkiIjI+Xo6KivvvrKrOnRo4cZqCQpKipKBw4c0K+//mrWFF9OUU3RcsrTS2lyc3OVk5Nj9wAAADenGzZUpaenS5L8/f3tpvv7+5vz0tPTVb9+fbv5tWrVko+Pj11NaWMUX8blaorPL6uX0syePVteXl7mIzAwsIyfGgAAVFc3bKi6GUybNk3Z2dnm49ixY1XdEgAAuEZu2FAVEBAgScrIyLCbnpGRYc4LCAhQZmam3fyLFy/q1KlTdjWljVF8GZerKT6/rF5K4+rqKpvNZvcAAAA3pxs2VDVp0kQBAQFKSkoyp+Xk5Oirr75SRESEJCkiIkJZWVlKTU01a5KTk1VYWKjw8HCzZvv27crPzzdrNm/erBYtWqhu3bpmTfHlFNUULac8vQAAgJqtSkPVmTNnlJaWprS0NEm/nRCelpamo0ePysHBQRMnTtSLL76ojz76SHv27NHw4cPVsGFD8wrBVq1a6e6779YjjzyiHTt26IsvvtC4ceM0ePBgNWzYUJL0hz/8QS4uLho1apT27dun1atXa8GCBYqLizP7mDBhghITE/Xqq69q//79mjlzpnbu3Klx48ZJUrl6AQAANVutqlz4zp071atXL/N5UdCJjY1VQkKCnn76aZ09e1aPPvqosrKy1K1bNyUmJsrNzc18zVtvvaVx48apT58+cnR01IABA/Taa6+Z8728vPTpp59q7NixCgsLk6+vr6ZPn253L6uuXbtq1apVeu655/TMM8+oefPmWrdundq0aWPWlKcXAABQc90w96mqCbhPFWoK7lMF4GZS7e9TBQAAUJ0QqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsQKgCAACwAKEKAADAAoQqAAAACxCqAAAALECoAgAAsAChCgAAwAKEKgAAAAsQqgAAACxAqAIAALAAoQoAAMAChCoAAAALEKoAAAAsUKuqGwAAVG9BUzdUdQu4jg6/FF3VLdyw2FMFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYAFCFQAAgAUIVQAAABYgVFXQokWLFBQUJDc3N4WHh2vHjh1V3RIAALgBEKoqYPXq1YqLi9OMGTO0a9cuhYaGKioqSpmZmVXdGgAAqGKEqgqYO3euHnnkEY0cOVIhISFaunSpateurTfffLOqWwMAAFWMUFVOeXl5Sk1NVWRkpDnN0dFRkZGRSklJqcLOAADAjYC//VdOJ0+eVEFBgfz9/e2m+/v7a//+/aW+Jjc3V7m5uebz7OxsSVJOTs61a/QGVZh7rqpbwHVUE7fxmozPd81SEz/fRT+zYRhXrCNUXUOzZ8/WrFmzSkwPDAysgm6A68drflV3AOBaqcmf79OnT8vLy+uy8wlV5eTr6ysnJydlZGTYTc/IyFBAQECpr5k2bZri4uLM54WFhTp16pTq1asnBweHa9ovql5OTo4CAwN17Ngx2Wy2qm4HgIX4fNcshmHo9OnTatiw4RXrCFXl5OLiorCwMCUlJSkmJkbSbyEpKSlJ48aNK/U1rq6ucnV1tZvm7e19jTvFjcZms/GlC9yk+HzXHFfaQ1WEUFUBcXFxio2NVceOHdW5c2fNnz9fZ8+e1ciRI6u6NQAAUMUIVRUwaNAgnThxQtOnT1d6errat2+vxMTEEievAwCAmodQVUHjxo277OE+oDhXV1fNmDGjxCFgANUfn2+UxsEo6/pAAAAAlImbfwIAAFiAUAUAAGABQhUAAIAFCFUAAAAW4Oo/wCInT57Um2++qZSUFKWnp0uSAgIC1LVrV40YMUJ+fn5V3CEA4Fri6j/AAl9//bWioqJUu3ZtRUZGmvcuy8jIUFJSks6dO6dNmzapY8eOVdwpAOBaIVQBFujSpYtCQ0O1dOnSEn/X0TAMPfbYY9q9e7dSUlKqqEMA18qxY8c0Y8YMvfnmm1XdCqoYoQqwgLu7u7755hu1bNmy1Pn79+/X7bffrvPnz1/nzgBca99++606dOiggoKCqm4FVYxzqgALBAQEaMeOHZcNVTt27ODPGQHV1EcffXTF+f/73/+uUye40RGqAAtMnjxZjz76qFJTU9WnT58S51T97W9/0yuvvFLFXQKojJiYGDk4OOhKB3YuPeyPmonDf4BFVq9erXnz5ik1NdU8DODk5KSwsDDFxcXp97//fRV3CKAybrnlFi1evFgPPPBAqfPT0tIUFhbG4T8QqgCr5efn6+TJk5IkX19fOTs7V3FHAK7G/fffr/bt2ys+Pr7U+d9++61uv/12FRYWXufOcKPh8B9gMWdnZzVo0KCq2wBgkaeeekpnz5697Pzg4GBt2bLlOnaEGxV7qgAAACzAn6kBAACwAKEKAADAAoQqAAAACxCqANQYPXv21MSJE6u6jQoZMWKEYmJiqroNAOVAqAJQY7z//vt64YUXyqwbMWKEHBwcSjwOHjx4HboEUF1xSwUANYaPj0+5a++++24tX77cbpqfn1+Jury8PLm4uFx1bwCqP/ZUAagxih/+W7x4sZo3by43Nzf5+/tr4MCBdrWurq4KCAiwezg5Oalnz54aN26cJk6cKF9fX0VFRUmS5s6dq7Zt28rDw0OBgYF6/PHHdebMGXO8mTNnqn379nbLmD9/voKCgsznBQUFiouLk7e3t+rVq6enn376in8aBcCNhVAFoMbZuXOnnnjiCcXHx+vAgQNKTExUjx49yv36FStWyMXFRV988YWWLl0qSXJ0dNRrr72mffv2acWKFUpOTtbTTz9dob5effVVJSQk6M0339Tnn3+uU6dO6YMPPqjQGACqDof/ANQ4R48elYeHh/r166c6deqocePGuv322+1q1q9fL09PT/P5Pffco7Vr10qSmjdvrjlz5tjVFz8BPigoSC+++KIee+wxLV68uNx9zZ8/X9OmTVP//v0lSUuXLtWmTZsq+uMBqCKEKgA1zl133aXGjRuradOmuvvuu3X33XfrwQcfVO3atc2aXr16acmSJeZzDw8P899hYWElxvzss880e/Zs7d+/Xzk5Obp48aIuXLigc+fO2Y17OdnZ2fr5558VHh5uTqtVq5Y6duzIIUCgmuDwH4Aap06dOtq1a5fefvttNWjQQNOnT1doaKiysrLMGg8PDwUHB5uP4n/PsXjAkqTDhw+rX79+ateund577z2lpqZq0aJFkn47kV367fDgpeEoPz//Gv2EAKoCoQpAjVSrVi1FRkZqzpw52r17tw4fPqzk5ORKjZWamqrCwkK9+uqr6tKli2677TYdP37crsbPz0/p6el2wSotLc38t5eXlxo0aKCvvvrKnHbx4kWlpqZWqicA1x+H/wDUOOvXr9f//vc/9ejRQ3Xr1tUnn3yiwsJCtWjRolLjBQcHKz8/X6+//rruu+8+uxPYi/Ts2VMnTpzQnDlzNHDgQCUmJmrjxo2y2WxmzYQJE/TSSy+pefPmatmypebOnWu39wzAjY09VQBqHG9vb73//vvq3bu3WrVqpaVLl+rtt99W69atKzVeaGio5s6dq7/85S9q06aN3nrrLc2ePduuplWrVlq8eLEWLVqk0NBQ7dixQ5MnT7arefLJJzVs2DDFxsYqIiJCderU0YMPPljpnxPA9eVgcAYkAADAVWNPFQAAgAUIVQAAABYgVAEAAFiAUAUAAGABQhUAAIAFCFUAAAAWIFQBAABYgFAFAABgAUIVAACABQhVAAAAFiBUAQAAWIBQBQAAYIH/A9/JY6yai4K0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of the target variable 'isFraud'\n",
    "train['isFraud'].value_counts().plot(kind='bar')\n",
    "plt.title(\"Distribution of Fraudulent vs Non-Fraudulent Transactions\")\n",
    "plt.xlabel(\"isFraud\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dist2',\n",
       " 'D7',\n",
       " 'id_07',\n",
       " 'id_08',\n",
       " 'id_18',\n",
       " 'id_21',\n",
       " 'id_22',\n",
       " 'id_23',\n",
       " 'id_24',\n",
       " 'id_25',\n",
       " 'id_26',\n",
       " 'id_27']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns where number of nulls exceeds 90%\n",
    "null_cols = [col for col in train.columns if train[col].isna().sum() > 0.9 * len(train)]\n",
    "null_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              m_flag_dist2   isFraud\n",
      "m_flag_dist2      1.000000 -0.091096\n",
      "isFraud          -0.091096  1.000000\n",
      "           m_flag_D7   isFraud\n",
      "m_flag_D7   1.000000 -0.164478\n",
      "isFraud    -0.164478  1.000000\n",
      "              m_flag_id_07   isFraud\n",
      "m_flag_id_07      1.000000 -0.024333\n",
      "isFraud          -0.024333  1.000000\n",
      "              m_flag_id_08   isFraud\n",
      "m_flag_id_08      1.000000 -0.024333\n",
      "isFraud          -0.024333  1.000000\n",
      "              m_flag_id_18   isFraud\n",
      "m_flag_id_18      1.000000 -0.074815\n",
      "isFraud          -0.074815  1.000000\n",
      "              m_flag_id_21  isFraud\n",
      "m_flag_id_21       1.00000 -0.02431\n",
      "isFraud           -0.02431  1.00000\n",
      "              m_flag_id_22   isFraud\n",
      "m_flag_id_22      1.000000 -0.024252\n",
      "isFraud          -0.024252  1.000000\n",
      "              m_flag_id_23   isFraud\n",
      "m_flag_id_23      1.000000 -0.024252\n",
      "isFraud          -0.024252  1.000000\n",
      "              m_flag_id_24   isFraud\n",
      "m_flag_id_24      1.000000 -0.024345\n",
      "isFraud          -0.024345  1.000000\n",
      "              m_flag_id_25   isFraud\n",
      "m_flag_id_25      1.000000 -0.023574\n",
      "isFraud          -0.023574  1.000000\n",
      "              m_flag_id_26   isFraud\n",
      "m_flag_id_26      1.000000 -0.024188\n",
      "isFraud          -0.024188  1.000000\n",
      "              m_flag_id_27   isFraud\n",
      "m_flag_id_27      1.000000 -0.024252\n",
      "isFraud          -0.024252  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Find correlations between columns with nulls and target\n",
    "missing_df = train.copy(deep=True)\n",
    "for col in null_cols:\n",
    "    missing_df[\"m_flag_\"+col] = np.where(missing_df[col].isnull(), 1, 0)\n",
    "    correlation = missing_df[[\"m_flag_\"+col, 'isFraud']].corr()\n",
    "    print(correlation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only correlation with D7 exceeds 0.1, others are not really sufficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Identify categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductCD 5 {'C', 'W', 'R', 'S', 'H'}\n",
      "card4 5 {'discover', nan, 'american express', 'visa', 'mastercard'}\n",
      "card6 5 {nan, 'debit', 'charge card', 'credit', 'debit or credit'}\n",
      "P_emaildomain 60 {'ptd.net', 'live.fr', 'protonmail.com', 'sbcglobal.net', 'gmail.com', 'earthlink.net', 'live.com.mx', 'comcast.net', 'yahoo.es', 'hotmail.co.uk', 'verizon.net', 'charter.net', 'att.net', 'ymail.com', 'yahoo.com.mx', 'hotmail.com', nan, 'live.com', 'frontier.com', 'hotmail.es', 'windstream.net', 'aol.com', 'rocketmail.com', 'juno.com', 'twc.com', 'roadrunner.com', 'msn.com', 'embarqmail.com', 'outlook.es', 'yahoo.com', 'gmail', 'suddenlink.net', 'aim.com', 'yahoo.co.jp', 'centurylink.net', 'netzero.net', 'cox.net', 'mail.com', 'me.com', 'anonymous.com', 'gmx.de', 'frontiernet.net', 'hotmail.fr', 'outlook.com', 'web.de', 'mac.com', 'prodigy.net.mx', 'q.com', 'yahoo.co.uk', 'cableone.net', 'optonline.net', 'hotmail.de', 'yahoo.fr', 'icloud.com', 'netzero.com', 'cfl.rr.com', 'servicios-ta.com', 'sc.rr.com', 'bellsouth.net', 'yahoo.de'}\n",
      "R_emaildomain 61 {'ptd.net', 'live.fr', 'protonmail.com', 'sbcglobal.net', 'gmail.com', 'earthlink.net', 'scranton.edu', 'live.com.mx', 'comcast.net', 'yahoo.es', 'hotmail.co.uk', 'verizon.net', 'charter.net', 'att.net', 'ymail.com', 'yahoo.com.mx', 'hotmail.com', nan, 'live.com', 'frontier.com', 'hotmail.es', 'windstream.net', 'aol.com', 'rocketmail.com', 'juno.com', 'twc.com', 'roadrunner.com', 'msn.com', 'embarqmail.com', 'outlook.es', 'yahoo.com', 'gmail', 'suddenlink.net', 'aim.com', 'yahoo.co.jp', 'centurylink.net', 'netzero.net', 'cox.net', 'mail.com', 'me.com', 'anonymous.com', 'gmx.de', 'frontiernet.net', 'hotmail.fr', 'outlook.com', 'web.de', 'mac.com', 'prodigy.net.mx', 'q.com', 'yahoo.co.uk', 'cableone.net', 'optonline.net', 'hotmail.de', 'yahoo.fr', 'icloud.com', 'netzero.com', 'cfl.rr.com', 'servicios-ta.com', 'sc.rr.com', 'bellsouth.net', 'yahoo.de'}\n",
      "M1 3 {nan, 'F', 'T'}\n",
      "M2 3 {nan, 'F', 'T'}\n",
      "M3 3 {nan, 'F', 'T'}\n",
      "M4 4 {nan, 'M1', 'M0', 'M2'}\n",
      "M5 3 {nan, 'F', 'T'}\n",
      "M6 3 {nan, 'F', 'T'}\n",
      "M7 3 {nan, 'F', 'T'}\n",
      "M8 3 {nan, 'F', 'T'}\n",
      "M9 3 {nan, 'F', 'T'}\n",
      "id_12 3 {nan, 'NotFound', 'Found'}\n",
      "id_15 4 {nan, 'New', 'Unknown', 'Found'}\n",
      "id_16 3 {nan, 'NotFound', 'Found'}\n",
      "id_23 4 {'IP_PROXY:ANONYMOUS', nan, 'IP_PROXY:HIDDEN', 'IP_PROXY:TRANSPARENT'}\n",
      "id_27 3 {nan, 'NotFound', 'Found'}\n",
      "id_28 3 {nan, 'New', 'Found'}\n",
      "id_29 3 {nan, 'NotFound', 'Found'}\n",
      "id_30 76 {'iOS 11.1.2', 'iOS 11.0.3', 'Android 7.1.2', 'Android 4.4.2', 'Mac OS X 10_13_2', 'Mac OS X 10.10', 'Android 6.0.1', 'Mac OS X 10_8_5', 'Windows 8', 'iOS 11.2.5', 'Android 6.0', 'func', 'Mac OS X 10.9', 'Mac OS X 10_11_3', 'Mac OS X 10_13_1', 'Android 5.1.1', 'Mac OS X 10_12_5', 'Windows XP', 'iOS 11.4.0', nan, 'Windows 7', 'iOS 11.1.1', 'iOS 9.3.5', 'Mac OS X 10_11_4', 'Mac OS X 10.6', 'Mac', 'Mac OS X 10_13_3', 'other', 'Mac OS X 10_13_4', 'iOS', 'iOS 11.2.6', 'Mac OS X 10_11_6', 'iOS 10.3.3', 'Linux', 'Mac OS X 10.12', 'Windows Vista', 'iOS 10.3.2', 'iOS 11.0.0', 'Mac OS X 10.13', 'Mac OS X 10_12_1', 'Android 8.1.0', 'iOS 10.3.1', 'Mac OS X 10_12', 'Mac OS X 10_12_4', 'Mac OS X 10_10_5', 'iOS 11.3.1', 'Mac OS X 10_13_5', 'Mac OS X 10_12_2', 'Android 5.0', 'Windows 8.1', 'Android 5.0.2', 'Mac OS X 10_12_6', 'iOS 10.2.1', 'Android 7.1.1', 'iOS 11.0.1', 'iOS 10.1.1', 'iOS 11.1.0', 'Mac OS X 10_11_5', 'iOS 11.0.2', 'Mac OS X 10_12_3', 'iOS 11.2.1', 'Windows 10', 'iOS 11.2.0', 'Android 7.0', 'iOS 10.0.2', 'Mac OS X 10_6_8', 'Mac OS X 10_7_5', 'Windows', 'iOS 11.2.2', 'iOS 10.2.0', 'Mac OS X 10.11', 'Android', 'iOS 11.3.0', 'Android 8.0.0', 'iOS 11.4.1', 'Mac OS X 10_9_5'}\n",
      "id_31 131 {'ie 11.0 for desktop', 'samsung browser 3.3', 'samsung browser 6.4', 'edge', 'chrome', 'samsung browser 6.2', 'mobile safari generic', 'iron', 'chrome 51.0 for android', 'chrome 69.0', 'chrome 57.0 for android', 'mobile safari 8.0', 'chrome 64.0 for android', 'chrome 58.0 for android', 'samsung browser 4.0', 'firefox 56.0', 'chrome generic for android', 'ZTE/Blade', 'opera 51.0', 'Samsung/SM-G531H', 'comodo', 'chrome 51.0', 'android browser 4.0', 'google', 'chrome 55.0 for android', 'safari', 'chrome 66.0 for ios', 'safari 9.0', 'chrome 49.0 for android', 'chromium', 'line', 'mobile safari 11.0', 'opera generic', 'chrome 59.0 for android', 'waterfox', 'Lanix/Ilium', 'mobile', 'chrome 56.0 for android', 'chrome 61.0 for android', 'Generic/Android', 'chrome 60.0 for android', 'opera 49.0', 'mobile safari 10.0', 'android', 'samsung browser generic', 'opera 52.0', 'firefox 60.0', nan, 'Generic/Android 7.0', 'chrome 67.0', 'chrome 57.0', 'facebook', 'maxthon', 'chrome 63.0', 'chrome 65.0 for ios', 'icedragon', 'silk', 'safari generic', 'chrome 64.0', 'Inco/Minion', 'firefox 52.0', 'mobile safari uiwebview', 'LG/K-200', 'firefox mobile 61.0', 'chrome 67.0 for android', 'edge 16.0', 'samsung', 'google search application 49.0', 'ie 11.0 for tablet', 'safari 10.0', 'chrome 52.0 for android', 'google search application 48.0', 'Samsung/SCH', 'chrome 62.0 for ios', 'android webview 4.0', 'Nokia/Lumia', 'safari 11.0', 'chrome 49.0', 'chrome 66.0 for android', 'edge 15.0', 'chrome 58.0', 'M4Tel/M4', 'samsung browser 4.2', 'chrome 63.0 for ios', 'firefox generic', 'ie', 'aol', 'chrome 63.0 for android', 'Samsung/SM-G532M', 'chrome 43.0 for android', 'firefox 59.0', 'Microsoft/Windows', 'palemoon', 'firefox 48.0', 'chrome 65.0 for android', 'chrome 61.0', 'chrome 64.0 for ios', 'firefox', 'chrome 62.0 for android', 'Mozilla/Firefox', 'edge 17.0', 'chrome 46.0 for android', 'opera 53.0', 'edge 14.0', 'chrome 50.0 for android', 'chrome 62.0', 'edge 13.0', 'chrome 59.0', 'chrome 66.0', 'chrome 56.0', 'other', 'samsung browser 5.2', 'opera', 'chrome generic', 'samsung browser 5.4', 'chrome 53.0 for android', 'chrome 60.0', 'firefox 47.0', 'samsung browser 7.0', 'Cherry', 'firefox 57.0', 'chrome 55.0', 'BLU/Dash', 'seamonkey', 'chrome 65.0', 'firefox 55.0', 'firefox 58.0', 'puffin', 'chrome 54.0 for android', 'mobile safari 9.0', 'cyberfox'}\n",
      "id_33 261 {'3840x1080', '2561x1442', '600x450', '1760x990', '1679x1049', '2000x1125', '1440x759', '3840x2400', '1281x801', '2816x1584', '1344x756', '1364x768', '1599x899', '1805x1015', '1600x899', '5040x3150', '1023x768', '1280x1023', '1920x1081', '1280x768', '3201x1800', '2392x1440', '2100x1312', '976x600', '3841x2161', '2880x1440', '960x540', '1600x837', '2256x1504', '1184x720', '1600x1200', '1921x1080', '3600x2250', '2160x1215', '2735x1823', '1400x1050', '1440x899', '2436x1125', '1152x720', '1280x620', '2368x1440', '2400x1500', '1136x640', '3696x2310', '1366x768', '1024x819', '1280x900', '2304x1440', '1658x946', '2999x2000', '1360x768', '2160x1440', '1024x600', '855x480', '1536x864', '1365x767', '1344x840', '1912x1025', '2160x1081', '3072x1728', '1280x960', '2560x1600', '1280x1025', '1502x844', '4499x2999', '3200x1800', '2208x1242', '1440x810', '2560x1440', '2880x1442', '1624x1080', '921x691', '1638x922', '1024x640', '1480x720', '1768x992', '1422x889', '3839x2160', '1920x975', '2255x1503', '1368x768', '2710x1440', '640x360', '7500x5000', '5120x2880', '1680x1050', '2049x1536', nan, '2880x1620', '1120x700', '2001x1125', '1365x768', '3360x1890', '2520x1575', '1272x960', '1062x630', '2400x1350', '1848x1155', '3839x2159', '2010x1080', '6400x3600', '1776x1000', '1496x844', '1279x1023', '1280x800', '1920x1018', '4200x2625', '2159x1439', '1280x732', '1360x767', '6720x3780', '3000x2000', '2560x1080', '1680x1051', '1728x972', '768x576', '1232x800', '1200x675', '1439x900', '2160x1350', '1200x720', '1512x945', '1918x1080', '2736x1824', '1296x774', '2048x1280', '1025x768', '1920x1279', '1800x1125', '1440x803', '1441x901', '1536x960', '2816x1760', '1680x945', '1440x800', '1511x944', '1680x1049', '1280x1024', '2160x1080', '2220x1080', '0x0', '1281x800', '1024x767', '1439x899', '2160x1439', '1584x990', '1093x615', '3840x2160', '1919x1080', '3838x2158', '2048x1080', '1920x1080', '1138x640', '1720x1440', '2960x1440', '3840x2162', '1684x947', '2560x1800', '1366x767', '2736x1823', '1024x552', '3520x1980', '2048x1278', '1281x721', '2880x1800', '3838x2160', '1707x960', '2112x1188', '1229x691', '1152x864', '1264x924', '1824x1026', '5760x3240', '6016x3384', '1919x1079', '801x480', '3843x2163', '1152x648', '960x640', '2049x1152', '1776x1080', '1023x767', '1359x768', '1334x750', '1280x740', '3441x1440', '4500x3000', '1440x720', '3360x1050', '1280x712', '1920x1281', '2559x1439', '1366x1024', '1727x971', '1408x792', '1600x1000', '1279x1024', '1439x809', '1440x900', '2076x1080', '2961x1440', '2800x1575', '1920x1079', '1536x1152', '2159x1440', '1440x960', '1700x960', '2672x1440', '1920x1201', '2737x1825', '1400x900', '2400x1600', '1502x845', '1281x720', '3001x2000', '1408x880', '1919x1200', '4096x2304', '1280x720', '2552x1337', '1888x941', '2882x1442', '1916x901', '1596x710', '1371x857', '1188x720', '3200x2000', '480x320', '1920x1200', '1356x900', '2224x1668', '1920x1280', '1024x768', '1280x600', '2735x1825', '1919x1199', '2961x1442', '1239x697', '3199x1800', '2591x1619', '2560x1700', '2048x1536', '2700x1800', '3360x2100', '2559x1440', '1921x1081', '3840x1600', '1600x900', '2048x1152', '1600x1024', '2304x1296', '2562x1442', '2220x1081', '1092x614', '1599x900', '1729x973', '800x600', '3440x1440', '2732x2048', '5760x1080', '3240x2160'}\n",
      "id_34 5 {nan, 'match_status:2', 'match_status:1', 'match_status:0', 'match_status:-1'}\n",
      "id_35 3 {nan, 'F', 'T'}\n",
      "id_36 3 {nan, 'F', 'T'}\n",
      "id_37 3 {nan, 'F', 'T'}\n",
      "id_38 3 {nan, 'F', 'T'}\n",
      "DeviceType 3 {nan, 'mobile', 'desktop'}\n",
      "DeviceInfo 1787 {'SM-N910C Build/MMB29K', 'LG-V495', 'MacOS', 'NX16A8116KP', 'SM-A320Y', 'Mi', 'Hisense E51 Build/LMY47V', 'LG-M200 Build/NRD90U', 'SM-A510M Build/MMB29K', 'AX920', 'SAMSUNG SM-G900T Build/MMB29M', 'SAMSUNG SM-N920A Build/NRD90M', 'SM-G900P Build/MMB29M', 'SM-P605V', 'HTCD100LVWPP', 'SGP621 Build/23.5.A.1.291', 'KFSAWI', 'Pixel XL Build/OPM4.171019.016.B1', 'SAMSUNG SM-G530H Build/LRX22G', '5056N', 'XT1030 Build/SU6-7.7', 'SM-P550', 'SM-N920T Build/NRD90M', 'C6743 Build/LMY47V', 'SM-T350 Build/NMF26X', 'TA-1052', 'GT-I9195L', 'SM-G950U1 Build/R16NW', 'Coolpad', 'SAMSUNG SM-J700T1 Build/NMF26X', 'GRACE', 'BV6000', 'LG-D625', 'SM-G925T Build/NRD90M', 'SM-G900I', 'ZTE Blade L5 Build/LMY47I', 'VK810', 'XT1563 Build/MPD24.107-52', 'Ilium X520 Build/NRD90M', 'Microsoft', 'LG-D320', 'A3-A20', 'HTC U11 Build/NMF26X', 'SM-T810', 'LG-H320 Build/LRX21Y', '4047A Build/NRD90M', '5011A Build/NRD90M', 'SAMSUNG-SM-J320AZ', 'M4 SS4457-R Build/NRD90M', 'SM-G930R4 Build/NRD90M', 'SM-G965U Build/R16NW', 'CPH1723', 'SAMSUNG SM-N920V Build/NRD90M', 'SM-J320V Build/NMF26X', 'rv:29.0', 'Ilium X710 Build/MRA58K', 'Moto G Play Build/MPIS24.241-15.3-26', 'Hisense F24 Build/NRD90M', 'LGL62VL', 'SAMSUNG SM-G610M Build/NRD90M', 'BBA100-2', 'SAMSUNG SM-G950U Build/R16NW', 'SM-J500FN Build/MMB29M', 'Lenovo YT3-850M Build/MMB29M', 'Lenovo PB2-670Y Build/MRA58K', 'A9', 'SM-A310M Build/LMY47X', 'rv:14.0', 'E6633', 'LGMS631', 'LGL58VL', 'D6603', 'SM-G930F Build/NRD90M', 'Lenovo TB2-X30F Build/LenovoTB2-X30F', 'BLADE A520 Build/NRD90M', 'Star', 'Y550-L02', 'F3313 Build/37.0.A.2.248', 'Moto G (5) Build/NPP25.137-33', 'G3223 Build/42.0.A.4.167', 'SM-G960U Build/R16NW', 'SM-G9600 Build/R16NW', 'SM-G900H Build/MMB29K', 'XT1055', 'ZUUM_ZEN_I Build/LRX21M', 'SM-G935W8', 'B3-A20', 'X3402', 'SM-G920P', 'H1611', 'N817', 'TA-1004', 'ASUS_Z00ED', 'SAMSUNG SM-N920P Build/NRD90M', 'AM508', 'SAMSUNG SM-A720F Build/NRD90M', '5042A', 'SM-N910F Build/MMB29M', 'SM-G850M', 'HTC Desire 530 Build/MMB29M', 'XT1008', 'SAMSUNG SM-N920T Build/NRD90M', '8080 Build/LRX21M', 'F5321 Build/34.3.A.0.238', 'FIG-LX3 Build/HUAWEIFIG-LX3', 'SAMSUNG-SM-N920A', 'Pixel 2 Build/OPM1.171019.011', 'SM-T330NU Build/LMY47X', 'GT-S7580L Build/JDQ39', 'K92', 'Neffos X1 Max Build/NRD90M', 'Blade L2 Plus Build/KOT49H', 'RNE-L22 Build/HUAWEIRNE-L22', 'KFAPWI Build/KTU84M', 'SM-J7108', 'Kylin', 'SAMSUNG SM-N910A Build/MMB29M', 'Tmovi Build/Vision', 'rv:56.0', 'Redmi 3S Build/MMB29M', '47418', 'ICON', 'LG-H850', 'Ilium LT510 Build/MRA58K', 'LG-K530 Build/MMB29M', 'YOGA', 'XT1097', 'D6503', 'SM-G955U Build/R16NW', 'SM-G920P Build/NRD90M', 'LOGIC', 'Z831', 'E5803 Build/32.4.A.1.54', 'R2', 'SM-G925V Build/NRD90M', 'MotoG3-TE', 'V.40R', 'SAMSUNG-SM-J727AZ', 'SAMSUNG SM-J730GM Build/NRD90M', 'TA-1039 Build/N2G47H', 'MAMI', 'SAMSUNG SM-A300H Build/LRX22G', 'Ilium L610 Build/MRA58K', 'M4 SS4456 Build/LMY47V', 'SAMSUNG-SM-T817A', 'HUAWEI G7-L03 Build/HuaweiG7-L03', 'SM-T800 Build/MMB29K', 'XT1650 Build/NPLS26.118-20-5-11', 'G3223 Build/42.0.A.4.101', 'D2306 Build/18.6.A.0.182', 'SM-G925W8', 'ZA509', 'LGMS323', 'xs-Z47b7VqTMxs', 'B1-810', 'ATT', 'MotoG3 Build/MPI24.65-25', 'B1-750', 'LG-P708g', 'IO', 'STV100-1', 'ZTE-Z956', 'SAMSUNG SM-G930F Build/NRD90M', 'Moto G (5) Build/NPPS25.137-93-8', 'HUAWEI TAG-L13 Build/HUAWEITAG-L13', 'LGLS990', 'Moto G (5) Build/NPP25.137-82', 'SPH-L720', 'SM-J530G', 'SM-T813 Build/NRD90M', 'P5006A', 'moto g(6) play Build/OPP27.61-14-4', 'ASUS_X015D Build/NRD90M', 'verykools5004', 'SM-T237P', 'E6653 Build/32.4.A.1.54', 'SM-A300M Build/KTU84P', 'SM-N920G Build/NRD90M', 'LG-M430 Build/NRD90U', 'LG-K428 Build/NRD90U', 'SM-A510M Build/NRD90M', 'XT1053 Build/LPAS23.12-21.7-1', 'ASUS_Z00AD Build/LRX21V', 'K88 Build/MMB29M', 'SM-G928G Build/NRD90M', 'Moto C Build/NRD90M.046', 'Z970', 'rv:52.9', 'LG-TP450 Build/NRD90U', 'Aquaris X Build/NMF26F', 'SM-A730F Build/NMF26X', 'COVET Build/NRD90M', 'MYA-L11', 'SM-G901F', 'LG-H345', 'SM-T817T', 'LG-H520', 'SAMSUNG SM-N950U1 Build/R16NW', 'SM-S327VL', 'SM-N950F Build/NMF26X', 'LG-D213', 'M4 SS4458 Build/MMB29M', 'SM-S820L', 'LG-X210 Build/LMY47I', 'verykoolS5530 Build/LMY47I', 'M4 SS4451 Build/LMY47D', 'Minion_Tab', 'SAMSUNG SM-G965U1 Build/R16NW', 'SCH-I545 Build/LRX22C', 'LG-SP200', 'LG-H735 Build/LMY47V', 'VS880', 'ALCATEL ONE TOUCH 5036A Build/JDQ39', 'SM-G610M Build/NRD90M', 'SGH-I317M', 'BLU STUDIO C 5+5 Build/LRX21M', 'LG-H933', 'Lenovo TB-7703X Build/S100', 'M4 SS4452 Build/LMY47V', 'MotoG3-TE Build/MPDS24.65-33-1-3', 'ALE-L23 Build/HuaweiALE-L23', 'SAMSUNG SM-J710MN Build/MMB29K', 'XT1021 Build/KXC21.5-40', 'rv:53.0', 'VS425', 'SAMSUNG SM-J510MN Build/MMB29M', 'ZTE A2017U Build/NRD90M', 'HTC_Desire_820', 'Moto G Play Build/NJH47F', 'F3113 Build/33.2.A.4.70', 'LG-D331', 'SM-G730V', 'E5506 Build/29.2.A.0.166', 'Z833', 'SM-G903W', 'ASUS_X00DD', 'Alumini3 Build/MRA58K', 'Mi A1 Build/N2G47H', '8062 Build/MRA58K', 'LGLK430', 'VS990 Build/MRA58K', 'LGMS395', 'MYA-L23', 'LGMS345', 'ASUS_Z01BDC', '4027A Build/KOT49H', 'VS820', 'SM-G570F', 'SAMSUNG SM-T580 Build/NRD90M', 'Moto Z2 Play Build/NPS26.118-19', 'verykools4009', 'F5321 Build/34.2.A.2.47', 'H1711 Build/HUAWEIH1711', 'SLAY', 'VTR-AL00 Build/HUAWEIVTR-AL00', 'Moto E (4) Build/NDQS26.69-23-2-3', 'SM-T560NU Build/MMB29M', 'HTC6525LVW', 'KFTT Build/IML74K', 'Alcatel_4060A', 'Tab2A7-10F', 'Redmi', 'Azumi_KINZO_A5_QL', 'MotoG3 Build/MPIS24.107-55-2-17', 'SM-S907VL', 'LG-H340AR', 'SM-G928G', 'ONEPLUS A5010 Build/OPM1.171019.011', 'XT1650 Build/NPLS26.118-20-5-3', 'GT-I9506', 'F8331 Build/41.2.A.7.76', 'Swift', 'Moto Z2 Play Build/NPSS26.118-19-14', 'ASUS_Z00UD', 'SAMSUNG SM-G930A Build/NRD90M', 'D5503', 'LGMP260 Build/NRD90U', 'NXA8QC116', 'Hisense L675 Build/MRA58K', 'SM-G388F', 'HTC6500LVW', 'vivo', 'G3313 Build/43.0.A.5.79', 'Nexus 6 Build/MOB30M', 'SAMSUNG SM-G9650 Build/R16NW', '6039A Build/LRX22G', 'LGLS675 Build/LMY47V', 'SM-G850M Build/LRX22G', 'Lenovo', 'ONEPLUS', 'LG-M400 Build/NRD90U', 'SM-A310F Build/NRD90M', 'SM-A310M Build/NRD90M', 'MALC', 'CPH1607', 'moto x4 Build/NPW26.83-42', 'Redmi 5 Plus Build/N2G47H', 'ASTRO', 'QTAIR7 Build/LMY47D', 'G3123', 'LG-X180g Build/LMY47I', 'Windows NT 6.2', 'SM-T377P', 'Nexus 6P Build/OPR5.170623.011', 'BLN-L21 Build/HONORBLN-L21', 'UL40', 'Z798BL Build/MMB29M', 'STV100-4 Build/LMY47V', 'SM-N920T', 'SAMSUNG SM-G920I Build/NRD90M', 'SM-J510FN', 'Z837VL', 'Intel', 'Moto G (5) Plus Build/NPNS25.137-93-8', 'SAMSUNG SM-G531H Build/LMY48B', 'moto x4 Build/OPWS27.57-40-6', 'Aquaris X5 Plus Build/NMF26F', 'ASUS_P00J', 'SAMSUNG SM-T800 Build/MMB29K', 'SAMSUNG SM-A510M Build/MMB29K', 'LG-H500 Build/LRX21Y', 'GT-I9515', 'LG-V700', 'LG-K330', 'KFMEWI', 'LG-H830', 'SAMSUNG SM-N900T Build/LRX21V', 'Ilium L1000 Build/LRX22G', 'LG-H542 Build/MRA58K', 'TOMMY2', 'HUAWEI Y560-L03 Build/HUAWEIY560-L03', 'QTASUN1 Build/NRD90M', 'HT0703K16', 'BNTV400', 'HTC Desire 650 Build/MMB29M', 'LG-K428 Build/MMB29M', 'SM-J500M Build/MMB29M', 'SM-G900T1', 'Moto G Play Build/NPIS26.48-36-5', 'LGMS550 Build/MXB48T', 'SM-T818V', 'RNE-L23 Build/HUAWEIRNE-L23', 'rv:41.0', 'SAMSUNG-SM-G935A', 'SM-T210', 'SAMSUNG-SM-N920A Build/NRD90M', 'LG-M320 Build/NRD90U', 'Touch', 'VTR-L09 Build/HUAWEIVTR-L09', 'SM-G935F Build/MMB29K', 'SAMSUNG SM-G935A Build/NRD90M', 'LGLS751', 'S.N.O.W.4', 'XT1575 Build/NPHS25.200-23-1', 'XT1635-02', 'Nexus 5X Build/OPR4.170623.006', 'rv:52.0', 'SAMSUNG SM-J327AZ Build/NRD90M', 'XT1032', 'ZUR70016', 'Z2', 'LG-H872 Build/NRD90U', 'SLA-L23', 'XT1575', 'XT1096', 'BLU', 'Fractal', 'LG-X220 Build/LMY47I', 'XT1068', 'MotoG3-TE Build/MPD24.65-33', 'SM-P600', 'Moto Z2 Play Build/NPS26.74-16-1', 'SM-G530W', 'HTC6535LVW', 'SM-J710GN', '4034G', 'XT1650', 'Android 5.1.1', 'SM-G920T', 'SM-G386T', 'SAMSUNG-SM-G928A Build/NRD90M', 'SM-G955U Build/NRD90M', 'SM-T537V', 'SM-G920R4', 'SM-G920T Build/NRD90M', 'SM-J700T Build/MMB29K', 'A1-850', 'XT1031', 'CPH1701', 'SM-T800', 'Moto G (4) Build/NPJS25.93-14-8', '0PM92', '5095I Build/MRA58K', 'SGH-I337M Build/LRX22C', 'SM-J500M Build/LMY48B', 'SAMSUNG-SGH-I537', 'PH-1', 'LG-H812', 'Windows NT 6.1', 'SM-J510F', 'SM-G935T Build/NRD90M', 'LG-V496', 'SM-T827R4', 'SAMSUNG-SM-G530AZ Build/LMY48B', 'STK_Sync_5e', 'SM-G950U Build/R16NW', 'LGL164VL Build/NRD90U', 'Moto C Build/NRD90M.054', 'SM-G928T Build/NRD90M', 'Blade V6 Plus Build/MRA58K', 'BV7000', 'SM-P350 Build/MMB29M', 'A97', 'G25524K', 'LG-D681', 'E2104 Build/24.0.A.5.14', 'TA-1028 Build/NRD90M', 'LG-LS997 Build/NRD90M', 'LG-K550', 'RCT6303W87M7 Build/MRA58K', 'SM-T555', 'TA-1044', 'SAMSUNG SM-J530GM Build/NRD90M', 'SM-P355M Build/MMB29M', 'SM-G360T1 Build/LMY47X', 'PRA507', 'G3313', 'LG-D850', 'SAMSUNG SM-A310F Build/NRD90M', 'SM-J700H Build/MMB29K', 'HUAWEI Y360-U23 Build/HUAWEIY360-U23', 'SM-N910T Build/LMY47X', 'VTR-L29', '5010S Build/MRA58K', 'STELLAR', 'E6683', 'SM-G930T Build/NRD90M', 'SAMSUNG SM-N950U1 Build/NMF26X', 'LG-K240 Build/MXB48T', 'Turbo C5 Build/LMY47I', 'Trident/7.0', 'Lenovo TB3-710I Build/LMY47I', 'H3321', 'Blade V580 Build/LMY47D', 'SM-G925I Build/NRD90M', 'Z982 Build/NMF26V', 'SAMSUNG-SM-N900A Build/LRX21V', 'HTC One M9 Build/NRD90M', 'M4', 'M10/Q1010', 'SAMSUNG-SM-G890A Build/NRD90M', 'm3', 'SAMSUNG SM-G800F Build/MMB29K', 'SAMSUNG SM-A320FL Build/NRD90M', 'GT-S7275B', 'U', 'ASUS_X018D', 'F5121 Build/34.3.A.0.228', 'BBB100-2', 'LG-D725', 'MHA-L29 Build/HUAWEIMHA-L29', 'Hisense', 'Moto G (4) Build/NPJS25.93-14-18', 'SGH-M919N', 'SM-G955W', 'Z813 Build/LMY47O', 'Fusion5_u7', 'MI MAX 2 Build/NMF26F', 'SM-G7105', 'E2104', 'Helix', 'FRD-L04 Build/HUAWEIFRD-L04', 'LG-D959', 'Moto G (5) Plus Build/NPNS25.137-92-4', 'SM-G530T1', 'SM-G935P Build/NRD90M', 'Max', 'rv:50.0', 'Pixel 2 XL Build/OPM2.171019.029', 'Blade A475 Build/LMY47D', 'SM-P580 Build/NRD90M', 'ZEIA8', 'SM-G930W8 Build/NRD90M', 'SAMSUNG SM-G950F Build/R16NW', 'moto x4 Build/OPW27.57-40', 'HT0701A16', 'Moto Z (2', 'SM-G530P', 'VerykoolS5030', 'SM-G570M Build/NRD90M', 'SAMSUNG-SM-G925A Build/NRD90M', 'E6603 Build/32.4.A.1.54', 'SM-G950F Build/NRD90M', 'Pixel XL Build/OPM1.171019.016', 'SM-J701M Build/NRD90M', 'GRANT', 'rv:49.0', 'MotoE2 Build/LPCS23.13-56-5', 'Alcatel', 'SM-T560NU Build/NMF26X', 'Pixel Build/OPM4.171019.016.B1', 'F5122', 'VS988 Build/NRD90U', 'SM-N910H', 'Moto G (4) Build/NPJS25.93-14-8.1-4', 'iris50', 'MOT-A6020l37 Build/LMY47V', 'P5526A Build/NRD90M', '2PZC5', 'BV8000Pro', 'Lenovo TB-X103F Build/LenovoTB-X103F', 'F5121 Build/34.3.A.0.252', 'LG-M150', 'Ilium', 'WAS-TL10 Build/HUAWEIWAS-TL10', 'SM-G928V Build/MMB29K', 'LGL33L/V100', 'LGL52VL Build/LMY47V', 'LG-D400', 'SAMSUNG SM-G950F Build/NRD90M', 'SM-T817V Build/NRD90M', 'BAC-L03 Build/HUAWEIBAC-L03', 'SM-G610F Build/NRD90M', 'SLA-L03 Build/HUAWEISLA-L03', 'SM-T530 Build/LRX22G', 'TA-1028 Build/NMF26O', 'SM-A520F Build/R16NW', 'M431', 'SAMSUNG-SM-T377A', 'LG-M153 Build/MXB48T', 'SAMSUNG SM-A310F/A310FXXU4CRB1 Build/NRD90M', 'R8106', 'LG-LS998', 'D5306', 'LGUS215 Build/NRD90U', 'Moto G (5) Build/NPP25.137-38', 'Redmi Note 4 Build/NRD90M', 'RS988', 'C6903', 'SM-G530T', 'Android 7.0', 'SM-G800F Build/KOT49H', 'SM-J510MN Build/MMB29M', 'SM-G930R7', 'HTC Desire 10 lifestyle Build/MMB29M', 'RNE-L03 Build/HUAWEIRNE-L03', 'iris702', 'XT1572 Build/NPHS25.200-15-8', 'SM-J320H', 'VFD', 'XT1254', 'SM-G550T2', 'E6810', 'Lenovo YT3-X50F Build/MMB29M', 'G3123 Build/40.0.A.6.175', 'DUK-AL20', 'SM-T285M', 'SM-G925I Build/MMB29K', 'SAMSUNG SM-G850F/G850FXXS2CQD9 Build/LRX22G', 'D5306 Build/19.4.A.0.182', 'KFDOWI Build/LVY48F', 'SAMSUNG SM-J320F Build/LMY47V', 'ASUS_Z01BDA', 'SM-N900W8 Build/LRX21V', 'LG-K420', 'LG-X240 Build/MRA58K', 'LGLS676 Build/MXB48T', 'SAMSUNG SM-A730F Build/NMF26X', 'A466BG', 'ALE-L21 Build/HuaweiALE-L21', 'AX821 Build/MRA58K', '4034E', 'SM-G9250', 'MotoE2(4G-LTE', 'Pixel 2 Build/OPM1.171019.019', 'HTC One_M8 Build/MRA58K', 'QTAQZ3 Build/LMY47V', 'rv:31.0', 'LIMIT', 'BLADE V8 SE Build/NRD90M', 'SM-G900M Build/KOT49H', 'SAMSUNG SM-G955U Build/NRD90M', 'MI', 'SKY_5.0LM', 'Moto C Build/NRD90M.063', 'XT1254 Build/MCG24.251-5-5', 'LGUS992', 'Z9 PLUS Build/NRD90M', 'SM-J500H', 'Neffos C5 Build/LMY47D', 'ALCATEL ONE TOUCH 7042A Build/JDQ39', 'Moto G (5) Plus Build/NPN25.137-92', 'LG-H650 Build/MRA58K', 'KFSUWI Build/LVY48F', 'LG-H870 Build/NRD90U', 'Moto G (5) Plus Build/NPN25.137-15', 'LG-H910 Build/NRD90M', 'E6833', 'Moto C Build/NRD90M.057', 'rv:38.0', 'HTC_One', 'SM-J320M Build/LMY47V', 'SM-G530H Build/KTU84P', 'SM-A520W', 'BBB100-3', 'Moto G (5) Build/NPP25.137-15', 'LG-H870DS Build/NRD90U', 'SM-G928V', 'HIGHWAY', 'SAMSUNG SM-G935F Build/MMB29K', 'Moto G (5) Build/NPP25.137-93', 'Ilium X220 Build/MRA58K', 'F3213', 'WAS-LX1A Build/HUAWEIWAS-LX1A', 'TA-1038 Build/NMF26O', 'SPH-L720T', 'iPhone', 'rv:59.0', 'SM-A510F Build/MMB29K', 'Pixel 2 Build/OPM1.171019.021', 'TREKKER-X3 Build/MMB29M', 'hi6210sft Build/MRA58K', 'Alumini3Plus', 'SAMSUNG SM-G950U1 Build/R16NW', 'SM-S906L', 'PLUS', 'TA-1044 Build/NMF26F', 'A37f', 'LG-V930', 'LGMS330 Build/LMY47V', 'Lenovo K33b36 Build/MMB29M', 'SM-J320W8', 'SM-T330', 'SM-A800I', 'moto x4 Build/NPW26.83-18-2-0-4', 'RCT6223W87', 'Linux', 'Moto G Play Build/NPI26.48-36', '9203A Build/MRA58K', 'LG-D320 Build/KOT49I.V10a', 'TA-1027', 'LG-LK460', 'Blade A465 Build/LMY47D', 'BBB100-1', 'Edison', 'Stellar', 'D6708', 'Blade V6 Max Build/MRA58K', 'Hisense F32 Build/NMF26F', 'LG-H700 Build/NRD90U', 'SM-G950U1 Build/NRD90M', 'SM-N920P Build/NRD90M', 'LG-H830 Build/NRD90U', 'F3313', 'Aquaris U Plus Build/NMF26F', 'rv:45.0', 'VS880PP', 'XT1680', 'Moto G (5) Plus Build/NPNS25.137-15-11', 'LGLS775 Build/MMB29M', 'SM-J200H', 'Joy', 'BLL-L23 Build/HUAWEIBLL-L23', 'Moto X Play Build/NPD26.48-24-1', 'LGL57BL', 'Lenovo YT3-850F Build/MMB29M', 'Blade L5 Build/LMY47I', 'ONE', 'SM-A530F Build/NMF26X', 'WAS-LX3 Build/HUAWEIWAS-LX3', 'SCH-I535', 'HTC One A9s Build/MRA58K', 'Z981 Build/MMB29M', 'TA-1003', 'rv:35.0', 'Moto G (5) Plus Build/NPNS25.137-92-10', 'E5306 Build/27.3.A.0.165', 'SM-G900P', 'G8141 Build/47.1.A.5.51', 'GT-N5110 Build/JDQ39', 'SM-J727P', 'SAMSUNG SM-A710M Build/NRD90M', 'LG-F400K', 'LG-H850 Build/MMB29M', 'KFSOWI', 'Moto E (4) Plus Build/NMA26.42-152', 'LG-M250 Build/NRD90U', 'LG-K350', 'Linux i686', 'XT1563', 'SAMSUNG SM-G935P Build/NRD90M', 'HTC_One_M8/4.28.502.2', 'LG-H525n Build/MRA58K', 'F3213 Build/36.1.A.1.86', '9022X', 'LGL163BL', 'SAMSUNG SM-G950U Build/NRD90M', 'Moto Z2 Play Build/NPSS26.118-19-4', 'moto x4 Build/OPWS27.57-40-14', 'XT1058', 'LG-LS777 Build/NRD90U', 'SM-J120W', 'BOIE9', '6037B', 'FRD-L14 Build/HUAWEIFRD-L14', 'SAMSUNG SM-G935F Build/NRD90M', 'G527-U081', 'F3311', 'LGUS990', 'SM-P900', 'LG-SP320', 'SM-N950U Build/R16NW', 'SAMSUNG-SM-G890A Build/MMB29K', 'S471', 'LG-H443/H44312g', 'SM-P600 Build/LMY47X', 'SM-J700M Build/MMB29K', 'SM-G935T', 'SAMSUNG SM-G900F Build/MMB29M', 'C6906 Build/14.6.A.1.236', 'NetHelper70', 'LG-P714', 'CLT-L09', '5012G Build/MRA58K', 'EVA-L19 Build/HUAWEIEVA-L19', 'TA-1027 Build/OPR1.170623.026', 'SAMSUNG-SM-J327A Build/NRD90M', 'SAMSUNG SM-J500FN Build/MMB29M', 'SM-G9650 Build/R16NW', 'F3313 Build/37.0.A.2.108', 'Lenovo A2016b30 Build/MRA58K', 'iOS Device', 'Android 6.0', 'GT-I9060M Build/KTU84P', '5054S Build/LMY47V', 'Moto G (5) Build/NPPS25.137-93-4', 'SAMSUNG-SM-G920A Build/NRD90M', 'SM-J727V Build/NRD90M', 'SM-G925I', 'VS5012 Build/NRD90M', 'ASUS_Z017DA', 'SM-G955F', 'AX1060', 'LG-H918 Build/NRD90M', 'GT-N8010', 'Alcatel_5044R Build/NRD90M', 'LGMS631 Build/MRA58K', 'SM-T113 Build/KTU84P', 'SAMSUNG SM-G920F Build/LRX22G', 'SM-G930U Build/NRD90M', 'SAMSUNG SM-J500M Build/MMB29M', 'IdeaTab', 'VS500', 'Energy X 2 Build/E050L', 'TA-1032', 'LG-M210 Build/NRD90U', 'SAMSUNG SM-G920T Build/NRD90M', 'T1', 'SP7731G', 'SM-T710 Build/NRD90M', 'XT1072', 'Pixel', 'LG-D802', '9002A', 'LG-E450f', 'rv:55.0', 'Build/KOT49H', 'A952', 'SM-T113NU Build/KTU84P', 'SAMSUNG SM-G920F Build/NRD90M', 'Alcatel_4060O Build/MMB29M', 'P5006A Build/NRD90M', 'SM-A520F Build/MMB29K', 'SM-T670', 'Nexus 5X Build/OPM3.171019.013', 'BLADE V8Q Build/N2G47H', 'GT-P5210 Build/KOT49H', 'LG-H650 Build/LMY47V', 'SM-G900L', 'SM-J120M', 'Build/OPM1.171019.011', 'LG-M154', 'Alcatel_5056O', 'SM-G531H Build/LMY48B', 'LGLS665 Build/LMY47V', 'IdeaTabA1000-F', 'SM-A300H', 'VS501 Build/NRD90U', 'LG-V521', 'SAMSUNG SM-G955F Build/NRD90M', 'SAMSUNG SM-G930T Build/NRD90M', 'SAMSUNG SM-G925F Build/NRD90M', 'XT1060', 'rv:48.0', 'SM-G900V', 'rv:37.0', 'verykoolS5019', 'G8141', 'rv:43.0', 'XT1092', 'Lenovo TB3-710F Build/LRX21M', 'SM-A520F Build/NRD90M', 'F3113 Build/33.2.A.3.81', 'LG-D851', 'TA-1020', 'SM-G386W', 'SM-G930T', 'LG-LG870', 'SM-G925R4', '5010G Build/MRA58K', 'GT-I8200N', 'E5606', 'XT1080', 'LG-E980h', 'XT1580', 'MDDRJS', 'TR10CS1 Build/JDQ39', 'SAMSUNG SM-G930R4 Build/NRD90M', 'GT-I8190L Build/JZO54K', 'SM-T377T', 'LG-LS995', '0PAJ5', 'SAMSUNG SM-G900M Build/LRX21T', 'Moto E (4) Build/NMA26.42-69', 'HTC_One_M8s/2.12.111.1', 'SM-G950U Build/NRD90M', 'LG-H221', 'SAMSUNG SM-J320M Build/LMY47V', 'SM-G900F Build/MMB29M', 'XT1563 Build/MPD24.65-25', 'HUAWEI Y520-U03 Build/HUAWEIY520-U03', 'SM-T310 Build/KOT49H', 'ZA990', 'SAMSUNG SM-J701M Build/NRD90M', 'KIW-L24', 'M4 SS4453 Build/MMB29M', 'SM-G900F Build/KOT49H', 'SM-N900T', 'ALP-L09 Build/HUAWEIALP-L09S', 'SM-G920I', 'SM-G530H Build/LRX22G', 'SAMSUNG-SM-J727A Build/NRD90M', 'Moto E (4) Plus Build/NMA26.42-11-3', '5056A Build/MMB29M', 'LG-D722', 'SAMSUNG SM-N900W8 Build/LRX21V', 'Blade', 'E5606 Build/30.2.A.1.21', 'XT1650 Build/NCLS26.118-23-13-6-5', 'Redmi 4X Build/N2G47H', 'SAMSUNG SM-J327A Build/NRD90M', 'Z956 Build/MMB29M', 'Lenovo PB2-650Y Build/MRA58K', 'Moto G (4) Build/NPJS25.93-14-13', 'Lenovo K33b36 Build/NRD90N', 'verykoolS5525', 'XT1063 Build/MPB24.65-34-3', 'G8142', 'SM-N950U Build/NMF26X', 'HUAWEI Y625-U13 Build/HUAWEIY625-U13', 'SM-G350M', 'SM-J100VPP Build/LMY48B', 'verykoolS5524', 'SM-T377P Build/NMF26X', 'E5803', 'SM-J110M Build/LMY48B', 'SAMSUNG SM-G960U Build/R16NW', 'SAMSUNG-SM-G930A', 'XT1710-02 Build/NDSS26.118-23-19-6', 'SM-N920C Build/NRD90M', 'D5316', 'es-us', 'SM-G900V Build/MMB29M', 'LG-D680', 'CRO-L03 Build/HUAWEICRO-L03', 'SM-J710F Build/NRD90M', '6045I Build/LRX22G', 'SM-G955F Build/NRD90M', 'Win64', 'LG-D693n Build/LRX22G', 'LGLS992', '7055A Build/KVT49L', 'MotoG3 Build/MPI24.65-25.1', 'BLADE L7 Build/MRA58K', 'Aquaris V Build/N2G47H', 'SAMSUNG SM-G965U Build/R16NW', 'Android 5.1', 'SAMSUNG SM-G610M Build/MMB29K', '831C', 'SM-N9005 Build/LRX21V', 'LG-V522', 'SM-T377W', 'SM-J120H Build/LMY47V', 'SM-T355Y Build/NMF26X', 'E5306 Build/27.3.A.0.129', 'G3123 Build/40.0.A.6.135', 'SM-N910T3', 'SM-T280 Build/LMY47V', 'LGMS550 Build/NRD90U', 'ASUS_A001', 'F80 PIABELLA Build/MRA58K', 'en-gb', 'LG-V500', 'SM-A510M Build/LMY47X', 'SAMSUNG SM-G532M Build/MMB29T', 'V502015', 'Moto G (4) Build/NPJ25.93-14.7', 'SAMSUNG-SM-G925A Build/MMB29K', 'SM-J727U Build/NRD90M', 'SM-A710M Build/LMY47X', 'Moto G (4) Build/NPJ25.93-14.5', 'SM-G928F', 'SM-G925F Build/NRD90M', 'LG-X230 Build/MRA58K', 'SM-T560 Build/KTU84P', 'SM-G920F Build/MMB29K', 'Moto C Plus Build/NRD90M.05.022', 'S70V', 'LG-D680 Build/KOT49I', 'SM-N9500', 'verykoolS5005', 'WAS-LX1 Build/HUAWEIWAS-LX1', '4009F', 'ASUS', 'R831L', 'B3-A40', 'LG-LS993 Build/NRD90U', 'LG-X165g Build/LRX21M', 'SM-G930T1', 'iris80', 'SAMSUNG-SM-T807A', 'REVVLPLUS', 'LG-K500 Build/MMB29M', 'BBA100-1', 'KFASWI Build/LVY48F', 'SM-G360M', 'SM-A500H', 'XT1563 Build/MPDS24.107-52-5', 'QwestIE8', 'SM-P607T', 'SAMSUNG-SM-G920AZ', 'ZTE BLADE A321 Build/NMF26F', 'Z971', 'Le', 'Lenovo TAB 2 A7-30GC Build/KOT49H', 'Hisense F102 Build/NRD90M', 'SAMSUNG SM-G570M Build/NRD90M', 'VS996', 'Moto G (5) Plus Build/NPN25.137-83', 'SM-N910P', 'Moto G (4) Build/NPJS25.93-14-15', 'Hisense F20 Build/MMB29M', 'Z410', 'Redmi Note 3 Build/MMB29M', 'BLADE V7 Build/MRA58K', 'SM-G900R4', 'Y635-L03 Build/HuaweiY635-L03', 'ZTE BLADE A6 Build/NMF26F', 'SM-P355M', 'XT1635-01', 'VS425PP Build/LMY47V', 'LG-H811 Build/MRA58K', 'ALP-L09 Build/HUAWEIALP-L09', 'SM-G928V Build/NRD90M', 'LDN-LX3 Build/HUAWEILDN-LX3', 'SM-T807V', 'HTC 10 Build/NRD90M', 'SM-G950F Build/R16NW', 'LGMP450 Build/NRD90U', 'Grand', 'E5306', 'G630-U251', 'SM-T530', 'SM-G360V', 'SM-G390F', 'SM-G955U1 Build/R16NW', 'Bolt', 'SM-J700P', 'Nexus 6 Build/N6F27M', 'LGUS991', 'SM-G318ML', 'Z955A', 'SM-G928G Build/MMB29K', 'SM-T110 Build/JDQ39', 'R1', 'SM-T530NU Build/LRX22G', 'SAMSUNG-SM-G900A Build/MMB29M', 'G3123 Build/40.0.A.6.189', 'IdeaTabA2109A', 'SM-T337V', 'Hisense U963 Build/MRA58K', 'SM-G920I Build/NRD90M', 'LG-K530 Build/NRD90U', 'HTC6545LVW', 'Archos', 'SAMSUNG-SGH-I337', 'Nexus 6P Build/OPR5.170623.014', 'SM-T810 Build/NRD90M', 'P00A', \"F80'S+\", 'SM-G530FZ', 'SM-N910T Build/MMB29M', 'Aquaris_A4.5', 'K10', 'SAMSUNG-SM-T337A Build/LMY47X', 'SAMSUNG SM-P580 Build/NRD90M', 'SM-G935F Build/NRD90M', 'XT1040', 'SM-N950U1 Build/R16NW', 'SM-T700 Build/MMB29K', 'LG-D693n', 'SM-G550T Build/MMB29K', 'PLK-L01 Build/HONORPLK-L01', 'T08', 'SAMSUNG SM-J700T Build/NMF26X', 'AKUS', 'E5506 Build/29.1.A.0.101', 'Z835 Build/NMF26V', 'PSPC550 Build/LMY47D', 'C1904', 'HUAWEI CAN-L11 Build/HUAWEICAN-L11', 'Pixel Build/OPR3.170623.013', 'Robin', 'SM-G920W8', 'Nexus 5 Build/M4B30Z', 'SM-N900V Build/LRX21V', 'Pixel 2 XL Build/OPM1.171019.021', 'S6000', 'SM-A720F Build/NRD90M', 'ONE TOUCH 4016A Build/JDQ39', 'SAMSUNG SM-N910V Build/MMB29M', 'en-us', 'SM-S320VL', 'SM-G355M Build/KOT49H', 'XT1528', 'SM-E500M', 'SM-A320FL Build/NRD90M', 'SM-G610F', 'SAMSUNG-SM-J320A Build/MMB29K', 'hp2015', 'HUAWEI', 'SAMSUNG SM-G9600 Build/R16NW', 'A50C+', 'SAMSUNG SM-N950F Build/NMF26X', 'SM-G531F', 'GT-P5210 Build/JDQ39', 'Alcatel_5098O Build/MMB29M', 'F8332', 'Nexus', 'GT-N8000', 'PLE-701L', 'A621R', 'Windows', 'SM-S920L', 'SM-G960F Build/R16NW', 'SM-T230 Build/KOT49H', 'NX785QC8G', 'LG-V520', 'Pixel 2 XL Build/OPM1.171019.013', 'TA-1038 Build/O00623', 'XT1064 Build/MPB24.65-34-3', 'Moto G (5) Build/NPPS25.137-15-11', 'YOLO', '5080A Build/MRA58K', 'XT1033', 'rv:46.0', 'Dream', 'VS835', 'SM-G720AX', 'Z963VL', 'Dash', 'LG-H820', 'XT1225', '5057M', 'Moto G Play Build/NPIS26.48-36-2', 'RCT6513W87 Build/MRA58K', 'Moto E (4) Build/NDQS26.69-64-2', 'E8QP', 'BLU LIFE XL Build/L050U', 'SAMSUNG-SM-N910A', 'Moto E (4) Plus Build/NMA26.42-69', 'TA-1044 Build/OPR1.170623.026', 'XT1080 Build/SU6-7.7', 'MotoG3 Build/MPIS24.65-25.1-19', 'PULP 4G Build/LMY47V', 'Hisense F8 MINI Build/NRD90M', 'ONE TOUCH 4033A Build/JDQ39', 'SM-S550TL', 'rv:33.0', 'SM-A710M', 'LG-K410 Build/LRX22G', 'SM-J320FN Build/LMY47V', 'XT1094', 'SAMSUNG SM-T813 Build/NRD90M', 'MHA-L09 Build/HUAWEIMHA-L09', 'SM-A300M', 'F5121 Build/34.4.A.2.19', 'LG-M700 Build/NMF26X', 'ASUS_X008D Build/NRD90M', 'Z832 Build/MMB29M', 'Ilium LT500 Build/LMY47O', 'LS5', 'LenovoA3300-GV Build/JDQ39', 'rv:11.0', 'STV100-2 Build/MMB29M', 'P5026A', 'HP', 'Android', 'WOW64', 'XT1032 Build/LPBS23.13-56-2', 'ALCATEL', 'VK815', 'Android 7.1.2', 'ILIUM', 'F3113 Build/33.3.A.1.97', 'XT1023', 'LG-M710 Build/NRD90U', 'LG-H840 Build/MMB29M', 'GT-N5110', 'C2104', 'WAS-LX2J', 'SM-J111M Build/LMY47V', 'SAMSUNG SM-G892A Build/NRD90M', 'BLADE A602 Build/MRA58K', 'Moto G (4) Build/NPJS25.93-14-10', 'SAMSUNG SM-G950U1 Build/NRD90M', 'SM-J330FN Build/NRD90M', 'SAMSUNG SM-A310M Build/LMY47X', 'LG-K212', 'BND-L34', 'LT30p', '5045I', 'E6853', 'Gravity Build/NRD90M', 'SAMSUNG', 'LG-D693n Build/KOT49I.V10a', 'SM-N920P', 'Moto G (5) Plus Build/NPN25.137-82', 'P01M', 'XT1635-01 Build/NDNS26.118-23-12-3', '1016S', 'SM-G965F Build/R16NW', 'LG-H810/H81021z', 'SAMSUNG-SM-J320AZ Build/MMB29K', 'Pixel 2 XL Build/OPM2.171019.029.B1', 'Ilium LT520 Build/NRD90M', 'SC-02H', 'DASH', 'LG-H815 Build/MRA58K', 'E2303', 'SM-S903VL', 'SM-G955U1 Build/NRD90M', 'VS995 Build/NRD90M', 'SM-J730G Build/NRD90M', 'DT0704K08', 'ANE-LX3 Build/HUAWEIANE-LX3', 'D5106', 'SM-J700T1', 'Beat', 'SM-G800M Build/KOT49H', 'KFFOWI Build/LVY48F', 'SM-G920V', 'SM-T825 Build/NRD90M', 'Blade V6 Build/LRX22G', 'SAMSUNG-SGH-I337 Build/KOT49H', 'TRT-L53 Build/HUAWEITRT-L53', 'iris 870 Build/MRA58K', 'BLN-L24 Build/HONORBLN-L24', 'SM-G935V', 'ZTE Blade A511 Build/MRA58K', 'ZTE BLADE A512 Build/MMB29M', 'F3111 Build/33.3.A.1.97', 'SM-J710MN Build/NRD90M', 'TA-1027 Build/N2G47H', 'U FEEL LITE Build/MRA58K', 'SM-G930V Build/NRD90M', 'SM-J700T1 Build/NMF26X', 'SM-J327P Build/MMB29M', 'SM-T705', 'rv:61.0', 'HUAWEI GRA-L09 Build/HUAWEIGRA-L09', 'SM-A500M Build/LRX22G', 'MTT', 'ALTER', 'LG-K200 Build/MXB48T', 'KFTBWI Build/LVY48F', 'Hisense T963 Build/MRA58K', 'Build/OPR6.170623.013', 'SM-G532M Build/MMB29T', 'ONE A2003 Build/MMB29M', 'SAMSUNG-SM-J120A', 'XT1095', 'WAS-L03T Build/HUAWEIWAS-L03T', 'F3213 Build/36.0.A.2.146', 'E2306 Build/26.3.A.1.33', 'SAMSUNG SM-G935T Build/NRD90M', 'ALCATEL ONE TOUCH 7047A Build/JDQ39', 'SM-A510F Build/NRD90M', 'AX705', 'K88', 'SM-G930P Build/NRD90M', 'TRT-LX3', 'Pixel Build/OPM1.171019.016', 'SAMSUNG SM-G530T Build/LMY47X', 'SM-A720F Build/MMB29K', 'Moto E (4) Build/NCQ26.69-56', 'EGO', 'XT1021', 'AERIAL Build/NRD90M', 'SAMSUNG-SM-T677A', 'XT1021 Build/LPCS23.13-34.8-3', 'verykools5034', 'M4 SS4457 Build/MRA58K', 'MotoG3', 'S60 Build/MMB29M', 'G8341', 'FEVER', 'ATT-IE11', 'XT1565', 'HTC One mini Build/KOT49H', 'SM-G930VL Build/NRD90M', '4047G Build/NRD90M', 'LGLS755', 'SAMSUNG SM-J727T1 Build/NRD90M', 'XT1710-02', 'PRA-LX1 Build/HUAWEIPRA-LX1', 'KYY22', 'SAMSUNG SM-G570M Build/MMB29K', 'LG-K540 Build/MMB29M', 'TA-1025 Build/OPR1.170623.026', 'E501', 'Ilium L1120 Build/NRD90M', 'GT-S7582', 'HTC Desire 526G Build/KOT49H', 'LG-E975', 'rv:47.0', 'A96 Build/LMY47I', 'D2306', 'SM-T580', 'Moto', 'SAMSUNG-SM-G900A', 'XT1063', 'LG-H820 Build/NRD90U', 'SM-A520W Build/NRD90M', 'BLU ENERGY X PLUS Build/LRX21M', 'SAMSUNG SM-A510F Build/NRD90M', 'rv:60.0', 'E5823 Build/32.4.A.1.54', 'TREKKER-M1', 'GT-N7100', 'Ilium L950 Build/KTU84P', 'SM-G800F Build/MMB29K', 'EML-L29 Build/HUAWEIEML-L29', 'HUAWEI CAN-L01 Build/HUAWEICAN-L01', 'LG-H932', 'SM-G903F Build/MMB29K', '5085B Build/MRA58K', 'SGH-I337M', 'Tornado', 'FTJ152D', 'ALCATEL ONE TOUCH 7040A Build/JDQ39', 'PMID7102DC', 'SM-A500FU Build/MMB29M', 'ORION', 'SLA-L22', 'BLA-L09 Build/HUAWEIBLA-L09', '9003A Build/MRA58K', 'PLAYTAB', 'LEX829', 'SGP511', 'ONEPLUS A5000 Build/NMF26X', 'DOMOS', 'SAMSUNG SM-G955U Build/R16NW', 'Blade L3 Build/KOT49H', 'KFGIWI Build/LVY48F', 'E2306 Build/26.1.A.3.111', 'SM-J200M Build/LMY47X', 'LGLS770', 'Lenovo A6020l37 Build/LMY47V', 'SAMSUNG SM-G925T Build/NRD90M', 'SM-N900T Build/LRX21V', 'SAMSUNG SM-J320FN Build/LMY47V', 'F8331', 'H550', 'LG-D373', '4013M Build/KOT49H', 'B1-790', 'ASUS_Z01KD', 'SM-G930V Build/MMB29M', 'SM-E700M', 'SGH-I747M', 'SAMSUNG SM-T710 Build/NRD90M', 'RCT6203W46 Build/KOT49H', 'EVA-L09 Build/HUAWEIEVA-L09', 'SM-T520', 'VS986 Build/MRA58K', 'F3111 Build/33.3.A.1.115', 'LG-H960', 'LG-H900/H90022b', 'HUAWEI RIO-L03 Build/HUAWEIRIO-L03', 'SAMSUNG SM-T530NU Build/LRX22G', 'XT1609 Build/NPIS26.48-38-3', 'STV100-3', 'SH-04F', 'REX', 'SM-G925P Build/NRD90M', 'Pixel Build/OPM1.171019.012', 'SM-T217S Build/KOT49H', 'SAMSUNG SM-G925P Build/NRD90M', 'ME173X', 'VS985', 'SM-G892A', 'Z839', 'LG-M257', 'SM-J700F', 'SM-A500FU', 'P008 Build/NRD90M', 'LG-H631', 'LGLS991', 'P00C', 'gxq6580_weg_l Build/LMY47I', 'SAMSUNG SM-J500M Build/LMY48B', 'HUAWEI Build/MMB28B', 'VT0701A08', 'HUAWEI M2-801W Build/HUAWEIM2-801W', 'Moto E (4) Build/NMA26.42-19', 'SM-G570M Build/MMB29K', 'RCT6S03W12', 'AERIAL', 'XT1585 Build/NCK25.118-10.5', 'SM-T713 Build/NRD90M', 'ASUS_Z017D', 'SM-G610M Build/MMB29K', 'CHC-U03 Build/HuaweiCHC-U03', 'C6603', '8050G Build/LMY47I', 'LG-K430 Build/MRA58K', 'SAMSUNG SM-G900A Build/MMB29M', 'LG-H871', 'SM-N950U1 Build/NMF26X', 'LGL84VL Build/NRD90U', 'SM-J727T Build/NRD90M', 'NEM-L51 Build/HONORNEM-L51', 'GT-S7390', 'SM-A320FL Build/MMB29K', 'Moto E (4) Plus Build/NMA26.42-142', 'Build/OPR1.170623.032', 'SAMSUNG-SM-G935A Build/NRD90M', 'E6553', 'rv:51.0', 'D5316 Build/19.4.A.0.182', 'Android 4.4.2', 'Advance', 'SAMSUNG SM-J327T1 Build/NRD90M', 'SAMSUNG SM-J710MN Build/NRD90M', 'SM-S120VL', 'GT-I9505 Build/LRX22C', 'STF-L09 Build/HUAWEISTF-L09', 'SM-T377V Build/NMF26X', 'SM-G530M', 'E5506', 'SM-G900P Build/LRX21T', 'SM-A320Y Build/NRD90M', 'SAMSUNG SM-T810 Build/NRD90M', 'ASUS_X00ID', 'Z799VL', 'GT-S7582L', 'SM-J105B Build/LMY47V', 'LG-D855', 'HTC One A9 Build/NRD90M', 'SAMSUNG SM-G930F/XXU2DRC1 Build/NRD90M', 'Pixel XL Build/OPM1.171019.021', 'MYA-L03 Build/HUAWEIMYA-L03', 'SM-G928P Build/NRD90M', 'HUAWEI VNS-L21 Build/HUAWEIVNS-L21', 'Origins', 'SM-N950W', 'GT-I9300', 'SM-S727VL Build/MMB29M', '5044A', 'SAMSUNG SM-G955F Build/R16NW', 'SM-A300FU Build/MMB29M', 'Moto G (5S', 'SM-J510MN Build/NMF26X', 'Redmi Note 4X Build/MRA58K', 'LGL83BL', 'LG-H542 Build/LRX22G', 'LG-K450 Build/MXB48T', 'Infinix', 'LGMS428', 'LG-D331 Build/LRX22G', '2PS64 Build/NRD90M', 'Linux x86_64', 'SAMSUNG SM-G930P Build/NRD90M', 'GT-P5110', 'SAMSUNG SM-G925P Build/MMB29K', 'SM-J730F', 'Z836BL', 'SM-A310F Build/MMB29K', 'CAM-L23', 'SAMSUNG SM-T550 Build/NMF26X', 'Ilium X510 Build/MRA58K', 'SAMSUNG-SM-N900A', '5051A Build/MMB29M', '2PYB2', 'SAMSUNG SM-G903F Build/MMB29K', 'MotoG3 Build/MPI24.65-33.1-2', 'SM-J727T1 Build/NRD90M', 'G3223', 'SAMSUNG-SM-G890A', 'XT890 Build/9.8.2I-50_SML-25', 'SM-G313ML', 'SM-N910V Build/MMB29M', 'Moto G (5) Build/NPP25.137-72', 'SAMSUNG SM-G892A Build/R16NW', 'SM-G900F Build/LRX21T', 'ALUMINI', 'SAMSUNG SM-J700M Build/LMY48B', 'AX820 Build/MRA58K', 'SM-S902L', 'SAMSUNG SM-G965F Build/R16NW', 'SM-J530GM Build/NRD90M', 'FP2', 'QTASUN1', 'SM-J330F', 'GT-I9500', 'LG-H931', 'SM-G900T Build/MMB29M', 'HTC Desire 626s Build/LMY47O', 'SM-G900M Build/LRX21T', 'Ilium L910 Build/MRA58K', 'SM-J320V Build/MMB29M', 'Aquaris', 'SM-G920V Build/MMB29K', 'LG-H810/H81022f', 'SM-G900V Build/LRX21T', 'SM-G930P', 'SM-N920R4', 'SAMSUNG SM-G891A Build/NRD90M', 'Alcatel_5054O', '9008A Build/NRD90M', 'BLADE V8 Build/NRD90M', 'LG-D855 Build/LRX21R', 'LG-H901', 'Z', 'NXA116QC164', 'P027', '7048A Build/LRX22G', 'NOKIA', 'SM-A300H Build/LRX22G', 'SM-J700T Build/NMF26X', 'Z959 Build/LMY47V', 'SAMSUNG-SM-G920A Build/MMB29K', 'Ilium L620 Build/NRD90M', 'XT1580 Build/NPKS25.200-17-8', 'E5823', 'SENS', 'E2006', 'SAMSUNG SM-G935W8 Build/NRD90M', 'A0001', 'SAMSUNG-SM-T537A', 'SAMSUNG-SM-G930AZ', 'E6810 Build/5.320VZ.03.r', 'ZTE', 'NYX_A1', 'SM-N920V Build/NRD90M', 'SM-E500M Build/KTU84P', 'es-mx', 'Pixel XL Build/OPM1.171019.011', 'F3113', 'TA-1025', 'SM-J320VPP', 'Z983 Build/NMF26F', 'SAMSUNG-SM-G925A', 'SM-T377V', 'SGP611', 'BND-L21 Build/HONORBND-L21', 'Moto C Plus Build/NRD90M.05.034', 'SM-T550', 'PE-TL10', 'SLA-L02', 'SM-J500FN', 'S57 Build/KTU84P', 'SAMSUNG SM-J530F Build/NRD90M', 'SM-G900M Build/MMB29M', 'Hisense L675 PRO Build/NRD90M', 'F5321', nan, 'SM-T550 Build/NMF26X', 'HTC Desire 510 Build/KOT49H', 'G3313 Build/43.0.A.7.25', 'SGH-M919 Build/KTU84P', 'GT-P5113', 'LG-H343', 'SM-T230NU Build/KOT49H', 'Moto E (4) Build/NMA26.42-11-3', 'SAMSUNG-SM-G870A', '916', 'Techpad', 'TA-1025 Build/NMF26F', 'Pixel Build/OPM2.171019.029', 'Moto C Build/NRD90M.070', 'Z965 Build/NMF26V', 'TAB7', 'SM-G920T1', 'moto', 'orbis', 'ME301T', 'Android 6.0.1', 'ASUS_X00HD Build/NMF26F', 'LT22i Build/6.2.A.1.100', 'Moto Z2 Play Build/NPSS26.118-19-6', 'SAMSUNG SM-J327T Build/NRD90M', 'SM-G900FD', 'O1', 'P5046A', 'LG-H420 Build/LRX21Y', 'LG-V410', 'LG-K371', '5015A Build/LMY47I', 'E6853 Build/32.4.A.1.54', 'HUAWEI VNS-L31 Build/HUAWEIVNS-L31', 'SM-T350 Build/MMB29M', 'SAMSUNG SM-G925I Build/NRD90M', 'X78', 'M4 SS4450 Build/MRA58K', 'Gigaset', 'SM-J730GM Build/NRD90M', 'Pixel 2 Build/OPM2.171019.016', 'HUAWEI NXT-L09 Build/HUAWEINXT-L09', 'SM-J327T Build/NRD90M', 'SGP521', 'Z812', 'XT1032 Build/LPBS23.13-57-2', 'E6603', 'N9136', 'SAMSUNG SM-A320Y Build/NRD90M', 'XT1032 Build/KXB20.9-1.10-1.24-1.1', 'XT1003', 'SM-N920A Build/MMB29K', 'LG-V410/V41020c', 'Wileyfox', 'LG-D373 Build/KOT49I.V10a', 'A463BG', 'SAMSUNG-SM-G900A Build/LMY47X', 'Pixel 2 XL Build/OPM1.171019.011', 'SM-J510FN Build/NMF26X', 'LG-K580 Build/MRA58K', 'Le X520 Build/IEXCNFN5902303111S', 'SM-J327T1 Build/NRD90M', 'TA-1038', 'P4526A Build/NRD90M', 'SM-G935V Build/NRD90M', 'SAMSUNG SM-N950U Build/NMF26X', 'SAMSUNG-SM-G870A Build/MMB29M', 'SM-T320 Build/KOT49H', 'Grand2c', 'Redmi 4A Build/N2G47H', 'SAMSUNG SM-A520F Build/NRD90M', 'HTC', 'SM-A710M Build/NRD90M', 'VKY-L09 Build/HUAWEIVKY-L09', 'SM-A310M', 'SAMSUNG-SM-G891A Build/NRD90M', 'Redmi Note 4 Build/MMB29M', 'XT1032 Build/KXB21.14-L1.40', 'G3423', 'Z557BL', 'RCT6K03W13', 'SM-G950W', 'SM-G935U', 'SM-N920V', 'Venue', 'HUAWEI LYO-L21 Build/HUAWEILYO-L21', 'HUAWEI LUA-U23 Build/HUAWEILUA-U23', 'SAMSUNG-SM-J327AZ', 'SM-G730W8 Build/KOT49H', 'SM-J327V Build/NRD90M', 'PRA-LX3 Build/HUAWEIPRA-LX3', 'HTC One Build/LRX22G', 'ZTE-Z835', 'rv:44.0', 'SCH-I435', 'SOV33 Build/35.0.D.2.25', 'LG-M255', 'BG2-W09', 'Shift Build/LMY47I', 'ASUS_X008DC Build/NRD90M', 'SM-G928P', 'A577VL', 'GT-I9060L Build/JDQ39', 'SM-G955F Build/R16NW', 'X10', 'HTCD160LVWPP', 'D5803 Build/23.5.A.1.291', 'SM-G550T1 Build/MMB29K', 'SAMSUNG SM-J250M Build/NMF26X', 'A3_mini', 'LG-M327 Build/NRD90U', 'KFTHWI Build/KTU84M', 'SM-P550 Build/MMB29M', 'KYOCERA-C6742A Build/LMY47V', 'XT1710-02 Build/NDSS26.118-23-15', 'CAM-L03 Build/HUAWEICAM-L03', 'SM-N950F Build/R16NW', 'Pixel Build/OPM1.171019.011', 'SAMSUNG SM-G920A Build/NRD90M', 'NX521J', 'SAMSUNG SM-N950U Build/R16NW', 'SAMSUNG SM-J111M Build/LMY47V', 'SAMSUNG-SGH-I497', 'F5121', 'A5002', 'X900+', 'SM-G360V Build/LMY48B', 'SAMSUNG SM-J700M Build/MMB29K', 'SM-T587P', 'SM-T820 Build/NRD90M', 'HUAWEI CUN-L03 Build/HUAWEICUN-L03', 'Northwell', 'SM-J320P Build/LMY47X', 'SM-C900F', 'Moto Z2 Play Build/NPSS26.118-19-11', 'F1f Build/LMY47V', 'Moto G (4) Build/NPJ25.93-14', 'Moto C Build/NRD90M.050', 'SAMSUNG SM-G928G Build/NRD90M', 'MYA-L13 Build/HUAWEIMYA-L13', 'Moto G Play Build/MPIS24.241-15.3-7', 'SM-J700M Build/LMY48B', 'LG-H540', 'A574BL Build/NMF26F', 'BAH-L09 Build/HUAWEIBAH-L09', 'verykools5035', 'STUDIO_G_HD', 'FRD-L09 Build/HUAWEIFRD-L09', 'Ilium Pad T7X Build/LMY47I', 'rv:58.0', 'rv:42.0', 'XT1609 Build/MPIS24.241-2.35-1-17', 'LG-H815', 'A1601 Build/LMY47I', 'SM-J727VPP Build/NRD90M', 'MotoG3 Build/MPIS24.65-33.1-2-16', 'RNE-L21 Build/HUAWEIRNE-L21', 'SAMSUNG SM-G900I Build/MMB29M', '7_Plus', 'SM-J100MU', 'Vivo', 'SM-G925T Build/LMY47X', 'KFAUWI Build/LVY48F', 'GT-I9195I', 'GT-I8190N', 'Redmi 4A Build/MMB29M', 'XT1650 Build/NCLS26.118-23-13-3', '0PJA2', 'K90U', 'HTC U11 Build/OPR6.170623.013', 'SM-G361F', 'LG-H810', 'Lenovo PB1-750M Build/S100', 'SM-G390W', 'LG-TP260 Build/NRD90U', 'SM-J500G', 'Mi A1 Build/OPR1.170623.026', 'SAMSUNG SM-A510M Build/NRD90M', 'SAMSUNG-SM-G900A Build/LRX21T', 'LG-K220 Build/MXB48T', 'LM-X210(G', 'TA-1028 Build/O00623', 'Mobiistar_LAI_Yuna_X', 'A0001 Build/MHC19Q', 'SAMSUNG-SM-J320A Build/NMF26X', 'SAMSUNG SM-J327P Build/MMB29M', 'Infinit', 'HUAWEI VNS-L23 Build/HUAWEIVNS-L23', 'C6906', 'RS988 Build/MMB29M', 'SM-T580 Build/NRD90M', 'XT1064', 'TA-1039 Build/NMF26F', 'SAMSUNG SM-T587P Build/NRD90M', 'ZTE BLADE V8 MINI Build/NRD90M', '5054N', 'XT1635-02 Build/OPN27.76-12-22', 'SM-G900W8', 'D6603 Build/23.5.A.1.291', 'LG-K373', 'VS980 4G Build/LRX22G', 'N9560 Build/NMF26F', 'Redmi Note 5A Build/N2G47H', 'SM-G920F Build/NRD90M', 'HTC_D10i', 'verykool', 'SAMSUNG SM-G920P Build/NRD90M', '5025G Build/LMY47I', 'SM-J327VPP Build/NRD90M', 'iris 820 Build/MRA58K', 'SAMSUNG-SM-G930A Build/NRD90M', 'LAVA_A3', 'D2406', 'MotoG3-TE Build/MPDS24.65-33-1-30', 'Blade A510 Build/MRA58K', 'RCT6773W22B', 'LGLS775 Build/NRD90U', 'Hisense F23 Build/NRD90M', 'MAGNO', 'SAMSUNG SM-J120H Build/LMY47V', 'SM-J710GN Build/MMB29K', 'ONE A2005 Build/MMB29M', 'XT1635-02 Build/NPN26.118-22-2', 'SM-G930F Build/MMB29K', 'LG-V495/V49520l', 'rv:39.0', 'Moto G (5) Plus Build/NPN25.137-72', 'KFJWI', 'SM-T827V Build/NRD90M', 'Blade A460 Build/LMY47O', 'SM-N915V', 'GT-S5310L', '5049W Build/NRD90M', 'XT1580 Build/NPKS25.200-12-9', 'SGH-M919V', '5017A', 'LG-H840 Build/NRD90U', 'XT1063 Build/MPB24.65-34', 'LG-M322', 'LGMS210 Build/NRD90U', 'DLI-L22 Build/HONORDLI-L22', 'SM-P550 Build/NMF26X', 'SM-J710MN Build/MMB29K', 'GT-P3100', 'SM-A500W', '6055B', 'SM-G360F', 'rv:57.0', 'XT1609', 'SAMSUNG SM-G890A Build/NRD90M', 'Ilium X210 Build/LMY47I', 'HTCD200LVW', 'SM-G903M', 'E6790TM', 'AOC_U706G', 'SAMSUNG SM-S727VL Build/MMB29M', 'SM-G615F', '4003A', 'Lenovo-A6020l36 Build/LMY47V', 'LG-K550 Build/NRD90U', 'XT1008 Build/LPBS23.13-56-2', 'XT1058 Build/LPAS23.12-21.7-1', 'LG-H831 Build/NRD90U', 'VK700 Build/LRX22G', 'LG-H990 Build/NRD90M', 'SM-T380', 'SMART', 'SAMSUNG-SM-G900A Build/KOT49H', 'AX1070', 'AX921 Build/MRA58K', 'VS987 Build/NRD90U', 'SAMSUNG-SM-T377A Build/MMB29K', 'HUAWEI VNS-L53 Build/HUAWEIVNS-L53', 'SM-S975L', 'SM-G925I Build/LMY47X', 'SM-T807T', 'F5121 Build/34.3.A.0.238', 'BLA-L29 Build/HUAWEIBLA-L29', 'VS996 Build/OPR1.170623.026', 'SM-J530F Build/NRD90M', 'LGL41C', 'ZA409', 'SM-T585', 'Moto G (5) Plus Build/NPNS25.137-92-8', 'G620S-L03', 'HELIO', 'QMV7A', 'SM-G920V Build/NRD90M', 'rv:54.0', 'SM-J250M Build/NMF26X', 'SM-J120FN Build/LMY47X', '2PQ93', 'SM-A500M Build/KTU84P', 'Studio', 'SM-N900P Build/LRX21V', 'SAMSUNG SM-G550T1 Build/MMB29K', 'QTAQZ3 Build/KOT49H', 'F8131', 'ASUS_X00DDA'}\n"
     ]
    }
   ],
   "source": [
    "categorical_features = train.select_dtypes(include=['object', 'category']).columns\n",
    "for col in categorical_features:\n",
    "    print(col, len(set(train[col])), set(train[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some features (id_30, id_31, id_33, DeviceInfo) have a lot of different values that makes encoding harder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find truly categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Screen resolution values are true numerical values, while all other features are categorical in nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split column id_33 to Width and Height\n",
    "train[['Screen_Width', 'Screen_Height']] = train['id_33'].str.split('x', expand=True).astype(float)\n",
    "train = train.drop(columns=['id_33'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['Screen_Width', 'Screen_Height']] = test['id_33'].str.split('x', expand=True).astype(float)\n",
    "test = test.drop(columns=['id_33'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some columns have integer type, but they categorical in nature, since they have too few distinct values, we need to identify it as categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate categorical features (numeric columns with few unique values):\n",
      "V1: 2 unique values\n",
      "V2: 9 unique values\n",
      "V3: 10 unique values\n",
      "V4: 7 unique values\n",
      "V5: 7 unique values\n",
      "V6: 10 unique values\n",
      "V7: 10 unique values\n",
      "V8: 9 unique values\n",
      "V9: 9 unique values\n",
      "V10: 5 unique values\n",
      "V11: 6 unique values\n",
      "V12: 4 unique values\n",
      "V13: 7 unique values\n",
      "V14: 2 unique values\n",
      "V15: 8 unique values\n",
      "V16: 15 unique values\n",
      "V17: 16 unique values\n",
      "V18: 16 unique values\n",
      "V19: 8 unique values\n",
      "V20: 15 unique values\n",
      "V21: 6 unique values\n",
      "V22: 9 unique values\n",
      "V23: 14 unique values\n",
      "V24: 14 unique values\n",
      "V25: 7 unique values\n",
      "V26: 13 unique values\n",
      "V27: 4 unique values\n",
      "V28: 4 unique values\n",
      "V29: 6 unique values\n",
      "V30: 8 unique values\n",
      "V31: 8 unique values\n",
      "V32: 15 unique values\n",
      "V33: 7 unique values\n",
      "V34: 13 unique values\n",
      "V35: 4 unique values\n",
      "V36: 6 unique values\n",
      "V39: 16 unique values\n",
      "V40: 18 unique values\n",
      "V41: 2 unique values\n",
      "V42: 9 unique values\n",
      "V43: 9 unique values\n",
      "V46: 7 unique values\n",
      "V47: 9 unique values\n",
      "V48: 6 unique values\n",
      "V49: 6 unique values\n",
      "V50: 6 unique values\n",
      "V51: 7 unique values\n",
      "V52: 9 unique values\n",
      "V53: 6 unique values\n",
      "V54: 7 unique values\n",
      "V55: 18 unique values\n",
      "V57: 7 unique values\n",
      "V58: 11 unique values\n",
      "V59: 17 unique values\n",
      "V60: 17 unique values\n",
      "V61: 7 unique values\n",
      "V62: 11 unique values\n",
      "V63: 8 unique values\n",
      "V64: 8 unique values\n",
      "V65: 2 unique values\n",
      "V66: 8 unique values\n",
      "V67: 9 unique values\n",
      "V68: 3 unique values\n",
      "V69: 6 unique values\n",
      "V70: 7 unique values\n",
      "V71: 7 unique values\n",
      "V72: 11 unique values\n",
      "V73: 8 unique values\n",
      "V74: 9 unique values\n",
      "V75: 5 unique values\n",
      "V76: 7 unique values\n",
      "V79: 8 unique values\n",
      "V82: 8 unique values\n",
      "V83: 8 unique values\n",
      "V84: 8 unique values\n",
      "V85: 8 unique values\n",
      "V88: 2 unique values\n",
      "V89: 3 unique values\n",
      "V90: 6 unique values\n",
      "V91: 7 unique values\n",
      "V92: 8 unique values\n",
      "V93: 8 unique values\n",
      "V94: 3 unique values\n",
      "V98: 13 unique values\n",
      "V104: 16 unique values\n",
      "V107: 2 unique values\n",
      "V108: 8 unique values\n",
      "V109: 8 unique values\n",
      "V110: 8 unique values\n",
      "V111: 10 unique values\n",
      "V112: 10 unique values\n",
      "V113: 10 unique values\n",
      "V114: 7 unique values\n",
      "V115: 7 unique values\n",
      "V116: 7 unique values\n",
      "V117: 4 unique values\n",
      "V118: 4 unique values\n",
      "V119: 4 unique values\n",
      "V120: 4 unique values\n",
      "V121: 4 unique values\n",
      "V122: 4 unique values\n",
      "V123: 14 unique values\n",
      "V124: 14 unique values\n",
      "V125: 14 unique values\n",
      "V141: 6 unique values\n",
      "V142: 10 unique values\n",
      "V153: 19 unique values\n",
      "V154: 19 unique values\n",
      "V173: 8 unique values\n",
      "V174: 9 unique values\n",
      "V175: 15 unique values\n",
      "V184: 17 unique values\n",
      "V194: 8 unique values\n",
      "V195: 17 unique values\n",
      "V197: 15 unique values\n",
      "V223: 17 unique values\n",
      "V240: 6 unique values\n",
      "V241: 5 unique values\n",
      "V247: 19 unique values\n",
      "V250: 19 unique values\n",
      "V251: 19 unique values\n",
      "V260: 9 unique values\n",
      "V284: 13 unique values\n",
      "V286: 9 unique values\n",
      "V288: 11 unique values\n",
      "V289: 13 unique values\n",
      "V297: 13 unique values\n",
      "V300: 12 unique values\n",
      "V301: 14 unique values\n",
      "V302: 17 unique values\n",
      "V304: 17 unique values\n",
      "V305: 2 unique values\n",
      "V325: 13 unique values\n",
      "V327: 19 unique values\n",
      "V328: 16 unique values\n",
      "id_04: 15 unique values\n",
      "id_18: 18 unique values\n",
      "id_24: 12 unique values\n",
      "id_32: 4 unique values\n"
     ]
    }
   ],
   "source": [
    "cat_cols = train.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Identify candidate categorical features based on unique value counts\n",
    "candidate_categorical = {}\n",
    "# Set a threshold for maximum unique values\n",
    "unique_threshold = 20\n",
    "\n",
    "# Iterate over numeric columns to check unique value counts\n",
    "for col in train.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    unique_vals = train[col].nunique()\n",
    "    if (unique_vals < unique_threshold) and (col != \"isFraud\"):\n",
    "        candidate_categorical[col] = unique_vals\n",
    "\n",
    "# Print candidate categorical features\n",
    "print(\"Candidate categorical features (numeric columns with few unique values):\")\n",
    "for col, count in candidate_categorical.items():\n",
    "    print(f\"{col}: {count} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imputing nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to leave as much features as possible, so Genetic Algorithm will select the most valuable ones. Therefore, we need smart imputation\n",
    "\n",
    "Not using standard imputation:\n",
    "1. Placed zero values as indicator for missing values where feature values no zero values anywhere else\n",
    "2. Added 'missing' instead of null for categorical values to keep all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Identify numeric and categorical columns\n",
    "num_cols = train.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_cols = list(set(cat_cols).union(set(candidate_categorical.keys()))) # Union of categorical values with numeric ones that actually caegorical\n",
    "num_cols = [col for col in num_cols if col not in cat_cols and col not in (\"TransactionID\", \"isFraud\")]\n",
    "\n",
    "# Imputation for numeric columns using zeros as indicator\n",
    "num_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "train[num_cols] = num_imputer.fit_transform(train[num_cols])\n",
    "\n",
    "# Imputation for categorical columns using a constant value\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "train[cat_cols] = cat_imputer.fit_transform(train[cat_cols])\n",
    "\n",
    "# Confirm that no missing values remain (or check overall missing count)\n",
    "print(\"Total missing values after imputation:\", train.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "test[num_cols] = num_imputer.transform(test[num_cols])\n",
    "test[cat_cols] = cat_imputer.transform(test[cat_cols])\n",
    "print(\"Total missing values after imputation:\", train.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=[\"isFraud\", \"TransactionID\"])\n",
    "y = train['isFraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting train and validation asap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using novel thing: WOE encoder to compensate for an enormous dimentionality for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_high = ce.WOEEncoder(cols=cat_cols)\n",
    "X_train_encoded_cat = encoder_high.fit_transform(X_train[cat_cols], y_train)\n",
    "X_val_encoded_cat = encoder_high.transform(X_val[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded_cat = encoder_high.transform(test[cat_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale data to remove any disrepancies in SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_for_scaling = pd.DataFrame(np.hstack([X_train_encoded_cat, X_train[num_cols]]), columns=cat_cols + num_cols)\n",
    "X_val_for_scaling = pd.DataFrame(np.hstack([X_val_encoded_cat, X_val[num_cols]]), columns=cat_cols + num_cols)\n",
    "test_for_scaling = pd.DataFrame(np.hstack([test_encoded_cat, test[num_cols]]), columns=cat_cols + num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_for_scaling)\n",
    "X_val_scaled = scaler.transform(X_val_for_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaled = scaler.transform(test_for_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded training set shape: (472432, 433)\n",
      "Encoded validation set shape: (118108, 433)\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoded training set shape:\", X_train_scaled.shape)\n",
    "print(\"Encoded validation set shape:\", X_val_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded test set shape: (506691, 433)\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoded test set shape:\", test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=cat_cols + num_cols)\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns=cat_cols + num_cols)\n",
    "test_scaled = pd.DataFrame(test_scaled, columns=cat_cols + num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V35</th>\n",
       "      <th>V31</th>\n",
       "      <th>M4</th>\n",
       "      <th>R_emaildomain</th>\n",
       "      <th>V122</th>\n",
       "      <th>V75</th>\n",
       "      <th>V84</th>\n",
       "      <th>id_38</th>\n",
       "      <th>V69</th>\n",
       "      <th>V57</th>\n",
       "      <th>V93</th>\n",
       "      <th>V63</th>\n",
       "      <th>V240</th>\n",
       "      <th>V297</th>\n",
       "      <th>V65</th>\n",
       "      <th>V50</th>\n",
       "      <th>V42</th>\n",
       "      <th>V83</th>\n",
       "      <th>V112</th>\n",
       "      <th>V32</th>\n",
       "      <th>V3</th>\n",
       "      <th>id_24</th>\n",
       "      <th>V41</th>\n",
       "      <th>V305</th>\n",
       "      <th>V4</th>\n",
       "      <th>V25</th>\n",
       "      <th>V110</th>\n",
       "      <th>M7</th>\n",
       "      <th>V301</th>\n",
       "      <th>M2</th>\n",
       "      <th>V197</th>\n",
       "      <th>V18</th>\n",
       "      <th>V304</th>\n",
       "      <th>M5</th>\n",
       "      <th>V53</th>\n",
       "      <th>V76</th>\n",
       "      <th>id_18</th>\n",
       "      <th>V325</th>\n",
       "      <th>id_27</th>\n",
       "      <th>id_16</th>\n",
       "      <th>id_34</th>\n",
       "      <th>V175</th>\n",
       "      <th>V64</th>\n",
       "      <th>V141</th>\n",
       "      <th>V8</th>\n",
       "      <th>V15</th>\n",
       "      <th>V173</th>\n",
       "      <th>id_32</th>\n",
       "      <th>V79</th>\n",
       "      <th>V194</th>\n",
       "      <th>V142</th>\n",
       "      <th>DeviceInfo</th>\n",
       "      <th>V94</th>\n",
       "      <th>V250</th>\n",
       "      <th>V19</th>\n",
       "      <th>M3</th>\n",
       "      <th>V288</th>\n",
       "      <th>V113</th>\n",
       "      <th>V328</th>\n",
       "      <th>V48</th>\n",
       "      <th>id_15</th>\n",
       "      <th>V51</th>\n",
       "      <th>V153</th>\n",
       "      <th>card4</th>\n",
       "      <th>V286</th>\n",
       "      <th>V98</th>\n",
       "      <th>id_35</th>\n",
       "      <th>V119</th>\n",
       "      <th>V27</th>\n",
       "      <th>V9</th>\n",
       "      <th>V92</th>\n",
       "      <th>V251</th>\n",
       "      <th>V61</th>\n",
       "      <th>id_28</th>\n",
       "      <th>V195</th>\n",
       "      <th>id_36</th>\n",
       "      <th>V34</th>\n",
       "      <th>V7</th>\n",
       "      <th>V23</th>\n",
       "      <th>V108</th>\n",
       "      <th>V121</th>\n",
       "      <th>V88</th>\n",
       "      <th>V29</th>\n",
       "      <th>V12</th>\n",
       "      <th>V115</th>\n",
       "      <th>V47</th>\n",
       "      <th>V26</th>\n",
       "      <th>M9</th>\n",
       "      <th>V66</th>\n",
       "      <th>V43</th>\n",
       "      <th>V59</th>\n",
       "      <th>V114</th>\n",
       "      <th>id_37</th>\n",
       "      <th>V89</th>\n",
       "      <th>V223</th>\n",
       "      <th>V74</th>\n",
       "      <th>V49</th>\n",
       "      <th>P_emaildomain</th>\n",
       "      <th>V68</th>\n",
       "      <th>V111</th>\n",
       "      <th>id_04</th>\n",
       "      <th>V36</th>\n",
       "      <th>V124</th>\n",
       "      <th>V58</th>\n",
       "      <th>V107</th>\n",
       "      <th>V33</th>\n",
       "      <th>V46</th>\n",
       "      <th>V21</th>\n",
       "      <th>V82</th>\n",
       "      <th>V109</th>\n",
       "      <th>V125</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_12</th>\n",
       "      <th>V73</th>\n",
       "      <th>V52</th>\n",
       "      <th>V116</th>\n",
       "      <th>V13</th>\n",
       "      <th>V302</th>\n",
       "      <th>V104</th>\n",
       "      <th>M1</th>\n",
       "      <th>V17</th>\n",
       "      <th>V6</th>\n",
       "      <th>V24</th>\n",
       "      <th>id_29</th>\n",
       "      <th>V10</th>\n",
       "      <th>V54</th>\n",
       "      <th>V30</th>\n",
       "      <th>V154</th>\n",
       "      <th>V22</th>\n",
       "      <th>V72</th>\n",
       "      <th>V71</th>\n",
       "      <th>V247</th>\n",
       "      <th>V300</th>\n",
       "      <th>V67</th>\n",
       "      <th>V289</th>\n",
       "      <th>V62</th>\n",
       "      <th>V85</th>\n",
       "      <th>V11</th>\n",
       "      <th>V70</th>\n",
       "      <th>id_30</th>\n",
       "      <th>V40</th>\n",
       "      <th>V5</th>\n",
       "      <th>V20</th>\n",
       "      <th>V91</th>\n",
       "      <th>V117</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>M6</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>V14</th>\n",
       "      <th>V16</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V28</th>\n",
       "      <th>V123</th>\n",
       "      <th>V327</th>\n",
       "      <th>V60</th>\n",
       "      <th>V174</th>\n",
       "      <th>V118</th>\n",
       "      <th>V241</th>\n",
       "      <th>V284</th>\n",
       "      <th>V90</th>\n",
       "      <th>V260</th>\n",
       "      <th>V120</th>\n",
       "      <th>id_23</th>\n",
       "      <th>card6</th>\n",
       "      <th>V55</th>\n",
       "      <th>M8</th>\n",
       "      <th>V39</th>\n",
       "      <th>V184</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card5</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>C13</th>\n",
       "      <th>C14</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>D10</th>\n",
       "      <th>D11</th>\n",
       "      <th>D12</th>\n",
       "      <th>D13</th>\n",
       "      <th>D14</th>\n",
       "      <th>D15</th>\n",
       "      <th>V37</th>\n",
       "      <th>V38</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V56</th>\n",
       "      <th>V77</th>\n",
       "      <th>V78</th>\n",
       "      <th>V80</th>\n",
       "      <th>V81</th>\n",
       "      <th>V86</th>\n",
       "      <th>V87</th>\n",
       "      <th>V95</th>\n",
       "      <th>V96</th>\n",
       "      <th>V97</th>\n",
       "      <th>V99</th>\n",
       "      <th>V100</th>\n",
       "      <th>V101</th>\n",
       "      <th>V102</th>\n",
       "      <th>V103</th>\n",
       "      <th>V105</th>\n",
       "      <th>V106</th>\n",
       "      <th>V126</th>\n",
       "      <th>V127</th>\n",
       "      <th>V128</th>\n",
       "      <th>V129</th>\n",
       "      <th>V130</th>\n",
       "      <th>V131</th>\n",
       "      <th>V132</th>\n",
       "      <th>V133</th>\n",
       "      <th>V134</th>\n",
       "      <th>V135</th>\n",
       "      <th>V136</th>\n",
       "      <th>V137</th>\n",
       "      <th>V138</th>\n",
       "      <th>V139</th>\n",
       "      <th>V140</th>\n",
       "      <th>V143</th>\n",
       "      <th>V144</th>\n",
       "      <th>V145</th>\n",
       "      <th>V146</th>\n",
       "      <th>V147</th>\n",
       "      <th>V148</th>\n",
       "      <th>V149</th>\n",
       "      <th>V150</th>\n",
       "      <th>V151</th>\n",
       "      <th>V152</th>\n",
       "      <th>V155</th>\n",
       "      <th>V156</th>\n",
       "      <th>V157</th>\n",
       "      <th>V158</th>\n",
       "      <th>V159</th>\n",
       "      <th>V160</th>\n",
       "      <th>V161</th>\n",
       "      <th>V162</th>\n",
       "      <th>V163</th>\n",
       "      <th>V164</th>\n",
       "      <th>V165</th>\n",
       "      <th>V166</th>\n",
       "      <th>V167</th>\n",
       "      <th>V168</th>\n",
       "      <th>V169</th>\n",
       "      <th>V170</th>\n",
       "      <th>V171</th>\n",
       "      <th>V172</th>\n",
       "      <th>V176</th>\n",
       "      <th>V177</th>\n",
       "      <th>V178</th>\n",
       "      <th>V179</th>\n",
       "      <th>V180</th>\n",
       "      <th>V181</th>\n",
       "      <th>V182</th>\n",
       "      <th>V183</th>\n",
       "      <th>V185</th>\n",
       "      <th>V186</th>\n",
       "      <th>V187</th>\n",
       "      <th>V188</th>\n",
       "      <th>V189</th>\n",
       "      <th>V190</th>\n",
       "      <th>V191</th>\n",
       "      <th>V192</th>\n",
       "      <th>V193</th>\n",
       "      <th>V196</th>\n",
       "      <th>V198</th>\n",
       "      <th>V199</th>\n",
       "      <th>V200</th>\n",
       "      <th>V201</th>\n",
       "      <th>V202</th>\n",
       "      <th>V203</th>\n",
       "      <th>V204</th>\n",
       "      <th>V205</th>\n",
       "      <th>V206</th>\n",
       "      <th>V207</th>\n",
       "      <th>V208</th>\n",
       "      <th>V209</th>\n",
       "      <th>V210</th>\n",
       "      <th>V211</th>\n",
       "      <th>V212</th>\n",
       "      <th>V213</th>\n",
       "      <th>V214</th>\n",
       "      <th>V215</th>\n",
       "      <th>V216</th>\n",
       "      <th>V217</th>\n",
       "      <th>V218</th>\n",
       "      <th>V219</th>\n",
       "      <th>V220</th>\n",
       "      <th>V221</th>\n",
       "      <th>V222</th>\n",
       "      <th>V224</th>\n",
       "      <th>V225</th>\n",
       "      <th>V226</th>\n",
       "      <th>V227</th>\n",
       "      <th>V228</th>\n",
       "      <th>V229</th>\n",
       "      <th>V230</th>\n",
       "      <th>V231</th>\n",
       "      <th>V232</th>\n",
       "      <th>V233</th>\n",
       "      <th>V234</th>\n",
       "      <th>V235</th>\n",
       "      <th>V236</th>\n",
       "      <th>V237</th>\n",
       "      <th>V238</th>\n",
       "      <th>V239</th>\n",
       "      <th>V242</th>\n",
       "      <th>V243</th>\n",
       "      <th>V244</th>\n",
       "      <th>V245</th>\n",
       "      <th>V246</th>\n",
       "      <th>V248</th>\n",
       "      <th>V249</th>\n",
       "      <th>V252</th>\n",
       "      <th>V253</th>\n",
       "      <th>V254</th>\n",
       "      <th>V255</th>\n",
       "      <th>V256</th>\n",
       "      <th>V257</th>\n",
       "      <th>V258</th>\n",
       "      <th>V259</th>\n",
       "      <th>V261</th>\n",
       "      <th>V262</th>\n",
       "      <th>V263</th>\n",
       "      <th>V264</th>\n",
       "      <th>V265</th>\n",
       "      <th>V266</th>\n",
       "      <th>V267</th>\n",
       "      <th>V268</th>\n",
       "      <th>V269</th>\n",
       "      <th>V270</th>\n",
       "      <th>V271</th>\n",
       "      <th>V272</th>\n",
       "      <th>V273</th>\n",
       "      <th>V274</th>\n",
       "      <th>V275</th>\n",
       "      <th>V276</th>\n",
       "      <th>V277</th>\n",
       "      <th>V278</th>\n",
       "      <th>V279</th>\n",
       "      <th>V280</th>\n",
       "      <th>V281</th>\n",
       "      <th>V282</th>\n",
       "      <th>V283</th>\n",
       "      <th>V285</th>\n",
       "      <th>V287</th>\n",
       "      <th>V290</th>\n",
       "      <th>V291</th>\n",
       "      <th>V292</th>\n",
       "      <th>V293</th>\n",
       "      <th>V294</th>\n",
       "      <th>V295</th>\n",
       "      <th>V296</th>\n",
       "      <th>V298</th>\n",
       "      <th>V299</th>\n",
       "      <th>V303</th>\n",
       "      <th>V306</th>\n",
       "      <th>V307</th>\n",
       "      <th>V308</th>\n",
       "      <th>V309</th>\n",
       "      <th>V310</th>\n",
       "      <th>V311</th>\n",
       "      <th>V312</th>\n",
       "      <th>V313</th>\n",
       "      <th>V314</th>\n",
       "      <th>V315</th>\n",
       "      <th>V316</th>\n",
       "      <th>V317</th>\n",
       "      <th>V318</th>\n",
       "      <th>V319</th>\n",
       "      <th>V320</th>\n",
       "      <th>V321</th>\n",
       "      <th>V322</th>\n",
       "      <th>V323</th>\n",
       "      <th>V324</th>\n",
       "      <th>V326</th>\n",
       "      <th>V329</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "      <th>id_01</th>\n",
       "      <th>id_02</th>\n",
       "      <th>id_03</th>\n",
       "      <th>id_05</th>\n",
       "      <th>id_06</th>\n",
       "      <th>id_07</th>\n",
       "      <th>id_08</th>\n",
       "      <th>id_09</th>\n",
       "      <th>id_10</th>\n",
       "      <th>id_11</th>\n",
       "      <th>id_13</th>\n",
       "      <th>id_14</th>\n",
       "      <th>id_17</th>\n",
       "      <th>id_19</th>\n",
       "      <th>id_20</th>\n",
       "      <th>id_21</th>\n",
       "      <th>id_22</th>\n",
       "      <th>id_25</th>\n",
       "      <th>id_26</th>\n",
       "      <th>Screen_Width</th>\n",
       "      <th>Screen_Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.249562</td>\n",
       "      <td>0.985555</td>\n",
       "      <td>-0.803152</td>\n",
       "      <td>0.118149</td>\n",
       "      <td>-0.041814</td>\n",
       "      <td>0.992088</td>\n",
       "      <td>0.893506</td>\n",
       "      <td>1.247671</td>\n",
       "      <td>0.894435</td>\n",
       "      <td>1.232184</td>\n",
       "      <td>0.890458</td>\n",
       "      <td>1.245603</td>\n",
       "      <td>1.872586</td>\n",
       "      <td>-0.108377</td>\n",
       "      <td>2.571279</td>\n",
       "      <td>0.385468</td>\n",
       "      <td>0.385747</td>\n",
       "      <td>1.208605</td>\n",
       "      <td>-0.069307</td>\n",
       "      <td>0.985460</td>\n",
       "      <td>1.007737</td>\n",
       "      <td>-0.083475</td>\n",
       "      <td>0.911749</td>\n",
       "      <td>-0.004593</td>\n",
       "      <td>1.032669</td>\n",
       "      <td>2.302824</td>\n",
       "      <td>-0.083589</td>\n",
       "      <td>0.837200</td>\n",
       "      <td>-0.193018</td>\n",
       "      <td>1.036899</td>\n",
       "      <td>1.273024</td>\n",
       "      <td>0.998680</td>\n",
       "      <td>1.686335</td>\n",
       "      <td>0.519333</td>\n",
       "      <td>1.404020</td>\n",
       "      <td>0.958821</td>\n",
       "      <td>-0.272797</td>\n",
       "      <td>2.335583</td>\n",
       "      <td>-0.093859</td>\n",
       "      <td>2.514579</td>\n",
       "      <td>0.952800</td>\n",
       "      <td>1.702710</td>\n",
       "      <td>1.241917</td>\n",
       "      <td>1.536652</td>\n",
       "      <td>1.047713</td>\n",
       "      <td>0.994488</td>\n",
       "      <td>1.817448</td>\n",
       "      <td>-0.219531</td>\n",
       "      <td>0.898955</td>\n",
       "      <td>1.279735</td>\n",
       "      <td>1.521277</td>\n",
       "      <td>-1.730724</td>\n",
       "      <td>0.880040</td>\n",
       "      <td>1.467761</td>\n",
       "      <td>1.789589</td>\n",
       "      <td>1.024527</td>\n",
       "      <td>-0.397750</td>\n",
       "      <td>-0.055439</td>\n",
       "      <td>1.274964</td>\n",
       "      <td>0.340548</td>\n",
       "      <td>2.300246</td>\n",
       "      <td>0.412278</td>\n",
       "      <td>0.496301</td>\n",
       "      <td>-1.478242</td>\n",
       "      <td>-0.154066</td>\n",
       "      <td>-0.234589</td>\n",
       "      <td>0.770854</td>\n",
       "      <td>-0.031981</td>\n",
       "      <td>2.414832</td>\n",
       "      <td>1.020952</td>\n",
       "      <td>0.885887</td>\n",
       "      <td>1.414944</td>\n",
       "      <td>1.815534</td>\n",
       "      <td>2.262642</td>\n",
       "      <td>1.249385</td>\n",
       "      <td>1.834438</td>\n",
       "      <td>0.973051</td>\n",
       "      <td>1.036516</td>\n",
       "      <td>1.445070</td>\n",
       "      <td>-0.066125</td>\n",
       "      <td>-0.065564</td>\n",
       "      <td>2.369663</td>\n",
       "      <td>0.738068</td>\n",
       "      <td>1.126510</td>\n",
       "      <td>-0.162702</td>\n",
       "      <td>0.312541</td>\n",
       "      <td>2.126737</td>\n",
       "      <td>0.806283</td>\n",
       "      <td>1.966465</td>\n",
       "      <td>0.390126</td>\n",
       "      <td>1.241881</td>\n",
       "      <td>-0.090673</td>\n",
       "      <td>1.872156</td>\n",
       "      <td>2.178445</td>\n",
       "      <td>1.856694</td>\n",
       "      <td>1.198272</td>\n",
       "      <td>0.341725</td>\n",
       "      <td>-0.752456</td>\n",
       "      <td>2.534823</td>\n",
       "      <td>-0.04969</td>\n",
       "      <td>2.779126</td>\n",
       "      <td>0.256668</td>\n",
       "      <td>-0.22275</td>\n",
       "      <td>1.236209</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>0.981250</td>\n",
       "      <td>0.294440</td>\n",
       "      <td>0.995269</td>\n",
       "      <td>1.337633</td>\n",
       "      <td>-0.114522</td>\n",
       "      <td>-0.182099</td>\n",
       "      <td>-0.618445</td>\n",
       "      <td>1.832608</td>\n",
       "      <td>1.209208</td>\n",
       "      <td>0.418686</td>\n",
       "      <td>-0.116566</td>\n",
       "      <td>1.080244</td>\n",
       "      <td>1.731517</td>\n",
       "      <td>-0.130335</td>\n",
       "      <td>1.084328</td>\n",
       "      <td>0.998054</td>\n",
       "      <td>1.048459</td>\n",
       "      <td>1.485220</td>\n",
       "      <td>2.293979</td>\n",
       "      <td>0.803947</td>\n",
       "      <td>1.342816</td>\n",
       "      <td>0.739264</td>\n",
       "      <td>0.29589</td>\n",
       "      <td>0.995308</td>\n",
       "      <td>1.241366</td>\n",
       "      <td>1.237255</td>\n",
       "      <td>1.636341</td>\n",
       "      <td>-0.183244</td>\n",
       "      <td>1.725030</td>\n",
       "      <td>-0.356303</td>\n",
       "      <td>1.662194</td>\n",
       "      <td>0.894948</td>\n",
       "      <td>0.804832</td>\n",
       "      <td>0.892424</td>\n",
       "      <td>-0.191768</td>\n",
       "      <td>0.402837</td>\n",
       "      <td>1.011969</td>\n",
       "      <td>1.667083</td>\n",
       "      <td>0.674694</td>\n",
       "      <td>-0.028718</td>\n",
       "      <td>0.514525</td>\n",
       "      <td>1.526335</td>\n",
       "      <td>1.432970</td>\n",
       "      <td>2.591129</td>\n",
       "      <td>0.994217</td>\n",
       "      <td>1.054511</td>\n",
       "      <td>1.042615</td>\n",
       "      <td>2.432304</td>\n",
       "      <td>-0.14449</td>\n",
       "      <td>1.503569</td>\n",
       "      <td>1.239407</td>\n",
       "      <td>1.742640</td>\n",
       "      <td>-0.042189</td>\n",
       "      <td>1.873777</td>\n",
       "      <td>-0.284724</td>\n",
       "      <td>0.675531</td>\n",
       "      <td>1.652838</td>\n",
       "      <td>-0.033802</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>1.72043</td>\n",
       "      <td>1.822244</td>\n",
       "      <td>0.816915</td>\n",
       "      <td>0.397178</td>\n",
       "      <td>1.574612</td>\n",
       "      <td>-1.378728</td>\n",
       "      <td>-0.145302</td>\n",
       "      <td>-0.759998</td>\n",
       "      <td>0.257853</td>\n",
       "      <td>-0.203484</td>\n",
       "      <td>-1.078432</td>\n",
       "      <td>0.042876</td>\n",
       "      <td>0.360192</td>\n",
       "      <td>-0.196545</td>\n",
       "      <td>-0.094803</td>\n",
       "      <td>-0.098434</td>\n",
       "      <td>-0.092693</td>\n",
       "      <td>-0.039137</td>\n",
       "      <td>-0.030306</td>\n",
       "      <td>-0.215803</td>\n",
       "      <td>-0.113225</td>\n",
       "      <td>-0.046189</td>\n",
       "      <td>-0.032914</td>\n",
       "      <td>-0.268532</td>\n",
       "      <td>-0.033820</td>\n",
       "      <td>-0.098328</td>\n",
       "      <td>-0.047102</td>\n",
       "      <td>-0.236331</td>\n",
       "      <td>-0.147581</td>\n",
       "      <td>3.269944</td>\n",
       "      <td>3.383160</td>\n",
       "      <td>-0.323817</td>\n",
       "      <td>-0.576067</td>\n",
       "      <td>-0.309651</td>\n",
       "      <td>-0.155767</td>\n",
       "      <td>-0.099152</td>\n",
       "      <td>6.159508</td>\n",
       "      <td>2.726051</td>\n",
       "      <td>-0.616023</td>\n",
       "      <td>-0.503169</td>\n",
       "      <td>-0.133469</td>\n",
       "      <td>-0.08284</td>\n",
       "      <td>-0.127827</td>\n",
       "      <td>-0.710153</td>\n",
       "      <td>-1.025429</td>\n",
       "      <td>-0.923236</td>\n",
       "      <td>-1.053204</td>\n",
       "      <td>-0.995398</td>\n",
       "      <td>-1.328185</td>\n",
       "      <td>-1.476095</td>\n",
       "      <td>-1.175716</td>\n",
       "      <td>-0.321885</td>\n",
       "      <td>-0.30961</td>\n",
       "      <td>-1.666740</td>\n",
       "      <td>-1.526172</td>\n",
       "      <td>-0.049281</td>\n",
       "      <td>-0.074508</td>\n",
       "      <td>-0.061936</td>\n",
       "      <td>-0.329338</td>\n",
       "      <td>-0.289522</td>\n",
       "      <td>-0.043091</td>\n",
       "      <td>-0.050719</td>\n",
       "      <td>-0.049673</td>\n",
       "      <td>-0.083152</td>\n",
       "      <td>-0.090258</td>\n",
       "      <td>-0.055307</td>\n",
       "      <td>-0.079258</td>\n",
       "      <td>-0.067677</td>\n",
       "      <td>-0.072755</td>\n",
       "      <td>-0.288973</td>\n",
       "      <td>-0.187140</td>\n",
       "      <td>-0.045542</td>\n",
       "      <td>-0.053788</td>\n",
       "      <td>-0.052465</td>\n",
       "      <td>-0.058679</td>\n",
       "      <td>-0.085678</td>\n",
       "      <td>-0.075511</td>\n",
       "      <td>-0.031701</td>\n",
       "      <td>1.362797</td>\n",
       "      <td>1.250752</td>\n",
       "      <td>-0.055918</td>\n",
       "      <td>-0.12476</td>\n",
       "      <td>-0.121427</td>\n",
       "      <td>-0.083953</td>\n",
       "      <td>-0.082158</td>\n",
       "      <td>2.625280</td>\n",
       "      <td>2.513603</td>\n",
       "      <td>-0.115427</td>\n",
       "      <td>0.017917</td>\n",
       "      <td>-0.035053</td>\n",
       "      <td>2.582140</td>\n",
       "      <td>2.477739</td>\n",
       "      <td>2.337768</td>\n",
       "      <td>2.227617</td>\n",
       "      <td>-0.115576</td>\n",
       "      <td>-0.118405</td>\n",
       "      <td>-0.030455</td>\n",
       "      <td>-0.035149</td>\n",
       "      <td>-0.03225</td>\n",
       "      <td>-0.053456</td>\n",
       "      <td>-0.097952</td>\n",
       "      <td>-0.10278</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.052381</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>-0.324797</td>\n",
       "      <td>-0.288607</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>0.632101</td>\n",
       "      <td>-0.041292</td>\n",
       "      <td>-0.046295</td>\n",
       "      <td>-0.046597</td>\n",
       "      <td>-0.07271</td>\n",
       "      <td>-0.097544</td>\n",
       "      <td>-0.071066</td>\n",
       "      <td>-0.079106</td>\n",
       "      <td>-0.119359</td>\n",
       "      <td>0.945534</td>\n",
       "      <td>0.115029</td>\n",
       "      <td>-0.447665</td>\n",
       "      <td>-0.422654</td>\n",
       "      <td>0.805797</td>\n",
       "      <td>1.343141</td>\n",
       "      <td>0.510182</td>\n",
       "      <td>0.752479</td>\n",
       "      <td>1.04627</td>\n",
       "      <td>-0.483298</td>\n",
       "      <td>0.714725</td>\n",
       "      <td>-0.34294</td>\n",
       "      <td>-0.323017</td>\n",
       "      <td>-0.045791</td>\n",
       "      <td>-0.057194</td>\n",
       "      <td>-0.054842</td>\n",
       "      <td>-0.031881</td>\n",
       "      <td>-0.015007</td>\n",
       "      <td>-0.037858</td>\n",
       "      <td>-0.072124</td>\n",
       "      <td>-0.067005</td>\n",
       "      <td>-0.079805</td>\n",
       "      <td>-0.040947</td>\n",
       "      <td>-0.0494</td>\n",
       "      <td>-0.047343</td>\n",
       "      <td>-0.032528</td>\n",
       "      <td>-0.061764</td>\n",
       "      <td>-0.050674</td>\n",
       "      <td>-0.052212</td>\n",
       "      <td>-0.058176</td>\n",
       "      <td>-0.053373</td>\n",
       "      <td>-0.08205</td>\n",
       "      <td>0.524086</td>\n",
       "      <td>0.471147</td>\n",
       "      <td>-0.053747</td>\n",
       "      <td>-0.069811</td>\n",
       "      <td>-0.04128</td>\n",
       "      <td>-0.041151</td>\n",
       "      <td>0.803852</td>\n",
       "      <td>0.302501</td>\n",
       "      <td>0.580496</td>\n",
       "      <td>-0.040645</td>\n",
       "      <td>-0.045145</td>\n",
       "      <td>-0.042053</td>\n",
       "      <td>-0.08919</td>\n",
       "      <td>-0.095307</td>\n",
       "      <td>-0.066844</td>\n",
       "      <td>-0.069129</td>\n",
       "      <td>-0.10873</td>\n",
       "      <td>-0.108326</td>\n",
       "      <td>1.355961</td>\n",
       "      <td>0.910857</td>\n",
       "      <td>1.324832</td>\n",
       "      <td>0.896841</td>\n",
       "      <td>1.063006</td>\n",
       "      <td>1.268468</td>\n",
       "      <td>1.551700</td>\n",
       "      <td>1.663359</td>\n",
       "      <td>0.429967</td>\n",
       "      <td>0.993293</td>\n",
       "      <td>1.437926</td>\n",
       "      <td>1.400867</td>\n",
       "      <td>0.896987</td>\n",
       "      <td>0.641202</td>\n",
       "      <td>0.747955</td>\n",
       "      <td>0.988099</td>\n",
       "      <td>1.518115</td>\n",
       "      <td>-0.041485</td>\n",
       "      <td>-0.041062</td>\n",
       "      <td>-0.044216</td>\n",
       "      <td>-0.019603</td>\n",
       "      <td>-0.02641</td>\n",
       "      <td>-0.027637</td>\n",
       "      <td>-0.012979</td>\n",
       "      <td>-0.057632</td>\n",
       "      <td>-0.062164</td>\n",
       "      <td>-0.059283</td>\n",
       "      <td>-0.036909</td>\n",
       "      <td>-0.03958</td>\n",
       "      <td>-0.038675</td>\n",
       "      <td>-0.023196</td>\n",
       "      <td>-0.032106</td>\n",
       "      <td>-0.028872</td>\n",
       "      <td>-0.053422</td>\n",
       "      <td>-0.070625</td>\n",
       "      <td>-0.170618</td>\n",
       "      <td>-0.882906</td>\n",
       "      <td>-0.630863</td>\n",
       "      <td>-0.357205</td>\n",
       "      <td>-0.332543</td>\n",
       "      <td>-0.131711</td>\n",
       "      <td>-0.04042</td>\n",
       "      <td>-0.062849</td>\n",
       "      <td>-0.045744</td>\n",
       "      <td>-0.058539</td>\n",
       "      <td>-0.055212</td>\n",
       "      <td>-0.10044</td>\n",
       "      <td>-0.093916</td>\n",
       "      <td>-0.099373</td>\n",
       "      <td>1.147385</td>\n",
       "      <td>-0.059471</td>\n",
       "      <td>-0.092981</td>\n",
       "      <td>-0.076203</td>\n",
       "      <td>-0.089662</td>\n",
       "      <td>-0.332187</td>\n",
       "      <td>-0.038594</td>\n",
       "      <td>-0.221127</td>\n",
       "      <td>-0.221827</td>\n",
       "      <td>-0.249078</td>\n",
       "      <td>-0.228881</td>\n",
       "      <td>-0.048346</td>\n",
       "      <td>-0.062216</td>\n",
       "      <td>-0.057999</td>\n",
       "      <td>-0.054761</td>\n",
       "      <td>-0.088248</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.041168</td>\n",
       "      <td>-0.045422</td>\n",
       "      <td>-0.046141</td>\n",
       "      <td>-0.078694</td>\n",
       "      <td>-0.05516</td>\n",
       "      <td>-0.060439</td>\n",
       "      <td>-0.043013</td>\n",
       "      <td>-0.045611</td>\n",
       "      <td>-0.047175</td>\n",
       "      <td>-0.014289</td>\n",
       "      <td>-0.054151</td>\n",
       "      <td>-0.036347</td>\n",
       "      <td>-0.029533</td>\n",
       "      <td>-0.050234</td>\n",
       "      <td>-0.044481</td>\n",
       "      <td>-0.300668</td>\n",
       "      <td>0.153944</td>\n",
       "      <td>-0.034193</td>\n",
       "      <td>-0.142894</td>\n",
       "      <td>0.184399</td>\n",
       "      <td>-0.07117</td>\n",
       "      <td>0.077504</td>\n",
       "      <td>-0.032413</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>1.788536</td>\n",
       "      <td>2.027221</td>\n",
       "      <td>-2.546586</td>\n",
       "      <td>1.479831</td>\n",
       "      <td>1.313585</td>\n",
       "      <td>0.634663</td>\n",
       "      <td>-0.08243</td>\n",
       "      <td>-0.086243</td>\n",
       "      <td>-0.089706</td>\n",
       "      <td>-0.091688</td>\n",
       "      <td>2.674988</td>\n",
       "      <td>2.529625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.209963</td>\n",
       "      <td>-0.544587</td>\n",
       "      <td>0.407824</td>\n",
       "      <td>-0.434818</td>\n",
       "      <td>-0.041814</td>\n",
       "      <td>-1.083156</td>\n",
       "      <td>-0.551276</td>\n",
       "      <td>-0.546267</td>\n",
       "      <td>0.643397</td>\n",
       "      <td>-0.537535</td>\n",
       "      <td>-0.566493</td>\n",
       "      <td>-0.542801</td>\n",
       "      <td>-0.533175</td>\n",
       "      <td>-0.108377</td>\n",
       "      <td>-0.385432</td>\n",
       "      <td>-0.663889</td>\n",
       "      <td>-0.634533</td>\n",
       "      <td>-0.136447</td>\n",
       "      <td>-0.069307</td>\n",
       "      <td>-0.544537</td>\n",
       "      <td>-1.007672</td>\n",
       "      <td>-0.083475</td>\n",
       "      <td>-0.339302</td>\n",
       "      <td>-0.004593</td>\n",
       "      <td>-0.990970</td>\n",
       "      <td>-0.413764</td>\n",
       "      <td>-0.083589</td>\n",
       "      <td>-1.227512</td>\n",
       "      <td>-0.193018</td>\n",
       "      <td>-1.019015</td>\n",
       "      <td>-0.526503</td>\n",
       "      <td>-0.527372</td>\n",
       "      <td>-0.553863</td>\n",
       "      <td>0.596366</td>\n",
       "      <td>-0.972753</td>\n",
       "      <td>-1.059143</td>\n",
       "      <td>-0.272797</td>\n",
       "      <td>-0.389465</td>\n",
       "      <td>-0.093859</td>\n",
       "      <td>-0.493680</td>\n",
       "      <td>-0.294501</td>\n",
       "      <td>-0.529056</td>\n",
       "      <td>-0.542678</td>\n",
       "      <td>-0.300054</td>\n",
       "      <td>-0.965816</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>-0.553826</td>\n",
       "      <td>-0.205104</td>\n",
       "      <td>-0.540532</td>\n",
       "      <td>-0.524318</td>\n",
       "      <td>-0.298381</td>\n",
       "      <td>-0.326247</td>\n",
       "      <td>-0.559101</td>\n",
       "      <td>-0.533809</td>\n",
       "      <td>-0.039890</td>\n",
       "      <td>-1.102171</td>\n",
       "      <td>-0.397750</td>\n",
       "      <td>-0.055439</td>\n",
       "      <td>-0.228292</td>\n",
       "      <td>0.748619</td>\n",
       "      <td>-0.531932</td>\n",
       "      <td>-0.656132</td>\n",
       "      <td>-0.076617</td>\n",
       "      <td>-0.169905</td>\n",
       "      <td>-0.154066</td>\n",
       "      <td>-0.234589</td>\n",
       "      <td>-0.501808</td>\n",
       "      <td>-0.031981</td>\n",
       "      <td>-0.346458</td>\n",
       "      <td>-0.985232</td>\n",
       "      <td>-0.569585</td>\n",
       "      <td>-0.526942</td>\n",
       "      <td>-0.174917</td>\n",
       "      <td>-0.535487</td>\n",
       "      <td>-0.522041</td>\n",
       "      <td>-0.553407</td>\n",
       "      <td>-0.540160</td>\n",
       "      <td>-0.996581</td>\n",
       "      <td>-0.352363</td>\n",
       "      <td>-0.066125</td>\n",
       "      <td>-0.065564</td>\n",
       "      <td>-0.422264</td>\n",
       "      <td>0.684057</td>\n",
       "      <td>-1.019282</td>\n",
       "      <td>-0.162702</td>\n",
       "      <td>-0.327293</td>\n",
       "      <td>-0.408597</td>\n",
       "      <td>-1.331973</td>\n",
       "      <td>-0.407192</td>\n",
       "      <td>-0.633584</td>\n",
       "      <td>-0.542823</td>\n",
       "      <td>-0.090673</td>\n",
       "      <td>-0.558720</td>\n",
       "      <td>-0.376049</td>\n",
       "      <td>-0.531279</td>\n",
       "      <td>-0.560236</td>\n",
       "      <td>0.744573</td>\n",
       "      <td>0.706391</td>\n",
       "      <td>-0.377186</td>\n",
       "      <td>-0.04969</td>\n",
       "      <td>-0.354550</td>\n",
       "      <td>-1.188271</td>\n",
       "      <td>-0.22275</td>\n",
       "      <td>-0.535084</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>-0.528523</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>-0.528749</td>\n",
       "      <td>-0.100484</td>\n",
       "      <td>-0.114522</td>\n",
       "      <td>-0.182099</td>\n",
       "      <td>-0.463749</td>\n",
       "      <td>-0.566417</td>\n",
       "      <td>-0.551901</td>\n",
       "      <td>-0.660177</td>\n",
       "      <td>-0.116566</td>\n",
       "      <td>-1.002589</td>\n",
       "      <td>-0.556132</td>\n",
       "      <td>-0.130335</td>\n",
       "      <td>-0.922256</td>\n",
       "      <td>-0.527387</td>\n",
       "      <td>-0.964954</td>\n",
       "      <td>-0.390305</td>\n",
       "      <td>-0.532699</td>\n",
       "      <td>0.079730</td>\n",
       "      <td>-0.957024</td>\n",
       "      <td>0.686806</td>\n",
       "      <td>-0.05709</td>\n",
       "      <td>-0.528080</td>\n",
       "      <td>-0.553281</td>\n",
       "      <td>-0.556269</td>\n",
       "      <td>-0.494734</td>\n",
       "      <td>-0.183244</td>\n",
       "      <td>-0.411473</td>\n",
       "      <td>-0.356303</td>\n",
       "      <td>-0.231481</td>\n",
       "      <td>-0.550550</td>\n",
       "      <td>0.080027</td>\n",
       "      <td>0.646860</td>\n",
       "      <td>-0.083471</td>\n",
       "      <td>-0.632061</td>\n",
       "      <td>-0.973044</td>\n",
       "      <td>-0.045786</td>\n",
       "      <td>0.704683</td>\n",
       "      <td>-0.028718</td>\n",
       "      <td>-0.526444</td>\n",
       "      <td>-0.348024</td>\n",
       "      <td>-0.550072</td>\n",
       "      <td>-0.381317</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>-0.948280</td>\n",
       "      <td>-0.977981</td>\n",
       "      <td>-0.349760</td>\n",
       "      <td>-0.14449</td>\n",
       "      <td>-0.241668</td>\n",
       "      <td>-0.542326</td>\n",
       "      <td>-0.556514</td>\n",
       "      <td>-0.042189</td>\n",
       "      <td>-0.533263</td>\n",
       "      <td>-0.284724</td>\n",
       "      <td>0.703487</td>\n",
       "      <td>-0.507690</td>\n",
       "      <td>-0.033802</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>-0.58175</td>\n",
       "      <td>-0.438362</td>\n",
       "      <td>-0.893489</td>\n",
       "      <td>-0.633937</td>\n",
       "      <td>-0.539156</td>\n",
       "      <td>-0.079104</td>\n",
       "      <td>-0.435353</td>\n",
       "      <td>-0.408558</td>\n",
       "      <td>-0.074010</td>\n",
       "      <td>-0.203484</td>\n",
       "      <td>0.588719</td>\n",
       "      <td>-0.869556</td>\n",
       "      <td>0.360192</td>\n",
       "      <td>-0.180097</td>\n",
       "      <td>-0.101669</td>\n",
       "      <td>-0.098434</td>\n",
       "      <td>-0.092693</td>\n",
       "      <td>-0.039137</td>\n",
       "      <td>-0.059583</td>\n",
       "      <td>-0.215803</td>\n",
       "      <td>-0.113225</td>\n",
       "      <td>-0.046189</td>\n",
       "      <td>-0.054075</td>\n",
       "      <td>-0.208426</td>\n",
       "      <td>-0.054926</td>\n",
       "      <td>-0.098328</td>\n",
       "      <td>-0.047102</td>\n",
       "      <td>-0.251869</td>\n",
       "      <td>-0.167893</td>\n",
       "      <td>-0.597478</td>\n",
       "      <td>-0.578065</td>\n",
       "      <td>-0.323817</td>\n",
       "      <td>-0.576067</td>\n",
       "      <td>-0.309651</td>\n",
       "      <td>-0.155767</td>\n",
       "      <td>-0.099152</td>\n",
       "      <td>-0.193691</td>\n",
       "      <td>-0.326769</td>\n",
       "      <td>-0.616023</td>\n",
       "      <td>-0.503169</td>\n",
       "      <td>-0.133469</td>\n",
       "      <td>-0.08284</td>\n",
       "      <td>-0.127827</td>\n",
       "      <td>-0.710153</td>\n",
       "      <td>0.271492</td>\n",
       "      <td>0.189757</td>\n",
       "      <td>0.308174</td>\n",
       "      <td>0.248921</td>\n",
       "      <td>0.034181</td>\n",
       "      <td>0.123804</td>\n",
       "      <td>0.034274</td>\n",
       "      <td>-0.321885</td>\n",
       "      <td>-0.30961</td>\n",
       "      <td>0.177113</td>\n",
       "      <td>0.108959</td>\n",
       "      <td>-0.049281</td>\n",
       "      <td>-0.074508</td>\n",
       "      <td>-0.061936</td>\n",
       "      <td>-0.329338</td>\n",
       "      <td>-0.289522</td>\n",
       "      <td>-0.043091</td>\n",
       "      <td>-0.050719</td>\n",
       "      <td>-0.049673</td>\n",
       "      <td>-0.083152</td>\n",
       "      <td>-0.090258</td>\n",
       "      <td>-0.055307</td>\n",
       "      <td>-0.079258</td>\n",
       "      <td>-0.067677</td>\n",
       "      <td>-0.072755</td>\n",
       "      <td>-0.288973</td>\n",
       "      <td>-0.187140</td>\n",
       "      <td>-0.045542</td>\n",
       "      <td>-0.053788</td>\n",
       "      <td>-0.052465</td>\n",
       "      <td>-0.058679</td>\n",
       "      <td>-0.085678</td>\n",
       "      <td>-0.075511</td>\n",
       "      <td>-0.031701</td>\n",
       "      <td>-0.239792</td>\n",
       "      <td>-0.232437</td>\n",
       "      <td>-0.055918</td>\n",
       "      <td>-0.12476</td>\n",
       "      <td>-0.121427</td>\n",
       "      <td>-0.083953</td>\n",
       "      <td>-0.082158</td>\n",
       "      <td>-0.312521</td>\n",
       "      <td>-0.303912</td>\n",
       "      <td>-0.118531</td>\n",
       "      <td>-0.146723</td>\n",
       "      <td>-0.150773</td>\n",
       "      <td>-0.308673</td>\n",
       "      <td>-0.300664</td>\n",
       "      <td>-0.300284</td>\n",
       "      <td>-0.292522</td>\n",
       "      <td>-0.115576</td>\n",
       "      <td>-0.118405</td>\n",
       "      <td>-0.030455</td>\n",
       "      <td>-0.035149</td>\n",
       "      <td>-0.03225</td>\n",
       "      <td>-0.053456</td>\n",
       "      <td>-0.097952</td>\n",
       "      <td>-0.10278</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.052381</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>-0.324797</td>\n",
       "      <td>-0.288607</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>-0.306484</td>\n",
       "      <td>-0.041292</td>\n",
       "      <td>-0.046295</td>\n",
       "      <td>-0.046597</td>\n",
       "      <td>-0.07271</td>\n",
       "      <td>-0.097544</td>\n",
       "      <td>-0.071066</td>\n",
       "      <td>-0.079106</td>\n",
       "      <td>-0.119359</td>\n",
       "      <td>-0.353630</td>\n",
       "      <td>-0.089382</td>\n",
       "      <td>-0.447665</td>\n",
       "      <td>-0.422654</td>\n",
       "      <td>-0.325115</td>\n",
       "      <td>-0.450097</td>\n",
       "      <td>-0.211605</td>\n",
       "      <td>-0.281908</td>\n",
       "      <td>-0.36208</td>\n",
       "      <td>-0.483298</td>\n",
       "      <td>-0.308233</td>\n",
       "      <td>-0.34294</td>\n",
       "      <td>-0.323017</td>\n",
       "      <td>-0.045791</td>\n",
       "      <td>-0.057194</td>\n",
       "      <td>-0.054842</td>\n",
       "      <td>-0.031881</td>\n",
       "      <td>-0.015007</td>\n",
       "      <td>-0.037858</td>\n",
       "      <td>-0.072124</td>\n",
       "      <td>-0.067005</td>\n",
       "      <td>-0.079805</td>\n",
       "      <td>-0.040947</td>\n",
       "      <td>-0.0494</td>\n",
       "      <td>-0.047343</td>\n",
       "      <td>-0.032528</td>\n",
       "      <td>-0.061764</td>\n",
       "      <td>-0.050674</td>\n",
       "      <td>-0.052212</td>\n",
       "      <td>-0.058176</td>\n",
       "      <td>-0.053373</td>\n",
       "      <td>-0.08205</td>\n",
       "      <td>-0.230531</td>\n",
       "      <td>-0.227590</td>\n",
       "      <td>-0.053747</td>\n",
       "      <td>-0.069811</td>\n",
       "      <td>-0.04128</td>\n",
       "      <td>-0.041151</td>\n",
       "      <td>-0.343569</td>\n",
       "      <td>-0.171602</td>\n",
       "      <td>-0.278643</td>\n",
       "      <td>-0.040645</td>\n",
       "      <td>-0.045145</td>\n",
       "      <td>-0.042053</td>\n",
       "      <td>-0.08919</td>\n",
       "      <td>-0.095307</td>\n",
       "      <td>-0.066844</td>\n",
       "      <td>-0.069129</td>\n",
       "      <td>-0.10873</td>\n",
       "      <td>-0.108326</td>\n",
       "      <td>-0.443577</td>\n",
       "      <td>-0.321263</td>\n",
       "      <td>-0.436050</td>\n",
       "      <td>-0.238435</td>\n",
       "      <td>-0.377649</td>\n",
       "      <td>-0.393050</td>\n",
       "      <td>-0.465556</td>\n",
       "      <td>-0.492519</td>\n",
       "      <td>-0.148389</td>\n",
       "      <td>-0.309876</td>\n",
       "      <td>-0.345461</td>\n",
       "      <td>-0.340874</td>\n",
       "      <td>-0.343962</td>\n",
       "      <td>-0.271606</td>\n",
       "      <td>-0.225907</td>\n",
       "      <td>-0.319623</td>\n",
       "      <td>-0.438433</td>\n",
       "      <td>-0.041485</td>\n",
       "      <td>-0.041062</td>\n",
       "      <td>-0.044216</td>\n",
       "      <td>-0.019603</td>\n",
       "      <td>-0.02641</td>\n",
       "      <td>-0.027637</td>\n",
       "      <td>-0.012979</td>\n",
       "      <td>-0.057632</td>\n",
       "      <td>-0.062164</td>\n",
       "      <td>-0.059283</td>\n",
       "      <td>-0.036909</td>\n",
       "      <td>-0.03958</td>\n",
       "      <td>-0.038675</td>\n",
       "      <td>-0.023196</td>\n",
       "      <td>-0.032106</td>\n",
       "      <td>-0.028872</td>\n",
       "      <td>-0.053422</td>\n",
       "      <td>-0.070625</td>\n",
       "      <td>-0.170618</td>\n",
       "      <td>0.199917</td>\n",
       "      <td>0.007098</td>\n",
       "      <td>-0.357205</td>\n",
       "      <td>-0.332543</td>\n",
       "      <td>-0.131711</td>\n",
       "      <td>-0.04042</td>\n",
       "      <td>-0.062849</td>\n",
       "      <td>-0.045744</td>\n",
       "      <td>-0.058539</td>\n",
       "      <td>-0.055212</td>\n",
       "      <td>-0.10044</td>\n",
       "      <td>-0.093916</td>\n",
       "      <td>-0.099373</td>\n",
       "      <td>-0.454447</td>\n",
       "      <td>-0.059471</td>\n",
       "      <td>-0.092981</td>\n",
       "      <td>-0.076203</td>\n",
       "      <td>-0.089662</td>\n",
       "      <td>-0.332187</td>\n",
       "      <td>-0.038594</td>\n",
       "      <td>-0.221127</td>\n",
       "      <td>-0.221827</td>\n",
       "      <td>-0.249078</td>\n",
       "      <td>-0.228881</td>\n",
       "      <td>-0.048346</td>\n",
       "      <td>-0.062216</td>\n",
       "      <td>-0.057999</td>\n",
       "      <td>-0.054761</td>\n",
       "      <td>-0.088248</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.041168</td>\n",
       "      <td>-0.045422</td>\n",
       "      <td>-0.046141</td>\n",
       "      <td>-0.078694</td>\n",
       "      <td>-0.05516</td>\n",
       "      <td>-0.060439</td>\n",
       "      <td>-0.043013</td>\n",
       "      <td>-0.045611</td>\n",
       "      <td>-0.047175</td>\n",
       "      <td>-0.014289</td>\n",
       "      <td>-0.054151</td>\n",
       "      <td>-0.036347</td>\n",
       "      <td>-0.029533</td>\n",
       "      <td>-0.050234</td>\n",
       "      <td>-0.044481</td>\n",
       "      <td>0.298722</td>\n",
       "      <td>-0.387232</td>\n",
       "      <td>-0.034193</td>\n",
       "      <td>-0.142894</td>\n",
       "      <td>0.184399</td>\n",
       "      <td>-0.07117</td>\n",
       "      <td>0.077504</td>\n",
       "      <td>-0.032413</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>-0.560911</td>\n",
       "      <td>-0.506029</td>\n",
       "      <td>0.380593</td>\n",
       "      <td>-0.547637</td>\n",
       "      <td>-0.506005</td>\n",
       "      <td>-0.511042</td>\n",
       "      <td>-0.08243</td>\n",
       "      <td>-0.086243</td>\n",
       "      <td>-0.089706</td>\n",
       "      <td>-0.091688</td>\n",
       "      <td>-0.357827</td>\n",
       "      <td>-0.356561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.209963</td>\n",
       "      <td>-0.544587</td>\n",
       "      <td>-0.803152</td>\n",
       "      <td>-0.434818</td>\n",
       "      <td>-0.041814</td>\n",
       "      <td>-1.083156</td>\n",
       "      <td>-0.551276</td>\n",
       "      <td>-0.546267</td>\n",
       "      <td>-1.449451</td>\n",
       "      <td>-0.537535</td>\n",
       "      <td>-0.566493</td>\n",
       "      <td>-0.542801</td>\n",
       "      <td>-0.533175</td>\n",
       "      <td>-0.108377</td>\n",
       "      <td>-0.385432</td>\n",
       "      <td>-0.663889</td>\n",
       "      <td>-0.634533</td>\n",
       "      <td>-0.136447</td>\n",
       "      <td>-0.069307</td>\n",
       "      <td>-0.544537</td>\n",
       "      <td>1.007737</td>\n",
       "      <td>-0.083475</td>\n",
       "      <td>-0.339302</td>\n",
       "      <td>-0.004593</td>\n",
       "      <td>1.032669</td>\n",
       "      <td>-0.413764</td>\n",
       "      <td>-0.083589</td>\n",
       "      <td>0.837200</td>\n",
       "      <td>-0.193018</td>\n",
       "      <td>1.036899</td>\n",
       "      <td>-0.526503</td>\n",
       "      <td>-0.527372</td>\n",
       "      <td>-0.553863</td>\n",
       "      <td>0.519333</td>\n",
       "      <td>-0.972753</td>\n",
       "      <td>-1.059143</td>\n",
       "      <td>-0.272797</td>\n",
       "      <td>-0.389465</td>\n",
       "      <td>-0.093859</td>\n",
       "      <td>-0.493680</td>\n",
       "      <td>-0.294501</td>\n",
       "      <td>-0.529056</td>\n",
       "      <td>-0.542678</td>\n",
       "      <td>-0.300054</td>\n",
       "      <td>1.047713</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>-0.553826</td>\n",
       "      <td>-0.205104</td>\n",
       "      <td>-0.540532</td>\n",
       "      <td>-0.524318</td>\n",
       "      <td>-0.298381</td>\n",
       "      <td>-0.326247</td>\n",
       "      <td>-0.559101</td>\n",
       "      <td>-0.533809</td>\n",
       "      <td>-0.039890</td>\n",
       "      <td>1.024527</td>\n",
       "      <td>-0.397750</td>\n",
       "      <td>-0.055439</td>\n",
       "      <td>-0.228292</td>\n",
       "      <td>-1.660800</td>\n",
       "      <td>-0.531932</td>\n",
       "      <td>-0.656132</td>\n",
       "      <td>-0.076617</td>\n",
       "      <td>-0.029009</td>\n",
       "      <td>-0.154066</td>\n",
       "      <td>-0.234589</td>\n",
       "      <td>-0.501808</td>\n",
       "      <td>-0.031981</td>\n",
       "      <td>-0.346458</td>\n",
       "      <td>1.020952</td>\n",
       "      <td>-0.569585</td>\n",
       "      <td>-0.526942</td>\n",
       "      <td>-0.174917</td>\n",
       "      <td>-0.535487</td>\n",
       "      <td>-0.522041</td>\n",
       "      <td>-0.553407</td>\n",
       "      <td>-0.540160</td>\n",
       "      <td>1.036516</td>\n",
       "      <td>-0.352363</td>\n",
       "      <td>-0.066125</td>\n",
       "      <td>-0.065564</td>\n",
       "      <td>-0.422264</td>\n",
       "      <td>-1.452824</td>\n",
       "      <td>-1.019282</td>\n",
       "      <td>-0.162702</td>\n",
       "      <td>-0.327293</td>\n",
       "      <td>-0.408597</td>\n",
       "      <td>0.806283</td>\n",
       "      <td>-0.407192</td>\n",
       "      <td>-0.633584</td>\n",
       "      <td>-0.542823</td>\n",
       "      <td>-0.090673</td>\n",
       "      <td>-0.558720</td>\n",
       "      <td>-0.376049</td>\n",
       "      <td>-0.531279</td>\n",
       "      <td>-0.560236</td>\n",
       "      <td>-1.685703</td>\n",
       "      <td>-0.032092</td>\n",
       "      <td>-0.377186</td>\n",
       "      <td>-0.04969</td>\n",
       "      <td>-0.354550</td>\n",
       "      <td>-1.188271</td>\n",
       "      <td>-0.22275</td>\n",
       "      <td>-0.535084</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>-0.528523</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>-0.528749</td>\n",
       "      <td>-0.100484</td>\n",
       "      <td>-0.114522</td>\n",
       "      <td>-0.182099</td>\n",
       "      <td>-0.463749</td>\n",
       "      <td>-0.566417</td>\n",
       "      <td>-0.551901</td>\n",
       "      <td>-0.660177</td>\n",
       "      <td>-0.116566</td>\n",
       "      <td>-1.002589</td>\n",
       "      <td>-0.556132</td>\n",
       "      <td>-0.130335</td>\n",
       "      <td>1.084328</td>\n",
       "      <td>-0.527387</td>\n",
       "      <td>1.048459</td>\n",
       "      <td>-0.390305</td>\n",
       "      <td>-0.532699</td>\n",
       "      <td>0.803947</td>\n",
       "      <td>-0.957024</td>\n",
       "      <td>-1.465056</td>\n",
       "      <td>-0.05709</td>\n",
       "      <td>-0.528080</td>\n",
       "      <td>-0.553281</td>\n",
       "      <td>-0.556269</td>\n",
       "      <td>-0.494734</td>\n",
       "      <td>-0.183244</td>\n",
       "      <td>-0.411473</td>\n",
       "      <td>-0.356303</td>\n",
       "      <td>-0.231481</td>\n",
       "      <td>-0.550550</td>\n",
       "      <td>0.804832</td>\n",
       "      <td>-1.461539</td>\n",
       "      <td>-0.083471</td>\n",
       "      <td>-0.632061</td>\n",
       "      <td>1.011969</td>\n",
       "      <td>-0.045786</td>\n",
       "      <td>-1.466143</td>\n",
       "      <td>-0.028718</td>\n",
       "      <td>-0.526444</td>\n",
       "      <td>-0.931627</td>\n",
       "      <td>-0.550072</td>\n",
       "      <td>-0.381317</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>1.054511</td>\n",
       "      <td>1.042615</td>\n",
       "      <td>-0.349760</td>\n",
       "      <td>-0.14449</td>\n",
       "      <td>-0.241668</td>\n",
       "      <td>-0.542326</td>\n",
       "      <td>-0.556514</td>\n",
       "      <td>-0.042189</td>\n",
       "      <td>-0.533263</td>\n",
       "      <td>-0.284724</td>\n",
       "      <td>-1.448103</td>\n",
       "      <td>-0.507690</td>\n",
       "      <td>-0.033802</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>1.72043</td>\n",
       "      <td>-0.438362</td>\n",
       "      <td>0.816915</td>\n",
       "      <td>-0.633937</td>\n",
       "      <td>-0.539156</td>\n",
       "      <td>-1.148460</td>\n",
       "      <td>-0.112365</td>\n",
       "      <td>0.364489</td>\n",
       "      <td>-1.512083</td>\n",
       "      <td>-0.203484</td>\n",
       "      <td>0.633778</td>\n",
       "      <td>-0.507599</td>\n",
       "      <td>0.360192</td>\n",
       "      <td>-0.196545</td>\n",
       "      <td>-0.101669</td>\n",
       "      <td>-0.098434</td>\n",
       "      <td>-0.092693</td>\n",
       "      <td>-0.039137</td>\n",
       "      <td>-0.059583</td>\n",
       "      <td>-0.176940</td>\n",
       "      <td>-0.113225</td>\n",
       "      <td>-0.046189</td>\n",
       "      <td>-0.054075</td>\n",
       "      <td>-0.208426</td>\n",
       "      <td>-0.054926</td>\n",
       "      <td>-0.098328</td>\n",
       "      <td>-0.047102</td>\n",
       "      <td>-0.135330</td>\n",
       "      <td>-0.147581</td>\n",
       "      <td>2.584096</td>\n",
       "      <td>2.680676</td>\n",
       "      <td>0.047895</td>\n",
       "      <td>2.320242</td>\n",
       "      <td>-0.032151</td>\n",
       "      <td>-0.155767</td>\n",
       "      <td>-0.099152</td>\n",
       "      <td>-0.193691</td>\n",
       "      <td>-0.326769</td>\n",
       "      <td>2.243298</td>\n",
       "      <td>-0.503169</td>\n",
       "      <td>-0.133469</td>\n",
       "      <td>-0.08284</td>\n",
       "      <td>-0.127827</td>\n",
       "      <td>1.853940</td>\n",
       "      <td>0.271492</td>\n",
       "      <td>0.189757</td>\n",
       "      <td>0.308174</td>\n",
       "      <td>0.248921</td>\n",
       "      <td>0.034181</td>\n",
       "      <td>0.123804</td>\n",
       "      <td>0.034274</td>\n",
       "      <td>-0.321885</td>\n",
       "      <td>-0.30961</td>\n",
       "      <td>0.177113</td>\n",
       "      <td>0.108959</td>\n",
       "      <td>-0.049281</td>\n",
       "      <td>-0.049607</td>\n",
       "      <td>-0.061936</td>\n",
       "      <td>0.039914</td>\n",
       "      <td>-0.289522</td>\n",
       "      <td>-0.043091</td>\n",
       "      <td>-0.050719</td>\n",
       "      <td>-0.049673</td>\n",
       "      <td>-0.083152</td>\n",
       "      <td>-0.090258</td>\n",
       "      <td>-0.055307</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.067677</td>\n",
       "      <td>-0.072755</td>\n",
       "      <td>0.338730</td>\n",
       "      <td>-0.187140</td>\n",
       "      <td>-0.045542</td>\n",
       "      <td>-0.053788</td>\n",
       "      <td>-0.052465</td>\n",
       "      <td>-0.058679</td>\n",
       "      <td>-0.085678</td>\n",
       "      <td>-0.075511</td>\n",
       "      <td>-0.031701</td>\n",
       "      <td>-0.239792</td>\n",
       "      <td>-0.232437</td>\n",
       "      <td>-0.055918</td>\n",
       "      <td>-0.12476</td>\n",
       "      <td>-0.121427</td>\n",
       "      <td>-0.083953</td>\n",
       "      <td>-0.082158</td>\n",
       "      <td>-0.312521</td>\n",
       "      <td>-0.303912</td>\n",
       "      <td>-0.118531</td>\n",
       "      <td>-0.146723</td>\n",
       "      <td>-0.150773</td>\n",
       "      <td>-0.308673</td>\n",
       "      <td>-0.300664</td>\n",
       "      <td>-0.300284</td>\n",
       "      <td>-0.292522</td>\n",
       "      <td>-0.115576</td>\n",
       "      <td>-0.118405</td>\n",
       "      <td>-0.030455</td>\n",
       "      <td>-0.035149</td>\n",
       "      <td>-0.03225</td>\n",
       "      <td>-0.053456</td>\n",
       "      <td>-0.097952</td>\n",
       "      <td>-0.10278</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.052381</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>-0.324797</td>\n",
       "      <td>-0.288607</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>-0.306484</td>\n",
       "      <td>-0.041292</td>\n",
       "      <td>-0.046295</td>\n",
       "      <td>-0.046597</td>\n",
       "      <td>-0.07271</td>\n",
       "      <td>-0.097544</td>\n",
       "      <td>-0.071066</td>\n",
       "      <td>-0.079106</td>\n",
       "      <td>-0.119359</td>\n",
       "      <td>-0.353630</td>\n",
       "      <td>-0.089382</td>\n",
       "      <td>-0.447665</td>\n",
       "      <td>-0.422654</td>\n",
       "      <td>-0.325115</td>\n",
       "      <td>-0.450097</td>\n",
       "      <td>-0.211605</td>\n",
       "      <td>-0.281908</td>\n",
       "      <td>-0.36208</td>\n",
       "      <td>-0.483298</td>\n",
       "      <td>-0.308233</td>\n",
       "      <td>-0.34294</td>\n",
       "      <td>-0.323017</td>\n",
       "      <td>-0.045791</td>\n",
       "      <td>-0.057194</td>\n",
       "      <td>-0.054842</td>\n",
       "      <td>-0.031881</td>\n",
       "      <td>-0.015007</td>\n",
       "      <td>-0.037858</td>\n",
       "      <td>-0.072124</td>\n",
       "      <td>-0.067005</td>\n",
       "      <td>-0.079805</td>\n",
       "      <td>-0.040947</td>\n",
       "      <td>-0.0494</td>\n",
       "      <td>-0.047343</td>\n",
       "      <td>-0.032528</td>\n",
       "      <td>-0.061764</td>\n",
       "      <td>-0.050674</td>\n",
       "      <td>-0.052212</td>\n",
       "      <td>-0.058176</td>\n",
       "      <td>-0.053373</td>\n",
       "      <td>-0.08205</td>\n",
       "      <td>-0.230531</td>\n",
       "      <td>-0.227590</td>\n",
       "      <td>-0.053747</td>\n",
       "      <td>-0.069811</td>\n",
       "      <td>-0.04128</td>\n",
       "      <td>-0.041151</td>\n",
       "      <td>-0.343569</td>\n",
       "      <td>-0.171602</td>\n",
       "      <td>-0.278643</td>\n",
       "      <td>-0.040645</td>\n",
       "      <td>-0.045145</td>\n",
       "      <td>-0.042053</td>\n",
       "      <td>-0.08919</td>\n",
       "      <td>-0.095307</td>\n",
       "      <td>-0.066844</td>\n",
       "      <td>-0.069129</td>\n",
       "      <td>-0.10873</td>\n",
       "      <td>-0.108326</td>\n",
       "      <td>-0.443577</td>\n",
       "      <td>-0.321263</td>\n",
       "      <td>-0.436050</td>\n",
       "      <td>-0.238435</td>\n",
       "      <td>-0.377649</td>\n",
       "      <td>-0.393050</td>\n",
       "      <td>-0.465556</td>\n",
       "      <td>-0.492519</td>\n",
       "      <td>-0.148389</td>\n",
       "      <td>-0.309876</td>\n",
       "      <td>-0.345461</td>\n",
       "      <td>-0.340874</td>\n",
       "      <td>-0.343962</td>\n",
       "      <td>-0.271606</td>\n",
       "      <td>-0.225907</td>\n",
       "      <td>-0.319623</td>\n",
       "      <td>-0.438433</td>\n",
       "      <td>-0.041485</td>\n",
       "      <td>-0.041062</td>\n",
       "      <td>-0.044216</td>\n",
       "      <td>-0.019603</td>\n",
       "      <td>-0.02641</td>\n",
       "      <td>-0.027637</td>\n",
       "      <td>-0.012979</td>\n",
       "      <td>-0.057632</td>\n",
       "      <td>-0.062164</td>\n",
       "      <td>-0.059283</td>\n",
       "      <td>-0.036909</td>\n",
       "      <td>-0.03958</td>\n",
       "      <td>-0.038675</td>\n",
       "      <td>-0.023196</td>\n",
       "      <td>-0.032106</td>\n",
       "      <td>-0.028872</td>\n",
       "      <td>-0.053422</td>\n",
       "      <td>-0.070625</td>\n",
       "      <td>-0.170618</td>\n",
       "      <td>-0.882906</td>\n",
       "      <td>-0.630863</td>\n",
       "      <td>-0.050212</td>\n",
       "      <td>-0.332543</td>\n",
       "      <td>-0.131711</td>\n",
       "      <td>-0.04042</td>\n",
       "      <td>-0.062849</td>\n",
       "      <td>-0.045744</td>\n",
       "      <td>-0.058539</td>\n",
       "      <td>-0.055212</td>\n",
       "      <td>-0.10044</td>\n",
       "      <td>-0.093916</td>\n",
       "      <td>-0.099373</td>\n",
       "      <td>-0.454447</td>\n",
       "      <td>-0.059471</td>\n",
       "      <td>-0.047467</td>\n",
       "      <td>-0.076203</td>\n",
       "      <td>-0.089662</td>\n",
       "      <td>0.230393</td>\n",
       "      <td>-0.038594</td>\n",
       "      <td>-0.221127</td>\n",
       "      <td>-0.221827</td>\n",
       "      <td>-0.249078</td>\n",
       "      <td>-0.228881</td>\n",
       "      <td>-0.048346</td>\n",
       "      <td>-0.062216</td>\n",
       "      <td>-0.057999</td>\n",
       "      <td>-0.054761</td>\n",
       "      <td>-0.088248</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.041168</td>\n",
       "      <td>-0.045422</td>\n",
       "      <td>-0.046141</td>\n",
       "      <td>-0.078694</td>\n",
       "      <td>-0.05516</td>\n",
       "      <td>-0.060439</td>\n",
       "      <td>-0.043013</td>\n",
       "      <td>-0.045611</td>\n",
       "      <td>-0.047175</td>\n",
       "      <td>-0.014289</td>\n",
       "      <td>-0.054151</td>\n",
       "      <td>-0.036347</td>\n",
       "      <td>-0.029533</td>\n",
       "      <td>-0.050234</td>\n",
       "      <td>-0.044481</td>\n",
       "      <td>0.298722</td>\n",
       "      <td>-0.387232</td>\n",
       "      <td>-0.034193</td>\n",
       "      <td>-0.142894</td>\n",
       "      <td>0.184399</td>\n",
       "      <td>-0.07117</td>\n",
       "      <td>0.077504</td>\n",
       "      <td>-0.032413</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>-0.560911</td>\n",
       "      <td>-0.506029</td>\n",
       "      <td>0.380593</td>\n",
       "      <td>-0.547637</td>\n",
       "      <td>-0.506005</td>\n",
       "      <td>-0.511042</td>\n",
       "      <td>-0.08243</td>\n",
       "      <td>-0.086243</td>\n",
       "      <td>-0.089706</td>\n",
       "      <td>-0.091688</td>\n",
       "      <td>-0.357827</td>\n",
       "      <td>-0.356561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.249562</td>\n",
       "      <td>-0.544587</td>\n",
       "      <td>-0.803152</td>\n",
       "      <td>-0.434818</td>\n",
       "      <td>-0.041814</td>\n",
       "      <td>-1.083156</td>\n",
       "      <td>-0.551276</td>\n",
       "      <td>-0.546267</td>\n",
       "      <td>-1.449451</td>\n",
       "      <td>-0.537535</td>\n",
       "      <td>-0.566493</td>\n",
       "      <td>-0.542801</td>\n",
       "      <td>-0.533175</td>\n",
       "      <td>-0.108377</td>\n",
       "      <td>-0.385432</td>\n",
       "      <td>0.385468</td>\n",
       "      <td>0.385747</td>\n",
       "      <td>-1.474449</td>\n",
       "      <td>-0.069307</td>\n",
       "      <td>-0.544537</td>\n",
       "      <td>-1.007672</td>\n",
       "      <td>-0.083475</td>\n",
       "      <td>0.911749</td>\n",
       "      <td>-0.004593</td>\n",
       "      <td>-0.894734</td>\n",
       "      <td>-0.413764</td>\n",
       "      <td>-0.083589</td>\n",
       "      <td>-1.227512</td>\n",
       "      <td>-0.193018</td>\n",
       "      <td>-1.019015</td>\n",
       "      <td>-0.526503</td>\n",
       "      <td>-0.527372</td>\n",
       "      <td>-0.553863</td>\n",
       "      <td>0.519333</td>\n",
       "      <td>-0.972753</td>\n",
       "      <td>-1.059143</td>\n",
       "      <td>-0.272797</td>\n",
       "      <td>-0.389465</td>\n",
       "      <td>-0.093859</td>\n",
       "      <td>-0.493680</td>\n",
       "      <td>-0.294501</td>\n",
       "      <td>-0.529056</td>\n",
       "      <td>-0.542678</td>\n",
       "      <td>-0.300054</td>\n",
       "      <td>-0.965816</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>-0.553826</td>\n",
       "      <td>-0.205104</td>\n",
       "      <td>-0.540532</td>\n",
       "      <td>-0.524318</td>\n",
       "      <td>-0.298381</td>\n",
       "      <td>-0.326247</td>\n",
       "      <td>-0.559101</td>\n",
       "      <td>-0.533809</td>\n",
       "      <td>-1.462481</td>\n",
       "      <td>-0.010886</td>\n",
       "      <td>-0.397750</td>\n",
       "      <td>-0.055439</td>\n",
       "      <td>-0.228292</td>\n",
       "      <td>0.340548</td>\n",
       "      <td>-0.531932</td>\n",
       "      <td>0.412278</td>\n",
       "      <td>-0.076617</td>\n",
       "      <td>9.154545</td>\n",
       "      <td>-0.154066</td>\n",
       "      <td>-0.234589</td>\n",
       "      <td>-0.501808</td>\n",
       "      <td>-0.031981</td>\n",
       "      <td>-0.346458</td>\n",
       "      <td>-0.985232</td>\n",
       "      <td>-0.569585</td>\n",
       "      <td>-0.526942</td>\n",
       "      <td>-1.149454</td>\n",
       "      <td>-0.535487</td>\n",
       "      <td>-0.522041</td>\n",
       "      <td>-0.553407</td>\n",
       "      <td>-0.540160</td>\n",
       "      <td>-0.996581</td>\n",
       "      <td>-0.352363</td>\n",
       "      <td>-0.066125</td>\n",
       "      <td>-0.065564</td>\n",
       "      <td>-0.422264</td>\n",
       "      <td>-1.452824</td>\n",
       "      <td>-1.019282</td>\n",
       "      <td>-0.162702</td>\n",
       "      <td>0.312541</td>\n",
       "      <td>-0.408597</td>\n",
       "      <td>-1.331973</td>\n",
       "      <td>-0.407192</td>\n",
       "      <td>0.390126</td>\n",
       "      <td>-0.542823</td>\n",
       "      <td>-0.090673</td>\n",
       "      <td>-0.558720</td>\n",
       "      <td>-0.376049</td>\n",
       "      <td>-0.531279</td>\n",
       "      <td>-0.560236</td>\n",
       "      <td>0.341725</td>\n",
       "      <td>-0.246551</td>\n",
       "      <td>-0.377186</td>\n",
       "      <td>-0.04969</td>\n",
       "      <td>-0.354550</td>\n",
       "      <td>0.256668</td>\n",
       "      <td>-0.22275</td>\n",
       "      <td>-0.535084</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>-0.528523</td>\n",
       "      <td>0.294440</td>\n",
       "      <td>-0.528749</td>\n",
       "      <td>-1.435363</td>\n",
       "      <td>-0.114522</td>\n",
       "      <td>-0.182099</td>\n",
       "      <td>-0.463749</td>\n",
       "      <td>-0.566417</td>\n",
       "      <td>-0.551901</td>\n",
       "      <td>0.418686</td>\n",
       "      <td>-0.116566</td>\n",
       "      <td>-1.002589</td>\n",
       "      <td>-0.556132</td>\n",
       "      <td>-0.130335</td>\n",
       "      <td>-0.922256</td>\n",
       "      <td>-0.527387</td>\n",
       "      <td>-0.964954</td>\n",
       "      <td>-0.390305</td>\n",
       "      <td>-0.532699</td>\n",
       "      <td>-1.722420</td>\n",
       "      <td>-0.957024</td>\n",
       "      <td>-1.465056</td>\n",
       "      <td>-0.05709</td>\n",
       "      <td>-0.528080</td>\n",
       "      <td>-0.553281</td>\n",
       "      <td>-0.556269</td>\n",
       "      <td>-0.494734</td>\n",
       "      <td>-0.183244</td>\n",
       "      <td>-0.411473</td>\n",
       "      <td>-0.356303</td>\n",
       "      <td>-1.117969</td>\n",
       "      <td>-0.550550</td>\n",
       "      <td>-1.730432</td>\n",
       "      <td>-1.461539</td>\n",
       "      <td>-0.083471</td>\n",
       "      <td>0.402837</td>\n",
       "      <td>-1.061595</td>\n",
       "      <td>-1.560152</td>\n",
       "      <td>-1.466143</td>\n",
       "      <td>-0.028718</td>\n",
       "      <td>-0.526444</td>\n",
       "      <td>-0.931627</td>\n",
       "      <td>-0.550072</td>\n",
       "      <td>-0.381317</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>-0.948280</td>\n",
       "      <td>-0.977981</td>\n",
       "      <td>-0.349760</td>\n",
       "      <td>-0.14449</td>\n",
       "      <td>-0.241668</td>\n",
       "      <td>-0.542326</td>\n",
       "      <td>-0.556514</td>\n",
       "      <td>-0.042189</td>\n",
       "      <td>-0.533263</td>\n",
       "      <td>-0.284724</td>\n",
       "      <td>-1.448103</td>\n",
       "      <td>-0.507690</td>\n",
       "      <td>-0.033802</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>1.72043</td>\n",
       "      <td>-0.438362</td>\n",
       "      <td>-0.893489</td>\n",
       "      <td>0.397178</td>\n",
       "      <td>-0.539156</td>\n",
       "      <td>1.283733</td>\n",
       "      <td>0.442796</td>\n",
       "      <td>-1.486336</td>\n",
       "      <td>-0.184631</td>\n",
       "      <td>-0.203484</td>\n",
       "      <td>-2.159828</td>\n",
       "      <td>0.540566</td>\n",
       "      <td>0.360192</td>\n",
       "      <td>-0.184209</td>\n",
       "      <td>-0.101669</td>\n",
       "      <td>-0.098434</td>\n",
       "      <td>-0.086169</td>\n",
       "      <td>-0.039137</td>\n",
       "      <td>-0.059583</td>\n",
       "      <td>-0.176940</td>\n",
       "      <td>-0.113225</td>\n",
       "      <td>-0.046189</td>\n",
       "      <td>-0.054075</td>\n",
       "      <td>-0.208426</td>\n",
       "      <td>-0.054926</td>\n",
       "      <td>-0.098328</td>\n",
       "      <td>-0.047102</td>\n",
       "      <td>-0.220792</td>\n",
       "      <td>-0.147581</td>\n",
       "      <td>0.526551</td>\n",
       "      <td>0.573227</td>\n",
       "      <td>1.452137</td>\n",
       "      <td>-0.576067</td>\n",
       "      <td>-0.309651</td>\n",
       "      <td>-0.155767</td>\n",
       "      <td>-0.099152</td>\n",
       "      <td>-0.193691</td>\n",
       "      <td>-0.326769</td>\n",
       "      <td>0.392144</td>\n",
       "      <td>0.648386</td>\n",
       "      <td>-0.133469</td>\n",
       "      <td>-0.08284</td>\n",
       "      <td>-0.127827</td>\n",
       "      <td>0.193920</td>\n",
       "      <td>-1.025429</td>\n",
       "      <td>-0.923236</td>\n",
       "      <td>-1.053204</td>\n",
       "      <td>-0.995398</td>\n",
       "      <td>0.034181</td>\n",
       "      <td>0.123804</td>\n",
       "      <td>0.034274</td>\n",
       "      <td>-0.321885</td>\n",
       "      <td>-0.30961</td>\n",
       "      <td>0.177113</td>\n",
       "      <td>0.108959</td>\n",
       "      <td>-0.049281</td>\n",
       "      <td>-0.074508</td>\n",
       "      <td>-0.061936</td>\n",
       "      <td>-0.329338</td>\n",
       "      <td>-0.289522</td>\n",
       "      <td>-0.043091</td>\n",
       "      <td>-0.050719</td>\n",
       "      <td>-0.049673</td>\n",
       "      <td>-0.083152</td>\n",
       "      <td>-0.090258</td>\n",
       "      <td>-0.055307</td>\n",
       "      <td>-0.079258</td>\n",
       "      <td>-0.067677</td>\n",
       "      <td>-0.072755</td>\n",
       "      <td>-0.288973</td>\n",
       "      <td>-0.187140</td>\n",
       "      <td>-0.045542</td>\n",
       "      <td>-0.053788</td>\n",
       "      <td>-0.052465</td>\n",
       "      <td>-0.058679</td>\n",
       "      <td>-0.085678</td>\n",
       "      <td>-0.075511</td>\n",
       "      <td>-0.031701</td>\n",
       "      <td>-0.239792</td>\n",
       "      <td>-0.232437</td>\n",
       "      <td>-0.055918</td>\n",
       "      <td>-0.12476</td>\n",
       "      <td>-0.121427</td>\n",
       "      <td>-0.083953</td>\n",
       "      <td>-0.082158</td>\n",
       "      <td>-0.312521</td>\n",
       "      <td>-0.303912</td>\n",
       "      <td>-0.118531</td>\n",
       "      <td>-0.146723</td>\n",
       "      <td>-0.150773</td>\n",
       "      <td>-0.308673</td>\n",
       "      <td>-0.300664</td>\n",
       "      <td>-0.300284</td>\n",
       "      <td>-0.292522</td>\n",
       "      <td>-0.115576</td>\n",
       "      <td>-0.118405</td>\n",
       "      <td>-0.030455</td>\n",
       "      <td>-0.035149</td>\n",
       "      <td>-0.03225</td>\n",
       "      <td>-0.053456</td>\n",
       "      <td>-0.097952</td>\n",
       "      <td>-0.10278</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.052381</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>-0.324797</td>\n",
       "      <td>-0.288607</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>-0.306484</td>\n",
       "      <td>-0.041292</td>\n",
       "      <td>-0.046295</td>\n",
       "      <td>-0.046597</td>\n",
       "      <td>-0.07271</td>\n",
       "      <td>-0.097544</td>\n",
       "      <td>-0.071066</td>\n",
       "      <td>-0.079106</td>\n",
       "      <td>-0.119359</td>\n",
       "      <td>-0.353630</td>\n",
       "      <td>-0.089382</td>\n",
       "      <td>-0.447665</td>\n",
       "      <td>-0.422654</td>\n",
       "      <td>-0.325115</td>\n",
       "      <td>-0.450097</td>\n",
       "      <td>-0.211605</td>\n",
       "      <td>-0.281908</td>\n",
       "      <td>-0.36208</td>\n",
       "      <td>-0.483298</td>\n",
       "      <td>-0.308233</td>\n",
       "      <td>-0.34294</td>\n",
       "      <td>-0.323017</td>\n",
       "      <td>-0.045791</td>\n",
       "      <td>-0.057194</td>\n",
       "      <td>-0.054842</td>\n",
       "      <td>-0.031881</td>\n",
       "      <td>-0.015007</td>\n",
       "      <td>-0.037858</td>\n",
       "      <td>-0.072124</td>\n",
       "      <td>-0.067005</td>\n",
       "      <td>-0.079805</td>\n",
       "      <td>-0.040947</td>\n",
       "      <td>-0.0494</td>\n",
       "      <td>-0.047343</td>\n",
       "      <td>-0.032528</td>\n",
       "      <td>-0.061764</td>\n",
       "      <td>-0.050674</td>\n",
       "      <td>-0.052212</td>\n",
       "      <td>-0.058176</td>\n",
       "      <td>-0.053373</td>\n",
       "      <td>-0.08205</td>\n",
       "      <td>-0.230531</td>\n",
       "      <td>-0.227590</td>\n",
       "      <td>-0.053747</td>\n",
       "      <td>-0.069811</td>\n",
       "      <td>-0.04128</td>\n",
       "      <td>-0.041151</td>\n",
       "      <td>-0.343569</td>\n",
       "      <td>-0.171602</td>\n",
       "      <td>-0.278643</td>\n",
       "      <td>-0.040645</td>\n",
       "      <td>-0.045145</td>\n",
       "      <td>-0.042053</td>\n",
       "      <td>-0.08919</td>\n",
       "      <td>-0.095307</td>\n",
       "      <td>-0.066844</td>\n",
       "      <td>-0.069129</td>\n",
       "      <td>-0.10873</td>\n",
       "      <td>-0.108326</td>\n",
       "      <td>-0.443577</td>\n",
       "      <td>-0.321263</td>\n",
       "      <td>-0.436050</td>\n",
       "      <td>-0.238435</td>\n",
       "      <td>-0.377649</td>\n",
       "      <td>-0.393050</td>\n",
       "      <td>-0.465556</td>\n",
       "      <td>-0.492519</td>\n",
       "      <td>-0.148389</td>\n",
       "      <td>-0.309876</td>\n",
       "      <td>-0.345461</td>\n",
       "      <td>-0.340874</td>\n",
       "      <td>-0.343962</td>\n",
       "      <td>-0.271606</td>\n",
       "      <td>-0.225907</td>\n",
       "      <td>-0.319623</td>\n",
       "      <td>-0.438433</td>\n",
       "      <td>-0.041485</td>\n",
       "      <td>-0.041062</td>\n",
       "      <td>-0.044216</td>\n",
       "      <td>-0.019603</td>\n",
       "      <td>-0.02641</td>\n",
       "      <td>-0.027637</td>\n",
       "      <td>-0.012979</td>\n",
       "      <td>-0.057632</td>\n",
       "      <td>-0.062164</td>\n",
       "      <td>-0.059283</td>\n",
       "      <td>-0.036909</td>\n",
       "      <td>-0.03958</td>\n",
       "      <td>-0.038675</td>\n",
       "      <td>-0.023196</td>\n",
       "      <td>-0.032106</td>\n",
       "      <td>-0.028872</td>\n",
       "      <td>-0.053422</td>\n",
       "      <td>-0.070625</td>\n",
       "      <td>-0.170618</td>\n",
       "      <td>-0.882906</td>\n",
       "      <td>-0.630863</td>\n",
       "      <td>-0.357205</td>\n",
       "      <td>-0.332543</td>\n",
       "      <td>-0.131711</td>\n",
       "      <td>-0.04042</td>\n",
       "      <td>-0.062849</td>\n",
       "      <td>-0.045744</td>\n",
       "      <td>-0.058539</td>\n",
       "      <td>-0.055212</td>\n",
       "      <td>-0.10044</td>\n",
       "      <td>-0.093916</td>\n",
       "      <td>-0.099373</td>\n",
       "      <td>-0.454447</td>\n",
       "      <td>-0.059471</td>\n",
       "      <td>-0.092981</td>\n",
       "      <td>-0.076203</td>\n",
       "      <td>-0.089662</td>\n",
       "      <td>-0.332187</td>\n",
       "      <td>-0.038594</td>\n",
       "      <td>-0.221127</td>\n",
       "      <td>-0.221827</td>\n",
       "      <td>-0.249078</td>\n",
       "      <td>-0.228881</td>\n",
       "      <td>-0.048346</td>\n",
       "      <td>-0.062216</td>\n",
       "      <td>-0.057999</td>\n",
       "      <td>-0.054761</td>\n",
       "      <td>-0.088248</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.041168</td>\n",
       "      <td>-0.045422</td>\n",
       "      <td>-0.046141</td>\n",
       "      <td>-0.078694</td>\n",
       "      <td>-0.05516</td>\n",
       "      <td>-0.060439</td>\n",
       "      <td>-0.043013</td>\n",
       "      <td>-0.045611</td>\n",
       "      <td>-0.047175</td>\n",
       "      <td>-0.014289</td>\n",
       "      <td>-0.054151</td>\n",
       "      <td>-0.036347</td>\n",
       "      <td>-0.029533</td>\n",
       "      <td>-0.050234</td>\n",
       "      <td>-0.044481</td>\n",
       "      <td>0.298722</td>\n",
       "      <td>-0.387232</td>\n",
       "      <td>-0.034193</td>\n",
       "      <td>-0.142894</td>\n",
       "      <td>0.184399</td>\n",
       "      <td>-0.07117</td>\n",
       "      <td>0.077504</td>\n",
       "      <td>-0.032413</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>-0.560911</td>\n",
       "      <td>-0.506029</td>\n",
       "      <td>0.380593</td>\n",
       "      <td>-0.547637</td>\n",
       "      <td>-0.506005</td>\n",
       "      <td>-0.511042</td>\n",
       "      <td>-0.08243</td>\n",
       "      <td>-0.086243</td>\n",
       "      <td>-0.089706</td>\n",
       "      <td>-0.091688</td>\n",
       "      <td>-0.357827</td>\n",
       "      <td>-0.356561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.249562</td>\n",
       "      <td>-0.544587</td>\n",
       "      <td>0.407824</td>\n",
       "      <td>-0.434818</td>\n",
       "      <td>-0.041814</td>\n",
       "      <td>-1.083156</td>\n",
       "      <td>-0.551276</td>\n",
       "      <td>-0.546267</td>\n",
       "      <td>0.643397</td>\n",
       "      <td>-0.537535</td>\n",
       "      <td>-0.566493</td>\n",
       "      <td>-0.542801</td>\n",
       "      <td>-0.533175</td>\n",
       "      <td>-0.108377</td>\n",
       "      <td>-0.385432</td>\n",
       "      <td>0.385468</td>\n",
       "      <td>0.385747</td>\n",
       "      <td>-1.474449</td>\n",
       "      <td>-0.069307</td>\n",
       "      <td>-0.544537</td>\n",
       "      <td>-1.007672</td>\n",
       "      <td>-0.083475</td>\n",
       "      <td>0.911749</td>\n",
       "      <td>-0.004593</td>\n",
       "      <td>-0.894734</td>\n",
       "      <td>-0.413764</td>\n",
       "      <td>-0.083589</td>\n",
       "      <td>0.837200</td>\n",
       "      <td>-0.193018</td>\n",
       "      <td>-1.019015</td>\n",
       "      <td>-0.526503</td>\n",
       "      <td>-0.527372</td>\n",
       "      <td>-0.553863</td>\n",
       "      <td>0.596366</td>\n",
       "      <td>-0.972753</td>\n",
       "      <td>-1.059143</td>\n",
       "      <td>-0.272797</td>\n",
       "      <td>-0.389465</td>\n",
       "      <td>-0.093859</td>\n",
       "      <td>-0.493680</td>\n",
       "      <td>-0.294501</td>\n",
       "      <td>-0.529056</td>\n",
       "      <td>-0.542678</td>\n",
       "      <td>-0.300054</td>\n",
       "      <td>-0.965816</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>-0.553826</td>\n",
       "      <td>-0.205104</td>\n",
       "      <td>-0.540532</td>\n",
       "      <td>-0.524318</td>\n",
       "      <td>-0.298381</td>\n",
       "      <td>-0.326247</td>\n",
       "      <td>-0.559101</td>\n",
       "      <td>-0.533809</td>\n",
       "      <td>-1.462481</td>\n",
       "      <td>-1.102171</td>\n",
       "      <td>1.616519</td>\n",
       "      <td>-0.055439</td>\n",
       "      <td>-0.228292</td>\n",
       "      <td>0.340548</td>\n",
       "      <td>-0.531932</td>\n",
       "      <td>0.412278</td>\n",
       "      <td>-0.076617</td>\n",
       "      <td>-0.029009</td>\n",
       "      <td>4.574395</td>\n",
       "      <td>3.893920</td>\n",
       "      <td>-0.501808</td>\n",
       "      <td>-0.031981</td>\n",
       "      <td>-0.346458</td>\n",
       "      <td>-0.985232</td>\n",
       "      <td>-0.569585</td>\n",
       "      <td>-0.526942</td>\n",
       "      <td>-1.149454</td>\n",
       "      <td>-0.535487</td>\n",
       "      <td>-0.522041</td>\n",
       "      <td>-0.553407</td>\n",
       "      <td>-0.540160</td>\n",
       "      <td>-0.996581</td>\n",
       "      <td>-0.352363</td>\n",
       "      <td>-0.066125</td>\n",
       "      <td>-0.065564</td>\n",
       "      <td>-0.422264</td>\n",
       "      <td>0.684057</td>\n",
       "      <td>-1.019282</td>\n",
       "      <td>-0.162702</td>\n",
       "      <td>0.312541</td>\n",
       "      <td>-0.408597</td>\n",
       "      <td>0.806283</td>\n",
       "      <td>-0.407192</td>\n",
       "      <td>0.390126</td>\n",
       "      <td>-0.542823</td>\n",
       "      <td>-0.090673</td>\n",
       "      <td>-0.558720</td>\n",
       "      <td>-0.376049</td>\n",
       "      <td>-0.531279</td>\n",
       "      <td>-0.560236</td>\n",
       "      <td>0.341725</td>\n",
       "      <td>-0.246551</td>\n",
       "      <td>-0.377186</td>\n",
       "      <td>-0.04969</td>\n",
       "      <td>-0.354550</td>\n",
       "      <td>0.256668</td>\n",
       "      <td>-0.22275</td>\n",
       "      <td>-0.535084</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>-0.528523</td>\n",
       "      <td>0.294440</td>\n",
       "      <td>-0.528749</td>\n",
       "      <td>-1.435363</td>\n",
       "      <td>-0.114522</td>\n",
       "      <td>-0.182099</td>\n",
       "      <td>-0.463749</td>\n",
       "      <td>-0.566417</td>\n",
       "      <td>-0.551901</td>\n",
       "      <td>0.418686</td>\n",
       "      <td>-0.116566</td>\n",
       "      <td>-1.002589</td>\n",
       "      <td>-0.556132</td>\n",
       "      <td>-0.130335</td>\n",
       "      <td>-0.922256</td>\n",
       "      <td>-0.527387</td>\n",
       "      <td>-0.964954</td>\n",
       "      <td>-0.390305</td>\n",
       "      <td>-0.532699</td>\n",
       "      <td>0.079730</td>\n",
       "      <td>-0.957024</td>\n",
       "      <td>0.686806</td>\n",
       "      <td>-0.05709</td>\n",
       "      <td>-0.528080</td>\n",
       "      <td>-0.553281</td>\n",
       "      <td>-0.556269</td>\n",
       "      <td>-0.494734</td>\n",
       "      <td>-0.183244</td>\n",
       "      <td>-0.411473</td>\n",
       "      <td>0.874067</td>\n",
       "      <td>-1.117969</td>\n",
       "      <td>-0.550550</td>\n",
       "      <td>0.080027</td>\n",
       "      <td>0.646860</td>\n",
       "      <td>-0.083471</td>\n",
       "      <td>0.402837</td>\n",
       "      <td>-1.061595</td>\n",
       "      <td>-1.560152</td>\n",
       "      <td>0.704683</td>\n",
       "      <td>-0.028718</td>\n",
       "      <td>-0.526444</td>\n",
       "      <td>-0.348024</td>\n",
       "      <td>-0.550072</td>\n",
       "      <td>-0.381317</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>-0.948280</td>\n",
       "      <td>-0.977981</td>\n",
       "      <td>-0.349760</td>\n",
       "      <td>-0.14449</td>\n",
       "      <td>-0.241668</td>\n",
       "      <td>-0.542326</td>\n",
       "      <td>-0.556514</td>\n",
       "      <td>-0.042189</td>\n",
       "      <td>-0.533263</td>\n",
       "      <td>3.297984</td>\n",
       "      <td>0.703487</td>\n",
       "      <td>-0.507690</td>\n",
       "      <td>-0.033802</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>-0.58175</td>\n",
       "      <td>-0.438362</td>\n",
       "      <td>0.816915</td>\n",
       "      <td>0.397178</td>\n",
       "      <td>-0.539156</td>\n",
       "      <td>-0.641418</td>\n",
       "      <td>-0.074871</td>\n",
       "      <td>0.790786</td>\n",
       "      <td>-0.362854</td>\n",
       "      <td>-0.203484</td>\n",
       "      <td>0.633778</td>\n",
       "      <td>1.377591</td>\n",
       "      <td>0.360192</td>\n",
       "      <td>-0.175985</td>\n",
       "      <td>-0.101669</td>\n",
       "      <td>-0.098434</td>\n",
       "      <td>-0.092693</td>\n",
       "      <td>-0.039137</td>\n",
       "      <td>-0.059583</td>\n",
       "      <td>-0.215803</td>\n",
       "      <td>-0.127313</td>\n",
       "      <td>-0.046189</td>\n",
       "      <td>-0.054075</td>\n",
       "      <td>-0.208426</td>\n",
       "      <td>-0.054926</td>\n",
       "      <td>-0.098328</td>\n",
       "      <td>-0.047102</td>\n",
       "      <td>-0.236331</td>\n",
       "      <td>-0.147581</td>\n",
       "      <td>-0.597478</td>\n",
       "      <td>-0.578065</td>\n",
       "      <td>-0.323817</td>\n",
       "      <td>-0.576067</td>\n",
       "      <td>-0.309651</td>\n",
       "      <td>-0.155767</td>\n",
       "      <td>-0.099152</td>\n",
       "      <td>-0.193691</td>\n",
       "      <td>-0.326769</td>\n",
       "      <td>-0.616023</td>\n",
       "      <td>-0.503169</td>\n",
       "      <td>-0.133469</td>\n",
       "      <td>-0.08284</td>\n",
       "      <td>-0.127827</td>\n",
       "      <td>-0.710153</td>\n",
       "      <td>-1.025429</td>\n",
       "      <td>-0.923236</td>\n",
       "      <td>-1.053204</td>\n",
       "      <td>-0.995398</td>\n",
       "      <td>0.034181</td>\n",
       "      <td>0.123804</td>\n",
       "      <td>0.034274</td>\n",
       "      <td>-0.321885</td>\n",
       "      <td>-0.30961</td>\n",
       "      <td>0.177113</td>\n",
       "      <td>0.108959</td>\n",
       "      <td>-0.001529</td>\n",
       "      <td>-0.049607</td>\n",
       "      <td>-0.025731</td>\n",
       "      <td>0.039914</td>\n",
       "      <td>0.772454</td>\n",
       "      <td>-0.043091</td>\n",
       "      <td>-0.050719</td>\n",
       "      <td>-0.049673</td>\n",
       "      <td>-0.083152</td>\n",
       "      <td>-0.090258</td>\n",
       "      <td>-0.005284</td>\n",
       "      <td>-0.051605</td>\n",
       "      <td>-0.028719</td>\n",
       "      <td>0.892797</td>\n",
       "      <td>0.078233</td>\n",
       "      <td>0.515279</td>\n",
       "      <td>-0.045542</td>\n",
       "      <td>-0.053788</td>\n",
       "      <td>-0.052465</td>\n",
       "      <td>-0.058679</td>\n",
       "      <td>-0.085678</td>\n",
       "      <td>-0.075511</td>\n",
       "      <td>-0.031701</td>\n",
       "      <td>-0.239792</td>\n",
       "      <td>-0.232437</td>\n",
       "      <td>-0.055918</td>\n",
       "      <td>-0.12476</td>\n",
       "      <td>-0.121427</td>\n",
       "      <td>-0.083953</td>\n",
       "      <td>-0.082158</td>\n",
       "      <td>-0.312521</td>\n",
       "      <td>-0.303912</td>\n",
       "      <td>-0.118531</td>\n",
       "      <td>-0.146723</td>\n",
       "      <td>-0.150773</td>\n",
       "      <td>-0.308673</td>\n",
       "      <td>-0.300664</td>\n",
       "      <td>-0.300284</td>\n",
       "      <td>-0.292522</td>\n",
       "      <td>-0.115576</td>\n",
       "      <td>-0.118405</td>\n",
       "      <td>-0.030455</td>\n",
       "      <td>-0.035149</td>\n",
       "      <td>-0.03225</td>\n",
       "      <td>-0.053456</td>\n",
       "      <td>-0.097952</td>\n",
       "      <td>-0.10278</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.052381</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>-0.324797</td>\n",
       "      <td>-0.288607</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>-0.306484</td>\n",
       "      <td>-0.041292</td>\n",
       "      <td>-0.046295</td>\n",
       "      <td>-0.046597</td>\n",
       "      <td>-0.07271</td>\n",
       "      <td>-0.097544</td>\n",
       "      <td>-0.071066</td>\n",
       "      <td>-0.079106</td>\n",
       "      <td>-0.119359</td>\n",
       "      <td>-0.353630</td>\n",
       "      <td>-0.089382</td>\n",
       "      <td>-0.447665</td>\n",
       "      <td>-0.422654</td>\n",
       "      <td>-0.325115</td>\n",
       "      <td>-0.450097</td>\n",
       "      <td>-0.211605</td>\n",
       "      <td>-0.281908</td>\n",
       "      <td>-0.36208</td>\n",
       "      <td>-0.483298</td>\n",
       "      <td>-0.308233</td>\n",
       "      <td>-0.34294</td>\n",
       "      <td>-0.323017</td>\n",
       "      <td>-0.045791</td>\n",
       "      <td>-0.057194</td>\n",
       "      <td>-0.054842</td>\n",
       "      <td>-0.031881</td>\n",
       "      <td>-0.015007</td>\n",
       "      <td>-0.037858</td>\n",
       "      <td>-0.072124</td>\n",
       "      <td>-0.067005</td>\n",
       "      <td>-0.079805</td>\n",
       "      <td>-0.040947</td>\n",
       "      <td>-0.0494</td>\n",
       "      <td>-0.047343</td>\n",
       "      <td>-0.032528</td>\n",
       "      <td>-0.061764</td>\n",
       "      <td>-0.050674</td>\n",
       "      <td>-0.052212</td>\n",
       "      <td>-0.058176</td>\n",
       "      <td>-0.053373</td>\n",
       "      <td>-0.08205</td>\n",
       "      <td>-0.230531</td>\n",
       "      <td>-0.227590</td>\n",
       "      <td>-0.053747</td>\n",
       "      <td>-0.069811</td>\n",
       "      <td>-0.04128</td>\n",
       "      <td>-0.041151</td>\n",
       "      <td>-0.343569</td>\n",
       "      <td>-0.171602</td>\n",
       "      <td>-0.278643</td>\n",
       "      <td>-0.040645</td>\n",
       "      <td>-0.045145</td>\n",
       "      <td>-0.042053</td>\n",
       "      <td>-0.08919</td>\n",
       "      <td>-0.095307</td>\n",
       "      <td>-0.066844</td>\n",
       "      <td>-0.069129</td>\n",
       "      <td>-0.10873</td>\n",
       "      <td>-0.108326</td>\n",
       "      <td>-0.443577</td>\n",
       "      <td>-0.321263</td>\n",
       "      <td>-0.436050</td>\n",
       "      <td>-0.238435</td>\n",
       "      <td>-0.377649</td>\n",
       "      <td>-0.393050</td>\n",
       "      <td>-0.465556</td>\n",
       "      <td>-0.492519</td>\n",
       "      <td>-0.148389</td>\n",
       "      <td>-0.309876</td>\n",
       "      <td>-0.345461</td>\n",
       "      <td>-0.340874</td>\n",
       "      <td>-0.343962</td>\n",
       "      <td>-0.271606</td>\n",
       "      <td>-0.225907</td>\n",
       "      <td>-0.319623</td>\n",
       "      <td>-0.438433</td>\n",
       "      <td>-0.041485</td>\n",
       "      <td>-0.041062</td>\n",
       "      <td>-0.044216</td>\n",
       "      <td>-0.019603</td>\n",
       "      <td>-0.02641</td>\n",
       "      <td>-0.027637</td>\n",
       "      <td>-0.012979</td>\n",
       "      <td>-0.057632</td>\n",
       "      <td>-0.062164</td>\n",
       "      <td>-0.059283</td>\n",
       "      <td>-0.036909</td>\n",
       "      <td>-0.03958</td>\n",
       "      <td>-0.038675</td>\n",
       "      <td>-0.023196</td>\n",
       "      <td>-0.032106</td>\n",
       "      <td>-0.028872</td>\n",
       "      <td>-0.005653</td>\n",
       "      <td>-0.034642</td>\n",
       "      <td>1.777032</td>\n",
       "      <td>1.282739</td>\n",
       "      <td>0.645058</td>\n",
       "      <td>-0.050212</td>\n",
       "      <td>0.596434</td>\n",
       "      <td>-0.131711</td>\n",
       "      <td>-0.04042</td>\n",
       "      <td>-0.062849</td>\n",
       "      <td>-0.045744</td>\n",
       "      <td>-0.058539</td>\n",
       "      <td>-0.055212</td>\n",
       "      <td>-0.10044</td>\n",
       "      <td>-0.093916</td>\n",
       "      <td>-0.099373</td>\n",
       "      <td>-0.454447</td>\n",
       "      <td>-0.009479</td>\n",
       "      <td>-0.066355</td>\n",
       "      <td>-0.037404</td>\n",
       "      <td>0.860296</td>\n",
       "      <td>-0.003077</td>\n",
       "      <td>1.011770</td>\n",
       "      <td>0.437845</td>\n",
       "      <td>0.994093</td>\n",
       "      <td>0.427420</td>\n",
       "      <td>0.772821</td>\n",
       "      <td>-0.048346</td>\n",
       "      <td>-0.062216</td>\n",
       "      <td>-0.057999</td>\n",
       "      <td>-0.054761</td>\n",
       "      <td>-0.088248</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.041168</td>\n",
       "      <td>-0.045422</td>\n",
       "      <td>-0.046141</td>\n",
       "      <td>-0.078694</td>\n",
       "      <td>-0.05516</td>\n",
       "      <td>-0.060439</td>\n",
       "      <td>-0.043013</td>\n",
       "      <td>-0.045611</td>\n",
       "      <td>-0.047175</td>\n",
       "      <td>-0.014289</td>\n",
       "      <td>-0.054151</td>\n",
       "      <td>-0.036347</td>\n",
       "      <td>-0.029533</td>\n",
       "      <td>-0.050234</td>\n",
       "      <td>-0.044481</td>\n",
       "      <td>0.298722</td>\n",
       "      <td>-0.387232</td>\n",
       "      <td>-0.034193</td>\n",
       "      <td>-0.142894</td>\n",
       "      <td>0.184399</td>\n",
       "      <td>-0.07117</td>\n",
       "      <td>0.077504</td>\n",
       "      <td>-0.032413</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>-0.560911</td>\n",
       "      <td>-0.506029</td>\n",
       "      <td>0.380593</td>\n",
       "      <td>-0.547637</td>\n",
       "      <td>-0.506005</td>\n",
       "      <td>-0.511042</td>\n",
       "      <td>-0.08243</td>\n",
       "      <td>-0.086243</td>\n",
       "      <td>-0.089706</td>\n",
       "      <td>-0.091688</td>\n",
       "      <td>-0.357827</td>\n",
       "      <td>-0.356561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        V35       V31        M4  R_emaildomain      V122       V75       V84  \\\n",
       "0  0.249562  0.985555 -0.803152       0.118149 -0.041814  0.992088  0.893506   \n",
       "1 -1.209963 -0.544587  0.407824      -0.434818 -0.041814 -1.083156 -0.551276   \n",
       "2 -1.209963 -0.544587 -0.803152      -0.434818 -0.041814 -1.083156 -0.551276   \n",
       "3  0.249562 -0.544587 -0.803152      -0.434818 -0.041814 -1.083156 -0.551276   \n",
       "4  0.249562 -0.544587  0.407824      -0.434818 -0.041814 -1.083156 -0.551276   \n",
       "\n",
       "      id_38       V69       V57       V93       V63      V240      V297  \\\n",
       "0  1.247671  0.894435  1.232184  0.890458  1.245603  1.872586 -0.108377   \n",
       "1 -0.546267  0.643397 -0.537535 -0.566493 -0.542801 -0.533175 -0.108377   \n",
       "2 -0.546267 -1.449451 -0.537535 -0.566493 -0.542801 -0.533175 -0.108377   \n",
       "3 -0.546267 -1.449451 -0.537535 -0.566493 -0.542801 -0.533175 -0.108377   \n",
       "4 -0.546267  0.643397 -0.537535 -0.566493 -0.542801 -0.533175 -0.108377   \n",
       "\n",
       "        V65       V50       V42       V83      V112       V32        V3  \\\n",
       "0  2.571279  0.385468  0.385747  1.208605 -0.069307  0.985460  1.007737   \n",
       "1 -0.385432 -0.663889 -0.634533 -0.136447 -0.069307 -0.544537 -1.007672   \n",
       "2 -0.385432 -0.663889 -0.634533 -0.136447 -0.069307 -0.544537  1.007737   \n",
       "3 -0.385432  0.385468  0.385747 -1.474449 -0.069307 -0.544537 -1.007672   \n",
       "4 -0.385432  0.385468  0.385747 -1.474449 -0.069307 -0.544537 -1.007672   \n",
       "\n",
       "      id_24       V41      V305        V4       V25      V110        M7  \\\n",
       "0 -0.083475  0.911749 -0.004593  1.032669  2.302824 -0.083589  0.837200   \n",
       "1 -0.083475 -0.339302 -0.004593 -0.990970 -0.413764 -0.083589 -1.227512   \n",
       "2 -0.083475 -0.339302 -0.004593  1.032669 -0.413764 -0.083589  0.837200   \n",
       "3 -0.083475  0.911749 -0.004593 -0.894734 -0.413764 -0.083589 -1.227512   \n",
       "4 -0.083475  0.911749 -0.004593 -0.894734 -0.413764 -0.083589  0.837200   \n",
       "\n",
       "       V301        M2      V197       V18      V304        M5       V53  \\\n",
       "0 -0.193018  1.036899  1.273024  0.998680  1.686335  0.519333  1.404020   \n",
       "1 -0.193018 -1.019015 -0.526503 -0.527372 -0.553863  0.596366 -0.972753   \n",
       "2 -0.193018  1.036899 -0.526503 -0.527372 -0.553863  0.519333 -0.972753   \n",
       "3 -0.193018 -1.019015 -0.526503 -0.527372 -0.553863  0.519333 -0.972753   \n",
       "4 -0.193018 -1.019015 -0.526503 -0.527372 -0.553863  0.596366 -0.972753   \n",
       "\n",
       "        V76     id_18      V325     id_27     id_16     id_34      V175  \\\n",
       "0  0.958821 -0.272797  2.335583 -0.093859  2.514579  0.952800  1.702710   \n",
       "1 -1.059143 -0.272797 -0.389465 -0.093859 -0.493680 -0.294501 -0.529056   \n",
       "2 -1.059143 -0.272797 -0.389465 -0.093859 -0.493680 -0.294501 -0.529056   \n",
       "3 -1.059143 -0.272797 -0.389465 -0.093859 -0.493680 -0.294501 -0.529056   \n",
       "4 -1.059143 -0.272797 -0.389465 -0.093859 -0.493680 -0.294501 -0.529056   \n",
       "\n",
       "        V64      V141        V8       V15      V173     id_32       V79  \\\n",
       "0  1.241917  1.536652  1.047713  0.994488  1.817448 -0.219531  0.898955   \n",
       "1 -0.542678 -0.300054 -0.965816 -0.515288 -0.553826 -0.205104 -0.540532   \n",
       "2 -0.542678 -0.300054  1.047713 -0.515288 -0.553826 -0.205104 -0.540532   \n",
       "3 -0.542678 -0.300054 -0.965816 -0.515288 -0.553826 -0.205104 -0.540532   \n",
       "4 -0.542678 -0.300054 -0.965816 -0.515288 -0.553826 -0.205104 -0.540532   \n",
       "\n",
       "       V194      V142  DeviceInfo       V94      V250       V19        M3  \\\n",
       "0  1.279735  1.521277   -1.730724  0.880040  1.467761  1.789589  1.024527   \n",
       "1 -0.524318 -0.298381   -0.326247 -0.559101 -0.533809 -0.039890 -1.102171   \n",
       "2 -0.524318 -0.298381   -0.326247 -0.559101 -0.533809 -0.039890  1.024527   \n",
       "3 -0.524318 -0.298381   -0.326247 -0.559101 -0.533809 -1.462481 -0.010886   \n",
       "4 -0.524318 -0.298381   -0.326247 -0.559101 -0.533809 -1.462481 -1.102171   \n",
       "\n",
       "       V288      V113      V328       V48     id_15       V51      V153  \\\n",
       "0 -0.397750 -0.055439  1.274964  0.340548  2.300246  0.412278  0.496301   \n",
       "1 -0.397750 -0.055439 -0.228292  0.748619 -0.531932 -0.656132 -0.076617   \n",
       "2 -0.397750 -0.055439 -0.228292 -1.660800 -0.531932 -0.656132 -0.076617   \n",
       "3 -0.397750 -0.055439 -0.228292  0.340548 -0.531932  0.412278 -0.076617   \n",
       "4  1.616519 -0.055439 -0.228292  0.340548 -0.531932  0.412278 -0.076617   \n",
       "\n",
       "      card4      V286       V98     id_35      V119       V27        V9  \\\n",
       "0 -1.478242 -0.154066 -0.234589  0.770854 -0.031981  2.414832  1.020952   \n",
       "1 -0.169905 -0.154066 -0.234589 -0.501808 -0.031981 -0.346458 -0.985232   \n",
       "2 -0.029009 -0.154066 -0.234589 -0.501808 -0.031981 -0.346458  1.020952   \n",
       "3  9.154545 -0.154066 -0.234589 -0.501808 -0.031981 -0.346458 -0.985232   \n",
       "4 -0.029009  4.574395  3.893920 -0.501808 -0.031981 -0.346458 -0.985232   \n",
       "\n",
       "        V92      V251       V61     id_28      V195     id_36       V34  \\\n",
       "0  0.885887  1.414944  1.815534  2.262642  1.249385  1.834438  0.973051   \n",
       "1 -0.569585 -0.526942 -0.174917 -0.535487 -0.522041 -0.553407 -0.540160   \n",
       "2 -0.569585 -0.526942 -0.174917 -0.535487 -0.522041 -0.553407 -0.540160   \n",
       "3 -0.569585 -0.526942 -1.149454 -0.535487 -0.522041 -0.553407 -0.540160   \n",
       "4 -0.569585 -0.526942 -1.149454 -0.535487 -0.522041 -0.553407 -0.540160   \n",
       "\n",
       "         V7       V23      V108      V121       V88       V29       V12  \\\n",
       "0  1.036516  1.445070 -0.066125 -0.065564  2.369663  0.738068  1.126510   \n",
       "1 -0.996581 -0.352363 -0.066125 -0.065564 -0.422264  0.684057 -1.019282   \n",
       "2  1.036516 -0.352363 -0.066125 -0.065564 -0.422264 -1.452824 -1.019282   \n",
       "3 -0.996581 -0.352363 -0.066125 -0.065564 -0.422264 -1.452824 -1.019282   \n",
       "4 -0.996581 -0.352363 -0.066125 -0.065564 -0.422264  0.684057 -1.019282   \n",
       "\n",
       "       V115       V47       V26        M9       V66       V43       V59  \\\n",
       "0 -0.162702  0.312541  2.126737  0.806283  1.966465  0.390126  1.241881   \n",
       "1 -0.162702 -0.327293 -0.408597 -1.331973 -0.407192 -0.633584 -0.542823   \n",
       "2 -0.162702 -0.327293 -0.408597  0.806283 -0.407192 -0.633584 -0.542823   \n",
       "3 -0.162702  0.312541 -0.408597 -1.331973 -0.407192  0.390126 -0.542823   \n",
       "4 -0.162702  0.312541 -0.408597  0.806283 -0.407192  0.390126 -0.542823   \n",
       "\n",
       "       V114     id_37       V89      V223       V74       V49  P_emaildomain  \\\n",
       "0 -0.090673  1.872156  2.178445  1.856694  1.198272  0.341725      -0.752456   \n",
       "1 -0.090673 -0.558720 -0.376049 -0.531279 -0.560236  0.744573       0.706391   \n",
       "2 -0.090673 -0.558720 -0.376049 -0.531279 -0.560236 -1.685703      -0.032092   \n",
       "3 -0.090673 -0.558720 -0.376049 -0.531279 -0.560236  0.341725      -0.246551   \n",
       "4 -0.090673 -0.558720 -0.376049 -0.531279 -0.560236  0.341725      -0.246551   \n",
       "\n",
       "        V68     V111     id_04       V36     V124       V58      V107  \\\n",
       "0  2.534823 -0.04969  2.779126  0.256668 -0.22275  1.236209 -0.003584   \n",
       "1 -0.377186 -0.04969 -0.354550 -1.188271 -0.22275 -0.535084 -0.003584   \n",
       "2 -0.377186 -0.04969 -0.354550 -1.188271 -0.22275 -0.535084 -0.003584   \n",
       "3 -0.377186 -0.04969 -0.354550  0.256668 -0.22275 -0.535084 -0.003584   \n",
       "4 -0.377186 -0.04969 -0.354550  0.256668 -0.22275 -0.535084 -0.003584   \n",
       "\n",
       "        V33       V46       V21       V82      V109      V125     id_31  \\\n",
       "0  0.981250  0.294440  0.995269  1.337633 -0.114522 -0.182099 -0.618445   \n",
       "1 -0.528523 -0.272727 -0.528749 -0.100484 -0.114522 -0.182099 -0.463749   \n",
       "2 -0.528523 -0.272727 -0.528749 -0.100484 -0.114522 -0.182099 -0.463749   \n",
       "3 -0.528523  0.294440 -0.528749 -1.435363 -0.114522 -0.182099 -0.463749   \n",
       "4 -0.528523  0.294440 -0.528749 -1.435363 -0.114522 -0.182099 -0.463749   \n",
       "\n",
       "      id_12       V73       V52      V116       V13      V302      V104  \\\n",
       "0  1.832608  1.209208  0.418686 -0.116566  1.080244  1.731517 -0.130335   \n",
       "1 -0.566417 -0.551901 -0.660177 -0.116566 -1.002589 -0.556132 -0.130335   \n",
       "2 -0.566417 -0.551901 -0.660177 -0.116566 -1.002589 -0.556132 -0.130335   \n",
       "3 -0.566417 -0.551901  0.418686 -0.116566 -1.002589 -0.556132 -0.130335   \n",
       "4 -0.566417 -0.551901  0.418686 -0.116566 -1.002589 -0.556132 -0.130335   \n",
       "\n",
       "         M1       V17        V6       V24     id_29       V10       V54  \\\n",
       "0  1.084328  0.998054  1.048459  1.485220  2.293979  0.803947  1.342816   \n",
       "1 -0.922256 -0.527387 -0.964954 -0.390305 -0.532699  0.079730 -0.957024   \n",
       "2  1.084328 -0.527387  1.048459 -0.390305 -0.532699  0.803947 -0.957024   \n",
       "3 -0.922256 -0.527387 -0.964954 -0.390305 -0.532699 -1.722420 -0.957024   \n",
       "4 -0.922256 -0.527387 -0.964954 -0.390305 -0.532699  0.079730 -0.957024   \n",
       "\n",
       "        V30     V154       V22       V72       V71      V247      V300  \\\n",
       "0  0.739264  0.29589  0.995308  1.241366  1.237255  1.636341 -0.183244   \n",
       "1  0.686806 -0.05709 -0.528080 -0.553281 -0.556269 -0.494734 -0.183244   \n",
       "2 -1.465056 -0.05709 -0.528080 -0.553281 -0.556269 -0.494734 -0.183244   \n",
       "3 -1.465056 -0.05709 -0.528080 -0.553281 -0.556269 -0.494734 -0.183244   \n",
       "4  0.686806 -0.05709 -0.528080 -0.553281 -0.556269 -0.494734 -0.183244   \n",
       "\n",
       "        V67      V289       V62       V85       V11       V70     id_30  \\\n",
       "0  1.725030 -0.356303  1.662194  0.894948  0.804832  0.892424 -0.191768   \n",
       "1 -0.411473 -0.356303 -0.231481 -0.550550  0.080027  0.646860 -0.083471   \n",
       "2 -0.411473 -0.356303 -0.231481 -0.550550  0.804832 -1.461539 -0.083471   \n",
       "3 -0.411473 -0.356303 -1.117969 -0.550550 -1.730432 -1.461539 -0.083471   \n",
       "4 -0.411473  0.874067 -1.117969 -0.550550  0.080027  0.646860 -0.083471   \n",
       "\n",
       "        V40        V5       V20       V91      V117  ProductCD        M6  \\\n",
       "0  0.402837  1.011969  1.667083  0.674694 -0.028718   0.514525  1.526335   \n",
       "1 -0.632061 -0.973044 -0.045786  0.704683 -0.028718  -0.526444 -0.348024   \n",
       "2 -0.632061  1.011969 -0.045786 -1.466143 -0.028718  -0.526444 -0.931627   \n",
       "3  0.402837 -1.061595 -1.560152 -1.466143 -0.028718  -0.526444 -0.931627   \n",
       "4  0.402837 -1.061595 -1.560152  0.704683 -0.028718  -0.526444 -0.348024   \n",
       "\n",
       "   DeviceType       V14       V16        V1        V2       V28     V123  \\\n",
       "0    1.432970  2.591129  0.994217  1.054511  1.042615  2.432304 -0.14449   \n",
       "1   -0.550072 -0.381317 -0.515288 -0.948280 -0.977981 -0.349760 -0.14449   \n",
       "2   -0.550072 -0.381317 -0.515288  1.054511  1.042615 -0.349760 -0.14449   \n",
       "3   -0.550072 -0.381317 -0.515288 -0.948280 -0.977981 -0.349760 -0.14449   \n",
       "4   -0.550072 -0.381317 -0.515288 -0.948280 -0.977981 -0.349760 -0.14449   \n",
       "\n",
       "       V327       V60      V174      V118      V241      V284       V90  \\\n",
       "0  1.503569  1.239407  1.742640 -0.042189  1.873777 -0.284724  0.675531   \n",
       "1 -0.241668 -0.542326 -0.556514 -0.042189 -0.533263 -0.284724  0.703487   \n",
       "2 -0.241668 -0.542326 -0.556514 -0.042189 -0.533263 -0.284724 -1.448103   \n",
       "3 -0.241668 -0.542326 -0.556514 -0.042189 -0.533263 -0.284724 -1.448103   \n",
       "4 -0.241668 -0.542326 -0.556514 -0.042189 -0.533263  3.297984  0.703487   \n",
       "\n",
       "       V260      V120     id_23    card6       V55        M8       V39  \\\n",
       "0  1.652838 -0.033802 -0.089246  1.72043  1.822244  0.816915  0.397178   \n",
       "1 -0.507690 -0.033802 -0.089246 -0.58175 -0.438362 -0.893489 -0.633937   \n",
       "2 -0.507690 -0.033802 -0.089246  1.72043 -0.438362  0.816915 -0.633937   \n",
       "3 -0.507690 -0.033802 -0.089246  1.72043 -0.438362 -0.893489  0.397178   \n",
       "4 -0.507690 -0.033802 -0.089246 -0.58175 -0.438362  0.816915  0.397178   \n",
       "\n",
       "       V184  TransactionDT  TransactionAmt     card1     card2     card3  \\\n",
       "0  1.574612      -1.378728       -0.145302 -0.759998  0.257853 -0.203484   \n",
       "1 -0.539156      -0.079104       -0.435353 -0.408558 -0.074010 -0.203484   \n",
       "2 -0.539156      -1.148460       -0.112365  0.364489 -1.512083 -0.203484   \n",
       "3 -0.539156       1.283733        0.442796 -1.486336 -0.184631 -0.203484   \n",
       "4 -0.539156      -0.641418       -0.074871  0.790786 -0.362854 -0.203484   \n",
       "\n",
       "      card5     addr1     addr2     dist1     dist2        C1        C2  \\\n",
       "0 -1.078432  0.042876  0.360192 -0.196545 -0.094803 -0.098434 -0.092693   \n",
       "1  0.588719 -0.869556  0.360192 -0.180097 -0.101669 -0.098434 -0.092693   \n",
       "2  0.633778 -0.507599  0.360192 -0.196545 -0.101669 -0.098434 -0.092693   \n",
       "3 -2.159828  0.540566  0.360192 -0.184209 -0.101669 -0.098434 -0.086169   \n",
       "4  0.633778  1.377591  0.360192 -0.175985 -0.101669 -0.098434 -0.092693   \n",
       "\n",
       "         C3        C4        C5        C6        C7        C8        C9  \\\n",
       "0 -0.039137 -0.030306 -0.215803 -0.113225 -0.046189 -0.032914 -0.268532   \n",
       "1 -0.039137 -0.059583 -0.215803 -0.113225 -0.046189 -0.054075 -0.208426   \n",
       "2 -0.039137 -0.059583 -0.176940 -0.113225 -0.046189 -0.054075 -0.208426   \n",
       "3 -0.039137 -0.059583 -0.176940 -0.113225 -0.046189 -0.054075 -0.208426   \n",
       "4 -0.039137 -0.059583 -0.215803 -0.127313 -0.046189 -0.054075 -0.208426   \n",
       "\n",
       "        C10       C11       C12       C13       C14        D1        D2  \\\n",
       "0 -0.033820 -0.098328 -0.047102 -0.236331 -0.147581  3.269944  3.383160   \n",
       "1 -0.054926 -0.098328 -0.047102 -0.251869 -0.167893 -0.597478 -0.578065   \n",
       "2 -0.054926 -0.098328 -0.047102 -0.135330 -0.147581  2.584096  2.680676   \n",
       "3 -0.054926 -0.098328 -0.047102 -0.220792 -0.147581  0.526551  0.573227   \n",
       "4 -0.054926 -0.098328 -0.047102 -0.236331 -0.147581 -0.597478 -0.578065   \n",
       "\n",
       "         D3        D4        D5        D6        D7        D8        D9  \\\n",
       "0 -0.323817 -0.576067 -0.309651 -0.155767 -0.099152  6.159508  2.726051   \n",
       "1 -0.323817 -0.576067 -0.309651 -0.155767 -0.099152 -0.193691 -0.326769   \n",
       "2  0.047895  2.320242 -0.032151 -0.155767 -0.099152 -0.193691 -0.326769   \n",
       "3  1.452137 -0.576067 -0.309651 -0.155767 -0.099152 -0.193691 -0.326769   \n",
       "4 -0.323817 -0.576067 -0.309651 -0.155767 -0.099152 -0.193691 -0.326769   \n",
       "\n",
       "        D10       D11       D12      D13       D14       D15       V37  \\\n",
       "0 -0.616023 -0.503169 -0.133469 -0.08284 -0.127827 -0.710153 -1.025429   \n",
       "1 -0.616023 -0.503169 -0.133469 -0.08284 -0.127827 -0.710153  0.271492   \n",
       "2  2.243298 -0.503169 -0.133469 -0.08284 -0.127827  1.853940  0.271492   \n",
       "3  0.392144  0.648386 -0.133469 -0.08284 -0.127827  0.193920 -1.025429   \n",
       "4 -0.616023 -0.503169 -0.133469 -0.08284 -0.127827 -0.710153 -1.025429   \n",
       "\n",
       "        V38       V44       V45       V56       V77       V78       V80  \\\n",
       "0 -0.923236 -1.053204 -0.995398 -1.328185 -1.476095 -1.175716 -0.321885   \n",
       "1  0.189757  0.308174  0.248921  0.034181  0.123804  0.034274 -0.321885   \n",
       "2  0.189757  0.308174  0.248921  0.034181  0.123804  0.034274 -0.321885   \n",
       "3 -0.923236 -1.053204 -0.995398  0.034181  0.123804  0.034274 -0.321885   \n",
       "4 -0.923236 -1.053204 -0.995398  0.034181  0.123804  0.034274 -0.321885   \n",
       "\n",
       "       V81       V86       V87       V95       V96       V97       V99  \\\n",
       "0 -0.30961 -1.666740 -1.526172 -0.049281 -0.074508 -0.061936 -0.329338   \n",
       "1 -0.30961  0.177113  0.108959 -0.049281 -0.074508 -0.061936 -0.329338   \n",
       "2 -0.30961  0.177113  0.108959 -0.049281 -0.049607 -0.061936  0.039914   \n",
       "3 -0.30961  0.177113  0.108959 -0.049281 -0.074508 -0.061936 -0.329338   \n",
       "4 -0.30961  0.177113  0.108959 -0.001529 -0.049607 -0.025731  0.039914   \n",
       "\n",
       "       V100      V101      V102      V103      V105      V106      V126  \\\n",
       "0 -0.289522 -0.043091 -0.050719 -0.049673 -0.083152 -0.090258 -0.055307   \n",
       "1 -0.289522 -0.043091 -0.050719 -0.049673 -0.083152 -0.090258 -0.055307   \n",
       "2 -0.289522 -0.043091 -0.050719 -0.049673 -0.083152 -0.090258 -0.055307   \n",
       "3 -0.289522 -0.043091 -0.050719 -0.049673 -0.083152 -0.090258 -0.055307   \n",
       "4  0.772454 -0.043091 -0.050719 -0.049673 -0.083152 -0.090258 -0.005284   \n",
       "\n",
       "       V127      V128      V129      V130      V131      V132      V133  \\\n",
       "0 -0.079258 -0.067677 -0.072755 -0.288973 -0.187140 -0.045542 -0.053788   \n",
       "1 -0.079258 -0.067677 -0.072755 -0.288973 -0.187140 -0.045542 -0.053788   \n",
       "2 -0.031988 -0.067677 -0.072755  0.338730 -0.187140 -0.045542 -0.053788   \n",
       "3 -0.079258 -0.067677 -0.072755 -0.288973 -0.187140 -0.045542 -0.053788   \n",
       "4 -0.051605 -0.028719  0.892797  0.078233  0.515279 -0.045542 -0.053788   \n",
       "\n",
       "       V134      V135      V136      V137      V138      V139      V140  \\\n",
       "0 -0.052465 -0.058679 -0.085678 -0.075511 -0.031701  1.362797  1.250752   \n",
       "1 -0.052465 -0.058679 -0.085678 -0.075511 -0.031701 -0.239792 -0.232437   \n",
       "2 -0.052465 -0.058679 -0.085678 -0.075511 -0.031701 -0.239792 -0.232437   \n",
       "3 -0.052465 -0.058679 -0.085678 -0.075511 -0.031701 -0.239792 -0.232437   \n",
       "4 -0.052465 -0.058679 -0.085678 -0.075511 -0.031701 -0.239792 -0.232437   \n",
       "\n",
       "       V143     V144      V145      V146      V147      V148      V149  \\\n",
       "0 -0.055918 -0.12476 -0.121427 -0.083953 -0.082158  2.625280  2.513603   \n",
       "1 -0.055918 -0.12476 -0.121427 -0.083953 -0.082158 -0.312521 -0.303912   \n",
       "2 -0.055918 -0.12476 -0.121427 -0.083953 -0.082158 -0.312521 -0.303912   \n",
       "3 -0.055918 -0.12476 -0.121427 -0.083953 -0.082158 -0.312521 -0.303912   \n",
       "4 -0.055918 -0.12476 -0.121427 -0.083953 -0.082158 -0.312521 -0.303912   \n",
       "\n",
       "       V150      V151      V152      V155      V156      V157      V158  \\\n",
       "0 -0.115427  0.017917 -0.035053  2.582140  2.477739  2.337768  2.227617   \n",
       "1 -0.118531 -0.146723 -0.150773 -0.308673 -0.300664 -0.300284 -0.292522   \n",
       "2 -0.118531 -0.146723 -0.150773 -0.308673 -0.300664 -0.300284 -0.292522   \n",
       "3 -0.118531 -0.146723 -0.150773 -0.308673 -0.300664 -0.300284 -0.292522   \n",
       "4 -0.118531 -0.146723 -0.150773 -0.308673 -0.300664 -0.300284 -0.292522   \n",
       "\n",
       "       V159      V160      V161      V162     V163      V164      V165  \\\n",
       "0 -0.115576 -0.118405 -0.030455 -0.035149 -0.03225 -0.053456 -0.097952   \n",
       "1 -0.115576 -0.118405 -0.030455 -0.035149 -0.03225 -0.053456 -0.097952   \n",
       "2 -0.115576 -0.118405 -0.030455 -0.035149 -0.03225 -0.053456 -0.097952   \n",
       "3 -0.115576 -0.118405 -0.030455 -0.035149 -0.03225 -0.053456 -0.097952   \n",
       "4 -0.115576 -0.118405 -0.030455 -0.035149 -0.03225 -0.053456 -0.097952   \n",
       "\n",
       "      V166      V167      V168      V169      V170      V171     V172  \\\n",
       "0 -0.10278 -0.045024 -0.052381 -0.089246 -0.324797 -0.288607 -0.06896   \n",
       "1 -0.10278 -0.045024 -0.052381 -0.089246 -0.324797 -0.288607 -0.06896   \n",
       "2 -0.10278 -0.045024 -0.052381 -0.089246 -0.324797 -0.288607 -0.06896   \n",
       "3 -0.10278 -0.045024 -0.052381 -0.089246 -0.324797 -0.288607 -0.06896   \n",
       "4 -0.10278 -0.045024 -0.052381 -0.089246 -0.324797 -0.288607 -0.06896   \n",
       "\n",
       "       V176      V177      V178      V179     V180      V181      V182  \\\n",
       "0  0.632101 -0.041292 -0.046295 -0.046597 -0.07271 -0.097544 -0.071066   \n",
       "1 -0.306484 -0.041292 -0.046295 -0.046597 -0.07271 -0.097544 -0.071066   \n",
       "2 -0.306484 -0.041292 -0.046295 -0.046597 -0.07271 -0.097544 -0.071066   \n",
       "3 -0.306484 -0.041292 -0.046295 -0.046597 -0.07271 -0.097544 -0.071066   \n",
       "4 -0.306484 -0.041292 -0.046295 -0.046597 -0.07271 -0.097544 -0.071066   \n",
       "\n",
       "       V183      V185      V186      V187      V188      V189      V190  \\\n",
       "0 -0.079106 -0.119359  0.945534  0.115029 -0.447665 -0.422654  0.805797   \n",
       "1 -0.079106 -0.119359 -0.353630 -0.089382 -0.447665 -0.422654 -0.325115   \n",
       "2 -0.079106 -0.119359 -0.353630 -0.089382 -0.447665 -0.422654 -0.325115   \n",
       "3 -0.079106 -0.119359 -0.353630 -0.089382 -0.447665 -0.422654 -0.325115   \n",
       "4 -0.079106 -0.119359 -0.353630 -0.089382 -0.447665 -0.422654 -0.325115   \n",
       "\n",
       "       V191      V192      V193     V196      V198      V199     V200  \\\n",
       "0  1.343141  0.510182  0.752479  1.04627 -0.483298  0.714725 -0.34294   \n",
       "1 -0.450097 -0.211605 -0.281908 -0.36208 -0.483298 -0.308233 -0.34294   \n",
       "2 -0.450097 -0.211605 -0.281908 -0.36208 -0.483298 -0.308233 -0.34294   \n",
       "3 -0.450097 -0.211605 -0.281908 -0.36208 -0.483298 -0.308233 -0.34294   \n",
       "4 -0.450097 -0.211605 -0.281908 -0.36208 -0.483298 -0.308233 -0.34294   \n",
       "\n",
       "       V201      V202      V203      V204      V205      V206      V207  \\\n",
       "0 -0.323017 -0.045791 -0.057194 -0.054842 -0.031881 -0.015007 -0.037858   \n",
       "1 -0.323017 -0.045791 -0.057194 -0.054842 -0.031881 -0.015007 -0.037858   \n",
       "2 -0.323017 -0.045791 -0.057194 -0.054842 -0.031881 -0.015007 -0.037858   \n",
       "3 -0.323017 -0.045791 -0.057194 -0.054842 -0.031881 -0.015007 -0.037858   \n",
       "4 -0.323017 -0.045791 -0.057194 -0.054842 -0.031881 -0.015007 -0.037858   \n",
       "\n",
       "       V208      V209      V210      V211    V212      V213      V214  \\\n",
       "0 -0.072124 -0.067005 -0.079805 -0.040947 -0.0494 -0.047343 -0.032528   \n",
       "1 -0.072124 -0.067005 -0.079805 -0.040947 -0.0494 -0.047343 -0.032528   \n",
       "2 -0.072124 -0.067005 -0.079805 -0.040947 -0.0494 -0.047343 -0.032528   \n",
       "3 -0.072124 -0.067005 -0.079805 -0.040947 -0.0494 -0.047343 -0.032528   \n",
       "4 -0.072124 -0.067005 -0.079805 -0.040947 -0.0494 -0.047343 -0.032528   \n",
       "\n",
       "       V215      V216      V217      V218      V219     V220      V221  \\\n",
       "0 -0.061764 -0.050674 -0.052212 -0.058176 -0.053373 -0.08205  0.524086   \n",
       "1 -0.061764 -0.050674 -0.052212 -0.058176 -0.053373 -0.08205 -0.230531   \n",
       "2 -0.061764 -0.050674 -0.052212 -0.058176 -0.053373 -0.08205 -0.230531   \n",
       "3 -0.061764 -0.050674 -0.052212 -0.058176 -0.053373 -0.08205 -0.230531   \n",
       "4 -0.061764 -0.050674 -0.052212 -0.058176 -0.053373 -0.08205 -0.230531   \n",
       "\n",
       "       V222      V224      V225     V226      V227      V228      V229  \\\n",
       "0  0.471147 -0.053747 -0.069811 -0.04128 -0.041151  0.803852  0.302501   \n",
       "1 -0.227590 -0.053747 -0.069811 -0.04128 -0.041151 -0.343569 -0.171602   \n",
       "2 -0.227590 -0.053747 -0.069811 -0.04128 -0.041151 -0.343569 -0.171602   \n",
       "3 -0.227590 -0.053747 -0.069811 -0.04128 -0.041151 -0.343569 -0.171602   \n",
       "4 -0.227590 -0.053747 -0.069811 -0.04128 -0.041151 -0.343569 -0.171602   \n",
       "\n",
       "       V230      V231      V232      V233     V234      V235      V236  \\\n",
       "0  0.580496 -0.040645 -0.045145 -0.042053 -0.08919 -0.095307 -0.066844   \n",
       "1 -0.278643 -0.040645 -0.045145 -0.042053 -0.08919 -0.095307 -0.066844   \n",
       "2 -0.278643 -0.040645 -0.045145 -0.042053 -0.08919 -0.095307 -0.066844   \n",
       "3 -0.278643 -0.040645 -0.045145 -0.042053 -0.08919 -0.095307 -0.066844   \n",
       "4 -0.278643 -0.040645 -0.045145 -0.042053 -0.08919 -0.095307 -0.066844   \n",
       "\n",
       "       V237     V238      V239      V242      V243      V244      V245  \\\n",
       "0 -0.069129 -0.10873 -0.108326  1.355961  0.910857  1.324832  0.896841   \n",
       "1 -0.069129 -0.10873 -0.108326 -0.443577 -0.321263 -0.436050 -0.238435   \n",
       "2 -0.069129 -0.10873 -0.108326 -0.443577 -0.321263 -0.436050 -0.238435   \n",
       "3 -0.069129 -0.10873 -0.108326 -0.443577 -0.321263 -0.436050 -0.238435   \n",
       "4 -0.069129 -0.10873 -0.108326 -0.443577 -0.321263 -0.436050 -0.238435   \n",
       "\n",
       "       V246      V248      V249      V252      V253      V254      V255  \\\n",
       "0  1.063006  1.268468  1.551700  1.663359  0.429967  0.993293  1.437926   \n",
       "1 -0.377649 -0.393050 -0.465556 -0.492519 -0.148389 -0.309876 -0.345461   \n",
       "2 -0.377649 -0.393050 -0.465556 -0.492519 -0.148389 -0.309876 -0.345461   \n",
       "3 -0.377649 -0.393050 -0.465556 -0.492519 -0.148389 -0.309876 -0.345461   \n",
       "4 -0.377649 -0.393050 -0.465556 -0.492519 -0.148389 -0.309876 -0.345461   \n",
       "\n",
       "       V256      V257      V258      V259      V261      V262      V263  \\\n",
       "0  1.400867  0.896987  0.641202  0.747955  0.988099  1.518115 -0.041485   \n",
       "1 -0.340874 -0.343962 -0.271606 -0.225907 -0.319623 -0.438433 -0.041485   \n",
       "2 -0.340874 -0.343962 -0.271606 -0.225907 -0.319623 -0.438433 -0.041485   \n",
       "3 -0.340874 -0.343962 -0.271606 -0.225907 -0.319623 -0.438433 -0.041485   \n",
       "4 -0.340874 -0.343962 -0.271606 -0.225907 -0.319623 -0.438433 -0.041485   \n",
       "\n",
       "       V264      V265      V266     V267      V268      V269      V270  \\\n",
       "0 -0.041062 -0.044216 -0.019603 -0.02641 -0.027637 -0.012979 -0.057632   \n",
       "1 -0.041062 -0.044216 -0.019603 -0.02641 -0.027637 -0.012979 -0.057632   \n",
       "2 -0.041062 -0.044216 -0.019603 -0.02641 -0.027637 -0.012979 -0.057632   \n",
       "3 -0.041062 -0.044216 -0.019603 -0.02641 -0.027637 -0.012979 -0.057632   \n",
       "4 -0.041062 -0.044216 -0.019603 -0.02641 -0.027637 -0.012979 -0.057632   \n",
       "\n",
       "       V271      V272      V273     V274      V275      V276      V277  \\\n",
       "0 -0.062164 -0.059283 -0.036909 -0.03958 -0.038675 -0.023196 -0.032106   \n",
       "1 -0.062164 -0.059283 -0.036909 -0.03958 -0.038675 -0.023196 -0.032106   \n",
       "2 -0.062164 -0.059283 -0.036909 -0.03958 -0.038675 -0.023196 -0.032106   \n",
       "3 -0.062164 -0.059283 -0.036909 -0.03958 -0.038675 -0.023196 -0.032106   \n",
       "4 -0.062164 -0.059283 -0.036909 -0.03958 -0.038675 -0.023196 -0.032106   \n",
       "\n",
       "       V278      V279      V280      V281      V282      V283      V285  \\\n",
       "0 -0.028872 -0.053422 -0.070625 -0.170618 -0.882906 -0.630863 -0.357205   \n",
       "1 -0.028872 -0.053422 -0.070625 -0.170618  0.199917  0.007098 -0.357205   \n",
       "2 -0.028872 -0.053422 -0.070625 -0.170618 -0.882906 -0.630863 -0.050212   \n",
       "3 -0.028872 -0.053422 -0.070625 -0.170618 -0.882906 -0.630863 -0.357205   \n",
       "4 -0.028872 -0.005653 -0.034642  1.777032  1.282739  0.645058 -0.050212   \n",
       "\n",
       "       V287      V290     V291      V292      V293      V294      V295  \\\n",
       "0 -0.332543 -0.131711 -0.04042 -0.062849 -0.045744 -0.058539 -0.055212   \n",
       "1 -0.332543 -0.131711 -0.04042 -0.062849 -0.045744 -0.058539 -0.055212   \n",
       "2 -0.332543 -0.131711 -0.04042 -0.062849 -0.045744 -0.058539 -0.055212   \n",
       "3 -0.332543 -0.131711 -0.04042 -0.062849 -0.045744 -0.058539 -0.055212   \n",
       "4  0.596434 -0.131711 -0.04042 -0.062849 -0.045744 -0.058539 -0.055212   \n",
       "\n",
       "      V296      V298      V299      V303      V306      V307      V308  \\\n",
       "0 -0.10044 -0.093916 -0.099373  1.147385 -0.059471 -0.092981 -0.076203   \n",
       "1 -0.10044 -0.093916 -0.099373 -0.454447 -0.059471 -0.092981 -0.076203   \n",
       "2 -0.10044 -0.093916 -0.099373 -0.454447 -0.059471 -0.047467 -0.076203   \n",
       "3 -0.10044 -0.093916 -0.099373 -0.454447 -0.059471 -0.092981 -0.076203   \n",
       "4 -0.10044 -0.093916 -0.099373 -0.454447 -0.009479 -0.066355 -0.037404   \n",
       "\n",
       "       V309      V310      V311      V312      V313      V314      V315  \\\n",
       "0 -0.089662 -0.332187 -0.038594 -0.221127 -0.221827 -0.249078 -0.228881   \n",
       "1 -0.089662 -0.332187 -0.038594 -0.221127 -0.221827 -0.249078 -0.228881   \n",
       "2 -0.089662  0.230393 -0.038594 -0.221127 -0.221827 -0.249078 -0.228881   \n",
       "3 -0.089662 -0.332187 -0.038594 -0.221127 -0.221827 -0.249078 -0.228881   \n",
       "4  0.860296 -0.003077  1.011770  0.437845  0.994093  0.427420  0.772821   \n",
       "\n",
       "       V316      V317      V318      V319      V320      V321      V322  \\\n",
       "0 -0.048346 -0.062216 -0.057999 -0.054761 -0.088248 -0.073425 -0.041168   \n",
       "1 -0.048346 -0.062216 -0.057999 -0.054761 -0.088248 -0.073425 -0.041168   \n",
       "2 -0.048346 -0.062216 -0.057999 -0.054761 -0.088248 -0.073425 -0.041168   \n",
       "3 -0.048346 -0.062216 -0.057999 -0.054761 -0.088248 -0.073425 -0.041168   \n",
       "4 -0.048346 -0.062216 -0.057999 -0.054761 -0.088248 -0.073425 -0.041168   \n",
       "\n",
       "       V323      V324      V326     V329      V330      V331      V332  \\\n",
       "0 -0.045422 -0.046141 -0.078694 -0.05516 -0.060439 -0.043013 -0.045611   \n",
       "1 -0.045422 -0.046141 -0.078694 -0.05516 -0.060439 -0.043013 -0.045611   \n",
       "2 -0.045422 -0.046141 -0.078694 -0.05516 -0.060439 -0.043013 -0.045611   \n",
       "3 -0.045422 -0.046141 -0.078694 -0.05516 -0.060439 -0.043013 -0.045611   \n",
       "4 -0.045422 -0.046141 -0.078694 -0.05516 -0.060439 -0.043013 -0.045611   \n",
       "\n",
       "       V333      V334      V335      V336      V337      V338      V339  \\\n",
       "0 -0.047175 -0.014289 -0.054151 -0.036347 -0.029533 -0.050234 -0.044481   \n",
       "1 -0.047175 -0.014289 -0.054151 -0.036347 -0.029533 -0.050234 -0.044481   \n",
       "2 -0.047175 -0.014289 -0.054151 -0.036347 -0.029533 -0.050234 -0.044481   \n",
       "3 -0.047175 -0.014289 -0.054151 -0.036347 -0.029533 -0.050234 -0.044481   \n",
       "4 -0.047175 -0.014289 -0.054151 -0.036347 -0.029533 -0.050234 -0.044481   \n",
       "\n",
       "      id_01     id_02     id_03     id_05     id_06    id_07     id_08  \\\n",
       "0 -0.300668  0.153944 -0.034193 -0.142894  0.184399 -0.07117  0.077504   \n",
       "1  0.298722 -0.387232 -0.034193 -0.142894  0.184399 -0.07117  0.077504   \n",
       "2  0.298722 -0.387232 -0.034193 -0.142894  0.184399 -0.07117  0.077504   \n",
       "3  0.298722 -0.387232 -0.034193 -0.142894  0.184399 -0.07117  0.077504   \n",
       "4  0.298722 -0.387232 -0.034193 -0.142894  0.184399 -0.07117  0.077504   \n",
       "\n",
       "      id_09     id_10     id_11     id_13     id_14     id_17     id_19  \\\n",
       "0 -0.032413  0.037666  1.788536  2.027221 -2.546586  1.479831  1.313585   \n",
       "1 -0.032413  0.037666 -0.560911 -0.506029  0.380593 -0.547637 -0.506005   \n",
       "2 -0.032413  0.037666 -0.560911 -0.506029  0.380593 -0.547637 -0.506005   \n",
       "3 -0.032413  0.037666 -0.560911 -0.506029  0.380593 -0.547637 -0.506005   \n",
       "4 -0.032413  0.037666 -0.560911 -0.506029  0.380593 -0.547637 -0.506005   \n",
       "\n",
       "      id_20    id_21     id_22     id_25     id_26  Screen_Width  \\\n",
       "0  0.634663 -0.08243 -0.086243 -0.089706 -0.091688      2.674988   \n",
       "1 -0.511042 -0.08243 -0.086243 -0.089706 -0.091688     -0.357827   \n",
       "2 -0.511042 -0.08243 -0.086243 -0.089706 -0.091688     -0.357827   \n",
       "3 -0.511042 -0.08243 -0.086243 -0.089706 -0.091688     -0.357827   \n",
       "4 -0.511042 -0.08243 -0.086243 -0.089706 -0.091688     -0.357827   \n",
       "\n",
       "   Screen_Height  \n",
       "0       2.529625  \n",
       "1      -0.356561  \n",
       "2      -0.356561  \n",
       "3      -0.356561  \n",
       "4      -0.356561  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>V35</th>\n",
       "      <th>V31</th>\n",
       "      <th>M4</th>\n",
       "      <th>R_emaildomain</th>\n",
       "      <th>V122</th>\n",
       "      <th>V75</th>\n",
       "      <th>V84</th>\n",
       "      <th>id_38</th>\n",
       "      <th>V69</th>\n",
       "      <th>V57</th>\n",
       "      <th>V93</th>\n",
       "      <th>V63</th>\n",
       "      <th>V240</th>\n",
       "      <th>V297</th>\n",
       "      <th>V65</th>\n",
       "      <th>V50</th>\n",
       "      <th>V42</th>\n",
       "      <th>V83</th>\n",
       "      <th>V112</th>\n",
       "      <th>V32</th>\n",
       "      <th>V3</th>\n",
       "      <th>id_24</th>\n",
       "      <th>V41</th>\n",
       "      <th>V305</th>\n",
       "      <th>V4</th>\n",
       "      <th>V25</th>\n",
       "      <th>V110</th>\n",
       "      <th>M7</th>\n",
       "      <th>V301</th>\n",
       "      <th>M2</th>\n",
       "      <th>V197</th>\n",
       "      <th>V18</th>\n",
       "      <th>V304</th>\n",
       "      <th>M5</th>\n",
       "      <th>V53</th>\n",
       "      <th>V76</th>\n",
       "      <th>id_18</th>\n",
       "      <th>V325</th>\n",
       "      <th>id_27</th>\n",
       "      <th>id_16</th>\n",
       "      <th>id_34</th>\n",
       "      <th>V175</th>\n",
       "      <th>V64</th>\n",
       "      <th>V141</th>\n",
       "      <th>V8</th>\n",
       "      <th>V15</th>\n",
       "      <th>V173</th>\n",
       "      <th>id_32</th>\n",
       "      <th>V79</th>\n",
       "      <th>V194</th>\n",
       "      <th>V142</th>\n",
       "      <th>DeviceInfo</th>\n",
       "      <th>V94</th>\n",
       "      <th>V250</th>\n",
       "      <th>V19</th>\n",
       "      <th>M3</th>\n",
       "      <th>V288</th>\n",
       "      <th>V113</th>\n",
       "      <th>V328</th>\n",
       "      <th>V48</th>\n",
       "      <th>id_15</th>\n",
       "      <th>V51</th>\n",
       "      <th>V153</th>\n",
       "      <th>card4</th>\n",
       "      <th>V286</th>\n",
       "      <th>V98</th>\n",
       "      <th>id_35</th>\n",
       "      <th>V119</th>\n",
       "      <th>V27</th>\n",
       "      <th>V9</th>\n",
       "      <th>V92</th>\n",
       "      <th>V251</th>\n",
       "      <th>V61</th>\n",
       "      <th>id_28</th>\n",
       "      <th>V195</th>\n",
       "      <th>id_36</th>\n",
       "      <th>V34</th>\n",
       "      <th>V7</th>\n",
       "      <th>V23</th>\n",
       "      <th>V108</th>\n",
       "      <th>V121</th>\n",
       "      <th>V88</th>\n",
       "      <th>V29</th>\n",
       "      <th>V12</th>\n",
       "      <th>V115</th>\n",
       "      <th>V47</th>\n",
       "      <th>V26</th>\n",
       "      <th>M9</th>\n",
       "      <th>V66</th>\n",
       "      <th>V43</th>\n",
       "      <th>V59</th>\n",
       "      <th>V114</th>\n",
       "      <th>id_37</th>\n",
       "      <th>V89</th>\n",
       "      <th>V223</th>\n",
       "      <th>V74</th>\n",
       "      <th>V49</th>\n",
       "      <th>P_emaildomain</th>\n",
       "      <th>V68</th>\n",
       "      <th>V111</th>\n",
       "      <th>id_04</th>\n",
       "      <th>V36</th>\n",
       "      <th>V124</th>\n",
       "      <th>V58</th>\n",
       "      <th>V107</th>\n",
       "      <th>V33</th>\n",
       "      <th>V46</th>\n",
       "      <th>V21</th>\n",
       "      <th>V82</th>\n",
       "      <th>V109</th>\n",
       "      <th>V125</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_12</th>\n",
       "      <th>V73</th>\n",
       "      <th>V52</th>\n",
       "      <th>V116</th>\n",
       "      <th>V13</th>\n",
       "      <th>V302</th>\n",
       "      <th>V104</th>\n",
       "      <th>M1</th>\n",
       "      <th>V17</th>\n",
       "      <th>V6</th>\n",
       "      <th>V24</th>\n",
       "      <th>id_29</th>\n",
       "      <th>V10</th>\n",
       "      <th>V54</th>\n",
       "      <th>V30</th>\n",
       "      <th>V154</th>\n",
       "      <th>V22</th>\n",
       "      <th>V72</th>\n",
       "      <th>V71</th>\n",
       "      <th>V247</th>\n",
       "      <th>V300</th>\n",
       "      <th>V67</th>\n",
       "      <th>V289</th>\n",
       "      <th>V62</th>\n",
       "      <th>V85</th>\n",
       "      <th>V11</th>\n",
       "      <th>V70</th>\n",
       "      <th>id_30</th>\n",
       "      <th>V40</th>\n",
       "      <th>V5</th>\n",
       "      <th>V20</th>\n",
       "      <th>V91</th>\n",
       "      <th>V117</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>M6</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>V14</th>\n",
       "      <th>V16</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V28</th>\n",
       "      <th>V123</th>\n",
       "      <th>V327</th>\n",
       "      <th>V60</th>\n",
       "      <th>V174</th>\n",
       "      <th>V118</th>\n",
       "      <th>V241</th>\n",
       "      <th>V284</th>\n",
       "      <th>V90</th>\n",
       "      <th>V260</th>\n",
       "      <th>V120</th>\n",
       "      <th>id_23</th>\n",
       "      <th>card6</th>\n",
       "      <th>V55</th>\n",
       "      <th>M8</th>\n",
       "      <th>V39</th>\n",
       "      <th>V184</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card5</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>C13</th>\n",
       "      <th>C14</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>D10</th>\n",
       "      <th>D11</th>\n",
       "      <th>D12</th>\n",
       "      <th>D13</th>\n",
       "      <th>D14</th>\n",
       "      <th>D15</th>\n",
       "      <th>V37</th>\n",
       "      <th>V38</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V56</th>\n",
       "      <th>V77</th>\n",
       "      <th>V78</th>\n",
       "      <th>V80</th>\n",
       "      <th>V81</th>\n",
       "      <th>V86</th>\n",
       "      <th>V87</th>\n",
       "      <th>V95</th>\n",
       "      <th>V96</th>\n",
       "      <th>V97</th>\n",
       "      <th>V99</th>\n",
       "      <th>V100</th>\n",
       "      <th>V101</th>\n",
       "      <th>V102</th>\n",
       "      <th>V103</th>\n",
       "      <th>V105</th>\n",
       "      <th>V106</th>\n",
       "      <th>V126</th>\n",
       "      <th>V127</th>\n",
       "      <th>V128</th>\n",
       "      <th>V129</th>\n",
       "      <th>V130</th>\n",
       "      <th>V131</th>\n",
       "      <th>V132</th>\n",
       "      <th>V133</th>\n",
       "      <th>V134</th>\n",
       "      <th>V135</th>\n",
       "      <th>V136</th>\n",
       "      <th>V137</th>\n",
       "      <th>V138</th>\n",
       "      <th>V139</th>\n",
       "      <th>V140</th>\n",
       "      <th>V143</th>\n",
       "      <th>V144</th>\n",
       "      <th>V145</th>\n",
       "      <th>V146</th>\n",
       "      <th>V147</th>\n",
       "      <th>V148</th>\n",
       "      <th>V149</th>\n",
       "      <th>V150</th>\n",
       "      <th>V151</th>\n",
       "      <th>V152</th>\n",
       "      <th>V155</th>\n",
       "      <th>V156</th>\n",
       "      <th>V157</th>\n",
       "      <th>V158</th>\n",
       "      <th>V159</th>\n",
       "      <th>V160</th>\n",
       "      <th>V161</th>\n",
       "      <th>V162</th>\n",
       "      <th>V163</th>\n",
       "      <th>V164</th>\n",
       "      <th>V165</th>\n",
       "      <th>V166</th>\n",
       "      <th>V167</th>\n",
       "      <th>V168</th>\n",
       "      <th>V169</th>\n",
       "      <th>V170</th>\n",
       "      <th>V171</th>\n",
       "      <th>V172</th>\n",
       "      <th>V176</th>\n",
       "      <th>V177</th>\n",
       "      <th>V178</th>\n",
       "      <th>V179</th>\n",
       "      <th>V180</th>\n",
       "      <th>V181</th>\n",
       "      <th>V182</th>\n",
       "      <th>V183</th>\n",
       "      <th>V185</th>\n",
       "      <th>V186</th>\n",
       "      <th>V187</th>\n",
       "      <th>V188</th>\n",
       "      <th>V189</th>\n",
       "      <th>V190</th>\n",
       "      <th>V191</th>\n",
       "      <th>V192</th>\n",
       "      <th>V193</th>\n",
       "      <th>V196</th>\n",
       "      <th>V198</th>\n",
       "      <th>V199</th>\n",
       "      <th>V200</th>\n",
       "      <th>V201</th>\n",
       "      <th>V202</th>\n",
       "      <th>V203</th>\n",
       "      <th>V204</th>\n",
       "      <th>V205</th>\n",
       "      <th>V206</th>\n",
       "      <th>V207</th>\n",
       "      <th>V208</th>\n",
       "      <th>V209</th>\n",
       "      <th>V210</th>\n",
       "      <th>V211</th>\n",
       "      <th>V212</th>\n",
       "      <th>V213</th>\n",
       "      <th>V214</th>\n",
       "      <th>V215</th>\n",
       "      <th>V216</th>\n",
       "      <th>V217</th>\n",
       "      <th>V218</th>\n",
       "      <th>V219</th>\n",
       "      <th>V220</th>\n",
       "      <th>V221</th>\n",
       "      <th>V222</th>\n",
       "      <th>V224</th>\n",
       "      <th>V225</th>\n",
       "      <th>V226</th>\n",
       "      <th>V227</th>\n",
       "      <th>V228</th>\n",
       "      <th>V229</th>\n",
       "      <th>V230</th>\n",
       "      <th>V231</th>\n",
       "      <th>V232</th>\n",
       "      <th>V233</th>\n",
       "      <th>V234</th>\n",
       "      <th>V235</th>\n",
       "      <th>V236</th>\n",
       "      <th>V237</th>\n",
       "      <th>V238</th>\n",
       "      <th>V239</th>\n",
       "      <th>V242</th>\n",
       "      <th>V243</th>\n",
       "      <th>V244</th>\n",
       "      <th>V245</th>\n",
       "      <th>V246</th>\n",
       "      <th>V248</th>\n",
       "      <th>V249</th>\n",
       "      <th>V252</th>\n",
       "      <th>V253</th>\n",
       "      <th>V254</th>\n",
       "      <th>V255</th>\n",
       "      <th>V256</th>\n",
       "      <th>V257</th>\n",
       "      <th>V258</th>\n",
       "      <th>V259</th>\n",
       "      <th>V261</th>\n",
       "      <th>V262</th>\n",
       "      <th>V263</th>\n",
       "      <th>V264</th>\n",
       "      <th>V265</th>\n",
       "      <th>V266</th>\n",
       "      <th>V267</th>\n",
       "      <th>V268</th>\n",
       "      <th>V269</th>\n",
       "      <th>V270</th>\n",
       "      <th>V271</th>\n",
       "      <th>V272</th>\n",
       "      <th>V273</th>\n",
       "      <th>V274</th>\n",
       "      <th>V275</th>\n",
       "      <th>V276</th>\n",
       "      <th>V277</th>\n",
       "      <th>V278</th>\n",
       "      <th>V279</th>\n",
       "      <th>V280</th>\n",
       "      <th>V281</th>\n",
       "      <th>V282</th>\n",
       "      <th>V283</th>\n",
       "      <th>V285</th>\n",
       "      <th>V287</th>\n",
       "      <th>V290</th>\n",
       "      <th>V291</th>\n",
       "      <th>V292</th>\n",
       "      <th>V293</th>\n",
       "      <th>V294</th>\n",
       "      <th>V295</th>\n",
       "      <th>V296</th>\n",
       "      <th>V298</th>\n",
       "      <th>V299</th>\n",
       "      <th>V303</th>\n",
       "      <th>V306</th>\n",
       "      <th>V307</th>\n",
       "      <th>V308</th>\n",
       "      <th>V309</th>\n",
       "      <th>V310</th>\n",
       "      <th>V311</th>\n",
       "      <th>V312</th>\n",
       "      <th>V313</th>\n",
       "      <th>V314</th>\n",
       "      <th>V315</th>\n",
       "      <th>V316</th>\n",
       "      <th>V317</th>\n",
       "      <th>V318</th>\n",
       "      <th>V319</th>\n",
       "      <th>V320</th>\n",
       "      <th>V321</th>\n",
       "      <th>V322</th>\n",
       "      <th>V323</th>\n",
       "      <th>V324</th>\n",
       "      <th>V326</th>\n",
       "      <th>V329</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "      <th>id_01</th>\n",
       "      <th>id_02</th>\n",
       "      <th>id_03</th>\n",
       "      <th>id_05</th>\n",
       "      <th>id_06</th>\n",
       "      <th>id_07</th>\n",
       "      <th>id_08</th>\n",
       "      <th>id_09</th>\n",
       "      <th>id_10</th>\n",
       "      <th>id_11</th>\n",
       "      <th>id_13</th>\n",
       "      <th>id_14</th>\n",
       "      <th>id_17</th>\n",
       "      <th>id_19</th>\n",
       "      <th>id_20</th>\n",
       "      <th>id_21</th>\n",
       "      <th>id_22</th>\n",
       "      <th>id_25</th>\n",
       "      <th>id_26</th>\n",
       "      <th>Screen_Width</th>\n",
       "      <th>Screen_Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549.0</td>\n",
       "      <td>-1.209963</td>\n",
       "      <td>-0.544587</td>\n",
       "      <td>-0.803152</td>\n",
       "      <td>-0.434818</td>\n",
       "      <td>-0.041814</td>\n",
       "      <td>0.799095</td>\n",
       "      <td>-0.551276</td>\n",
       "      <td>-0.546267</td>\n",
       "      <td>0.643397</td>\n",
       "      <td>-0.537535</td>\n",
       "      <td>-0.566493</td>\n",
       "      <td>-0.542801</td>\n",
       "      <td>-0.533175</td>\n",
       "      <td>-0.108377</td>\n",
       "      <td>-0.385432</td>\n",
       "      <td>-0.663889</td>\n",
       "      <td>-0.634533</td>\n",
       "      <td>-0.136447</td>\n",
       "      <td>-0.069307</td>\n",
       "      <td>-0.544537</td>\n",
       "      <td>-1.007672</td>\n",
       "      <td>-0.083475</td>\n",
       "      <td>-0.339302</td>\n",
       "      <td>-0.004593</td>\n",
       "      <td>-0.99097</td>\n",
       "      <td>1.079944</td>\n",
       "      <td>-0.083589</td>\n",
       "      <td>-0.949928</td>\n",
       "      <td>-0.193018</td>\n",
       "      <td>-1.019015</td>\n",
       "      <td>-0.526503</td>\n",
       "      <td>-0.527372</td>\n",
       "      <td>-0.553863</td>\n",
       "      <td>0.519333</td>\n",
       "      <td>0.706862</td>\n",
       "      <td>0.841976</td>\n",
       "      <td>-0.272797</td>\n",
       "      <td>-0.389465</td>\n",
       "      <td>-0.093859</td>\n",
       "      <td>-0.49368</td>\n",
       "      <td>-0.294501</td>\n",
       "      <td>-0.529056</td>\n",
       "      <td>-0.542678</td>\n",
       "      <td>-0.300054</td>\n",
       "      <td>-0.965816</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>-0.553826</td>\n",
       "      <td>-0.205104</td>\n",
       "      <td>-0.540532</td>\n",
       "      <td>-0.524318</td>\n",
       "      <td>-0.298381</td>\n",
       "      <td>-0.326247</td>\n",
       "      <td>-0.559101</td>\n",
       "      <td>-0.533809</td>\n",
       "      <td>-1.462481</td>\n",
       "      <td>-0.010886</td>\n",
       "      <td>-0.397750</td>\n",
       "      <td>-0.055439</td>\n",
       "      <td>-0.228292</td>\n",
       "      <td>-1.660800</td>\n",
       "      <td>-0.531932</td>\n",
       "      <td>-0.656132</td>\n",
       "      <td>-0.076617</td>\n",
       "      <td>-0.029009</td>\n",
       "      <td>-0.154066</td>\n",
       "      <td>-0.234589</td>\n",
       "      <td>-0.501808</td>\n",
       "      <td>-0.031981</td>\n",
       "      <td>-0.346458</td>\n",
       "      <td>-0.985232</td>\n",
       "      <td>-0.569585</td>\n",
       "      <td>-0.526942</td>\n",
       "      <td>-1.149454</td>\n",
       "      <td>-0.535487</td>\n",
       "      <td>-0.522041</td>\n",
       "      <td>-0.553407</td>\n",
       "      <td>-0.54016</td>\n",
       "      <td>-0.996581</td>\n",
       "      <td>-0.352363</td>\n",
       "      <td>-0.066125</td>\n",
       "      <td>-0.065564</td>\n",
       "      <td>-0.422264</td>\n",
       "      <td>0.684057</td>\n",
       "      <td>0.816550</td>\n",
       "      <td>-0.162702</td>\n",
       "      <td>-0.327293</td>\n",
       "      <td>0.780794</td>\n",
       "      <td>-1.331973</td>\n",
       "      <td>0.773818</td>\n",
       "      <td>-0.633584</td>\n",
       "      <td>-0.542823</td>\n",
       "      <td>-0.090673</td>\n",
       "      <td>-0.55872</td>\n",
       "      <td>-0.376049</td>\n",
       "      <td>-0.531279</td>\n",
       "      <td>-0.560236</td>\n",
       "      <td>-1.685703</td>\n",
       "      <td>0.706391</td>\n",
       "      <td>-0.377186</td>\n",
       "      <td>-0.04969</td>\n",
       "      <td>-0.35455</td>\n",
       "      <td>-1.188271</td>\n",
       "      <td>-0.22275</td>\n",
       "      <td>-0.535084</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>-0.528523</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>-0.528749</td>\n",
       "      <td>-0.100484</td>\n",
       "      <td>-0.114522</td>\n",
       "      <td>-0.182099</td>\n",
       "      <td>-0.463749</td>\n",
       "      <td>-0.566417</td>\n",
       "      <td>-0.551901</td>\n",
       "      <td>-0.660177</td>\n",
       "      <td>-0.116566</td>\n",
       "      <td>0.843152</td>\n",
       "      <td>-0.556132</td>\n",
       "      <td>-0.130335</td>\n",
       "      <td>-0.922256</td>\n",
       "      <td>-0.527387</td>\n",
       "      <td>-0.964954</td>\n",
       "      <td>-0.390305</td>\n",
       "      <td>-0.532699</td>\n",
       "      <td>-1.72242</td>\n",
       "      <td>0.728937</td>\n",
       "      <td>0.686806</td>\n",
       "      <td>-0.05709</td>\n",
       "      <td>-0.52808</td>\n",
       "      <td>-0.553281</td>\n",
       "      <td>-0.556269</td>\n",
       "      <td>-0.494734</td>\n",
       "      <td>-0.183244</td>\n",
       "      <td>0.669091</td>\n",
       "      <td>-0.356303</td>\n",
       "      <td>-1.117969</td>\n",
       "      <td>-0.55055</td>\n",
       "      <td>-1.730432</td>\n",
       "      <td>0.646860</td>\n",
       "      <td>-0.083471</td>\n",
       "      <td>-0.632061</td>\n",
       "      <td>-0.973044</td>\n",
       "      <td>-1.560152</td>\n",
       "      <td>-1.466143</td>\n",
       "      <td>-0.028718</td>\n",
       "      <td>-0.526444</td>\n",
       "      <td>-0.348024</td>\n",
       "      <td>-0.550072</td>\n",
       "      <td>-0.381317</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>-0.94828</td>\n",
       "      <td>-0.977981</td>\n",
       "      <td>-0.34976</td>\n",
       "      <td>-0.14449</td>\n",
       "      <td>-0.241668</td>\n",
       "      <td>-0.542326</td>\n",
       "      <td>-0.556514</td>\n",
       "      <td>-0.042189</td>\n",
       "      <td>-0.533263</td>\n",
       "      <td>-0.284724</td>\n",
       "      <td>-1.448103</td>\n",
       "      <td>-0.50769</td>\n",
       "      <td>-0.033802</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>-0.58175</td>\n",
       "      <td>-0.438362</td>\n",
       "      <td>-1.627023</td>\n",
       "      <td>-0.633937</td>\n",
       "      <td>-0.539156</td>\n",
       "      <td>2.389216</td>\n",
       "      <td>-0.427233</td>\n",
       "      <td>0.103203</td>\n",
       "      <td>-1.512083</td>\n",
       "      <td>-0.203484</td>\n",
       "      <td>0.633778</td>\n",
       "      <td>-0.665955</td>\n",
       "      <td>0.360192</td>\n",
       "      <td>-0.192433</td>\n",
       "      <td>-0.101669</td>\n",
       "      <td>-0.060670</td>\n",
       "      <td>-0.060075</td>\n",
       "      <td>-0.039137</td>\n",
       "      <td>-0.059583</td>\n",
       "      <td>-0.099214</td>\n",
       "      <td>-0.070961</td>\n",
       "      <td>-0.046189</td>\n",
       "      <td>-0.054075</td>\n",
       "      <td>0.092101</td>\n",
       "      <td>-0.054926</td>\n",
       "      <td>-0.055569</td>\n",
       "      <td>-0.035446</td>\n",
       "      <td>0.641595</td>\n",
       "      <td>-0.046025</td>\n",
       "      <td>2.063359</td>\n",
       "      <td>2.147310</td>\n",
       "      <td>0.233750</td>\n",
       "      <td>1.720210</td>\n",
       "      <td>0.106599</td>\n",
       "      <td>-0.155767</td>\n",
       "      <td>-0.099152</td>\n",
       "      <td>-0.193691</td>\n",
       "      <td>-0.326769</td>\n",
       "      <td>1.764846</td>\n",
       "      <td>0.817541</td>\n",
       "      <td>-0.133469</td>\n",
       "      <td>-0.08284</td>\n",
       "      <td>-0.127827</td>\n",
       "      <td>1.378919</td>\n",
       "      <td>0.271492</td>\n",
       "      <td>0.189757</td>\n",
       "      <td>0.308174</td>\n",
       "      <td>0.248921</td>\n",
       "      <td>0.034181</td>\n",
       "      <td>0.123804</td>\n",
       "      <td>0.034274</td>\n",
       "      <td>-0.321885</td>\n",
       "      <td>-0.30961</td>\n",
       "      <td>0.177113</td>\n",
       "      <td>0.108959</td>\n",
       "      <td>-0.049281</td>\n",
       "      <td>-0.049607</td>\n",
       "      <td>-0.061936</td>\n",
       "      <td>0.039914</td>\n",
       "      <td>-0.289522</td>\n",
       "      <td>-0.043091</td>\n",
       "      <td>-0.050719</td>\n",
       "      <td>-0.049673</td>\n",
       "      <td>-0.083152</td>\n",
       "      <td>-0.090258</td>\n",
       "      <td>-0.055307</td>\n",
       "      <td>-0.067925</td>\n",
       "      <td>-0.067677</td>\n",
       "      <td>-0.072755</td>\n",
       "      <td>-0.138481</td>\n",
       "      <td>-0.187140</td>\n",
       "      <td>-0.045542</td>\n",
       "      <td>-0.053788</td>\n",
       "      <td>-0.052465</td>\n",
       "      <td>-0.058679</td>\n",
       "      <td>-0.085678</td>\n",
       "      <td>-0.075511</td>\n",
       "      <td>-0.031701</td>\n",
       "      <td>-0.239792</td>\n",
       "      <td>-0.232437</td>\n",
       "      <td>-0.055918</td>\n",
       "      <td>-0.12476</td>\n",
       "      <td>-0.121427</td>\n",
       "      <td>-0.083953</td>\n",
       "      <td>-0.082158</td>\n",
       "      <td>-0.312521</td>\n",
       "      <td>-0.303912</td>\n",
       "      <td>-0.118531</td>\n",
       "      <td>-0.146723</td>\n",
       "      <td>-0.150773</td>\n",
       "      <td>-0.308673</td>\n",
       "      <td>-0.300664</td>\n",
       "      <td>-0.300284</td>\n",
       "      <td>-0.292522</td>\n",
       "      <td>-0.115576</td>\n",
       "      <td>-0.118405</td>\n",
       "      <td>-0.030455</td>\n",
       "      <td>-0.035149</td>\n",
       "      <td>-0.03225</td>\n",
       "      <td>-0.053456</td>\n",
       "      <td>-0.097952</td>\n",
       "      <td>-0.10278</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.052381</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>-0.324797</td>\n",
       "      <td>-0.288607</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>-0.306484</td>\n",
       "      <td>-0.041292</td>\n",
       "      <td>-0.046295</td>\n",
       "      <td>-0.046597</td>\n",
       "      <td>-0.07271</td>\n",
       "      <td>-0.097544</td>\n",
       "      <td>-0.071066</td>\n",
       "      <td>-0.079106</td>\n",
       "      <td>-0.119359</td>\n",
       "      <td>-0.35363</td>\n",
       "      <td>-0.089382</td>\n",
       "      <td>-0.447665</td>\n",
       "      <td>-0.422654</td>\n",
       "      <td>-0.325115</td>\n",
       "      <td>-0.450097</td>\n",
       "      <td>-0.211605</td>\n",
       "      <td>-0.281908</td>\n",
       "      <td>-0.36208</td>\n",
       "      <td>-0.483298</td>\n",
       "      <td>-0.308233</td>\n",
       "      <td>-0.34294</td>\n",
       "      <td>-0.323017</td>\n",
       "      <td>-0.045791</td>\n",
       "      <td>-0.057194</td>\n",
       "      <td>-0.054842</td>\n",
       "      <td>-0.031881</td>\n",
       "      <td>-0.015007</td>\n",
       "      <td>-0.037858</td>\n",
       "      <td>-0.072124</td>\n",
       "      <td>-0.067005</td>\n",
       "      <td>-0.079805</td>\n",
       "      <td>-0.040947</td>\n",
       "      <td>-0.0494</td>\n",
       "      <td>-0.047343</td>\n",
       "      <td>-0.032528</td>\n",
       "      <td>-0.061764</td>\n",
       "      <td>-0.050674</td>\n",
       "      <td>-0.052212</td>\n",
       "      <td>-0.058176</td>\n",
       "      <td>-0.053373</td>\n",
       "      <td>-0.08205</td>\n",
       "      <td>-0.230531</td>\n",
       "      <td>-0.22759</td>\n",
       "      <td>-0.053747</td>\n",
       "      <td>-0.069811</td>\n",
       "      <td>-0.04128</td>\n",
       "      <td>-0.041151</td>\n",
       "      <td>-0.343569</td>\n",
       "      <td>-0.171602</td>\n",
       "      <td>-0.278643</td>\n",
       "      <td>-0.040645</td>\n",
       "      <td>-0.045145</td>\n",
       "      <td>-0.042053</td>\n",
       "      <td>-0.08919</td>\n",
       "      <td>-0.095307</td>\n",
       "      <td>-0.066844</td>\n",
       "      <td>-0.069129</td>\n",
       "      <td>-0.10873</td>\n",
       "      <td>-0.108326</td>\n",
       "      <td>-0.443577</td>\n",
       "      <td>-0.321263</td>\n",
       "      <td>-0.43605</td>\n",
       "      <td>-0.238435</td>\n",
       "      <td>-0.377649</td>\n",
       "      <td>-0.39305</td>\n",
       "      <td>-0.465556</td>\n",
       "      <td>-0.492519</td>\n",
       "      <td>-0.148389</td>\n",
       "      <td>-0.309876</td>\n",
       "      <td>-0.345461</td>\n",
       "      <td>-0.340874</td>\n",
       "      <td>-0.343962</td>\n",
       "      <td>-0.271606</td>\n",
       "      <td>-0.225907</td>\n",
       "      <td>-0.319623</td>\n",
       "      <td>-0.438433</td>\n",
       "      <td>-0.041485</td>\n",
       "      <td>-0.041062</td>\n",
       "      <td>-0.044216</td>\n",
       "      <td>-0.019603</td>\n",
       "      <td>-0.02641</td>\n",
       "      <td>-0.027637</td>\n",
       "      <td>-0.012979</td>\n",
       "      <td>-0.057632</td>\n",
       "      <td>-0.062164</td>\n",
       "      <td>-0.059283</td>\n",
       "      <td>-0.036909</td>\n",
       "      <td>-0.03958</td>\n",
       "      <td>-0.038675</td>\n",
       "      <td>-0.023196</td>\n",
       "      <td>-0.032106</td>\n",
       "      <td>-0.028872</td>\n",
       "      <td>-0.053422</td>\n",
       "      <td>-0.070625</td>\n",
       "      <td>-0.170618</td>\n",
       "      <td>-0.882906</td>\n",
       "      <td>-0.630863</td>\n",
       "      <td>-0.050212</td>\n",
       "      <td>-0.332543</td>\n",
       "      <td>-0.131711</td>\n",
       "      <td>-0.040420</td>\n",
       "      <td>-0.062849</td>\n",
       "      <td>-0.045744</td>\n",
       "      <td>-0.058539</td>\n",
       "      <td>-0.055212</td>\n",
       "      <td>-0.100440</td>\n",
       "      <td>-0.093916</td>\n",
       "      <td>-0.099373</td>\n",
       "      <td>-0.454447</td>\n",
       "      <td>-0.059471</td>\n",
       "      <td>-0.082069</td>\n",
       "      <td>-0.076203</td>\n",
       "      <td>-0.089662</td>\n",
       "      <td>-0.197308</td>\n",
       "      <td>-0.038594</td>\n",
       "      <td>-0.221127</td>\n",
       "      <td>-0.221827</td>\n",
       "      <td>-0.249078</td>\n",
       "      <td>-0.228881</td>\n",
       "      <td>-0.048346</td>\n",
       "      <td>-0.062216</td>\n",
       "      <td>-0.057999</td>\n",
       "      <td>-0.054761</td>\n",
       "      <td>-0.088248</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.041168</td>\n",
       "      <td>-0.045422</td>\n",
       "      <td>-0.046141</td>\n",
       "      <td>-0.078694</td>\n",
       "      <td>-0.05516</td>\n",
       "      <td>-0.060439</td>\n",
       "      <td>-0.043013</td>\n",
       "      <td>-0.045611</td>\n",
       "      <td>-0.047175</td>\n",
       "      <td>-0.014289</td>\n",
       "      <td>-0.054151</td>\n",
       "      <td>-0.036347</td>\n",
       "      <td>-0.029533</td>\n",
       "      <td>-0.050234</td>\n",
       "      <td>-0.044481</td>\n",
       "      <td>0.298722</td>\n",
       "      <td>-0.387232</td>\n",
       "      <td>-0.034193</td>\n",
       "      <td>-0.142894</td>\n",
       "      <td>0.184399</td>\n",
       "      <td>-0.07117</td>\n",
       "      <td>0.077504</td>\n",
       "      <td>-0.032413</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>-0.560911</td>\n",
       "      <td>-0.506029</td>\n",
       "      <td>0.380593</td>\n",
       "      <td>-0.547637</td>\n",
       "      <td>-0.506005</td>\n",
       "      <td>-0.511042</td>\n",
       "      <td>-0.08243</td>\n",
       "      <td>-0.086243</td>\n",
       "      <td>-0.089706</td>\n",
       "      <td>-0.091688</td>\n",
       "      <td>-0.357827</td>\n",
       "      <td>-0.356561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550.0</td>\n",
       "      <td>-1.209963</td>\n",
       "      <td>-0.544587</td>\n",
       "      <td>0.407824</td>\n",
       "      <td>-0.434818</td>\n",
       "      <td>-0.041814</td>\n",
       "      <td>-1.083156</td>\n",
       "      <td>-0.551276</td>\n",
       "      <td>-0.546267</td>\n",
       "      <td>0.643397</td>\n",
       "      <td>-0.537535</td>\n",
       "      <td>-0.566493</td>\n",
       "      <td>-0.542801</td>\n",
       "      <td>-0.533175</td>\n",
       "      <td>-0.108377</td>\n",
       "      <td>-0.385432</td>\n",
       "      <td>-0.663889</td>\n",
       "      <td>-0.634533</td>\n",
       "      <td>-0.136447</td>\n",
       "      <td>-0.069307</td>\n",
       "      <td>-0.544537</td>\n",
       "      <td>-1.007672</td>\n",
       "      <td>-0.083475</td>\n",
       "      <td>-0.339302</td>\n",
       "      <td>-0.004593</td>\n",
       "      <td>-0.99097</td>\n",
       "      <td>-0.413764</td>\n",
       "      <td>-0.083589</td>\n",
       "      <td>0.837200</td>\n",
       "      <td>-0.193018</td>\n",
       "      <td>0.273469</td>\n",
       "      <td>-0.526503</td>\n",
       "      <td>-0.527372</td>\n",
       "      <td>-0.553863</td>\n",
       "      <td>0.519333</td>\n",
       "      <td>0.706862</td>\n",
       "      <td>-1.059143</td>\n",
       "      <td>-0.272797</td>\n",
       "      <td>-0.389465</td>\n",
       "      <td>-0.093859</td>\n",
       "      <td>-0.49368</td>\n",
       "      <td>-0.294501</td>\n",
       "      <td>-0.529056</td>\n",
       "      <td>-0.542678</td>\n",
       "      <td>-0.300054</td>\n",
       "      <td>-0.965816</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>-0.553826</td>\n",
       "      <td>-0.205104</td>\n",
       "      <td>-0.540532</td>\n",
       "      <td>-0.524318</td>\n",
       "      <td>-0.298381</td>\n",
       "      <td>-0.326247</td>\n",
       "      <td>-0.559101</td>\n",
       "      <td>-0.533809</td>\n",
       "      <td>-0.039890</td>\n",
       "      <td>-0.010886</td>\n",
       "      <td>-0.397750</td>\n",
       "      <td>-0.055439</td>\n",
       "      <td>-0.228292</td>\n",
       "      <td>0.748619</td>\n",
       "      <td>-0.531932</td>\n",
       "      <td>-0.656132</td>\n",
       "      <td>-0.076617</td>\n",
       "      <td>-0.029009</td>\n",
       "      <td>-0.154066</td>\n",
       "      <td>-0.234589</td>\n",
       "      <td>-0.501808</td>\n",
       "      <td>-0.031981</td>\n",
       "      <td>-0.346458</td>\n",
       "      <td>-0.985232</td>\n",
       "      <td>-0.569585</td>\n",
       "      <td>-0.526942</td>\n",
       "      <td>-0.174917</td>\n",
       "      <td>-0.535487</td>\n",
       "      <td>-0.522041</td>\n",
       "      <td>-0.553407</td>\n",
       "      <td>-0.54016</td>\n",
       "      <td>-0.996581</td>\n",
       "      <td>-0.352363</td>\n",
       "      <td>-0.066125</td>\n",
       "      <td>-0.065564</td>\n",
       "      <td>-0.422264</td>\n",
       "      <td>0.684057</td>\n",
       "      <td>-1.019282</td>\n",
       "      <td>-0.162702</td>\n",
       "      <td>-0.327293</td>\n",
       "      <td>-0.408597</td>\n",
       "      <td>0.806283</td>\n",
       "      <td>-0.407192</td>\n",
       "      <td>-0.633584</td>\n",
       "      <td>-0.542823</td>\n",
       "      <td>-0.090673</td>\n",
       "      <td>-0.55872</td>\n",
       "      <td>-0.376049</td>\n",
       "      <td>-0.531279</td>\n",
       "      <td>-0.560236</td>\n",
       "      <td>0.744573</td>\n",
       "      <td>-0.928992</td>\n",
       "      <td>-0.377186</td>\n",
       "      <td>-0.04969</td>\n",
       "      <td>-0.35455</td>\n",
       "      <td>-1.188271</td>\n",
       "      <td>-0.22275</td>\n",
       "      <td>-0.535084</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>-0.528523</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>-0.528749</td>\n",
       "      <td>-0.100484</td>\n",
       "      <td>-0.114522</td>\n",
       "      <td>-0.182099</td>\n",
       "      <td>-0.463749</td>\n",
       "      <td>-0.566417</td>\n",
       "      <td>-0.551901</td>\n",
       "      <td>-0.660177</td>\n",
       "      <td>-0.116566</td>\n",
       "      <td>-1.002589</td>\n",
       "      <td>-0.556132</td>\n",
       "      <td>-0.130335</td>\n",
       "      <td>-0.922256</td>\n",
       "      <td>-0.527387</td>\n",
       "      <td>-0.964954</td>\n",
       "      <td>-0.390305</td>\n",
       "      <td>-0.532699</td>\n",
       "      <td>0.07973</td>\n",
       "      <td>0.728937</td>\n",
       "      <td>0.686806</td>\n",
       "      <td>-0.05709</td>\n",
       "      <td>-0.52808</td>\n",
       "      <td>-0.553281</td>\n",
       "      <td>-0.556269</td>\n",
       "      <td>-0.494734</td>\n",
       "      <td>-0.183244</td>\n",
       "      <td>-0.411473</td>\n",
       "      <td>-0.356303</td>\n",
       "      <td>-0.231481</td>\n",
       "      <td>-0.55055</td>\n",
       "      <td>0.080027</td>\n",
       "      <td>0.646860</td>\n",
       "      <td>-0.083471</td>\n",
       "      <td>-0.632061</td>\n",
       "      <td>-0.973044</td>\n",
       "      <td>-0.045786</td>\n",
       "      <td>0.704683</td>\n",
       "      <td>-0.028718</td>\n",
       "      <td>-0.526444</td>\n",
       "      <td>-0.348024</td>\n",
       "      <td>-0.550072</td>\n",
       "      <td>-0.381317</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>-0.94828</td>\n",
       "      <td>-0.977981</td>\n",
       "      <td>-0.34976</td>\n",
       "      <td>-0.14449</td>\n",
       "      <td>-0.241668</td>\n",
       "      <td>-0.542326</td>\n",
       "      <td>-0.556514</td>\n",
       "      <td>-0.042189</td>\n",
       "      <td>-0.533263</td>\n",
       "      <td>-0.284724</td>\n",
       "      <td>0.703487</td>\n",
       "      <td>-0.50769</td>\n",
       "      <td>-0.033802</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>-0.58175</td>\n",
       "      <td>-0.438362</td>\n",
       "      <td>0.816915</td>\n",
       "      <td>-0.633937</td>\n",
       "      <td>-0.539156</td>\n",
       "      <td>2.389225</td>\n",
       "      <td>-0.356595</td>\n",
       "      <td>-1.148561</td>\n",
       "      <td>-1.512083</td>\n",
       "      <td>-0.203484</td>\n",
       "      <td>0.633778</td>\n",
       "      <td>0.306803</td>\n",
       "      <td>0.360192</td>\n",
       "      <td>-0.180097</td>\n",
       "      <td>-0.101669</td>\n",
       "      <td>-0.083328</td>\n",
       "      <td>-0.086169</td>\n",
       "      <td>-0.039137</td>\n",
       "      <td>-0.059583</td>\n",
       "      <td>-0.215803</td>\n",
       "      <td>-0.113225</td>\n",
       "      <td>-0.046189</td>\n",
       "      <td>-0.054075</td>\n",
       "      <td>-0.148321</td>\n",
       "      <td>-0.054926</td>\n",
       "      <td>-0.098328</td>\n",
       "      <td>-0.035446</td>\n",
       "      <td>-0.158638</td>\n",
       "      <td>-0.127270</td>\n",
       "      <td>0.348739</td>\n",
       "      <td>0.391102</td>\n",
       "      <td>-0.179262</td>\n",
       "      <td>3.081821</td>\n",
       "      <td>-0.201734</td>\n",
       "      <td>-0.155767</td>\n",
       "      <td>-0.099152</td>\n",
       "      <td>-0.193691</td>\n",
       "      <td>-0.326769</td>\n",
       "      <td>0.699720</td>\n",
       "      <td>3.621611</td>\n",
       "      <td>-0.133469</td>\n",
       "      <td>-0.08284</td>\n",
       "      <td>-0.127827</td>\n",
       "      <td>2.528164</td>\n",
       "      <td>0.271492</td>\n",
       "      <td>0.189757</td>\n",
       "      <td>0.308174</td>\n",
       "      <td>0.248921</td>\n",
       "      <td>0.034181</td>\n",
       "      <td>0.123804</td>\n",
       "      <td>0.034274</td>\n",
       "      <td>-0.321885</td>\n",
       "      <td>-0.30961</td>\n",
       "      <td>0.177113</td>\n",
       "      <td>0.108959</td>\n",
       "      <td>-0.049281</td>\n",
       "      <td>0.025097</td>\n",
       "      <td>-0.025731</td>\n",
       "      <td>1.147669</td>\n",
       "      <td>0.772454</td>\n",
       "      <td>-0.043091</td>\n",
       "      <td>-0.050719</td>\n",
       "      <td>-0.049673</td>\n",
       "      <td>-0.083152</td>\n",
       "      <td>-0.090258</td>\n",
       "      <td>-0.055307</td>\n",
       "      <td>-0.013079</td>\n",
       "      <td>-0.042038</td>\n",
       "      <td>-0.072755</td>\n",
       "      <td>0.589811</td>\n",
       "      <td>0.275136</td>\n",
       "      <td>-0.045542</td>\n",
       "      <td>-0.053788</td>\n",
       "      <td>-0.052465</td>\n",
       "      <td>-0.058679</td>\n",
       "      <td>-0.085678</td>\n",
       "      <td>-0.075511</td>\n",
       "      <td>-0.031701</td>\n",
       "      <td>-0.239792</td>\n",
       "      <td>-0.232437</td>\n",
       "      <td>-0.055918</td>\n",
       "      <td>-0.12476</td>\n",
       "      <td>-0.121427</td>\n",
       "      <td>-0.083953</td>\n",
       "      <td>-0.082158</td>\n",
       "      <td>-0.312521</td>\n",
       "      <td>-0.303912</td>\n",
       "      <td>-0.118531</td>\n",
       "      <td>-0.146723</td>\n",
       "      <td>-0.150773</td>\n",
       "      <td>-0.308673</td>\n",
       "      <td>-0.300664</td>\n",
       "      <td>-0.300284</td>\n",
       "      <td>-0.292522</td>\n",
       "      <td>-0.115576</td>\n",
       "      <td>-0.118405</td>\n",
       "      <td>-0.030455</td>\n",
       "      <td>-0.035149</td>\n",
       "      <td>-0.03225</td>\n",
       "      <td>-0.053456</td>\n",
       "      <td>-0.097952</td>\n",
       "      <td>-0.10278</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.052381</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>-0.324797</td>\n",
       "      <td>-0.288607</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>-0.306484</td>\n",
       "      <td>-0.041292</td>\n",
       "      <td>-0.046295</td>\n",
       "      <td>-0.046597</td>\n",
       "      <td>-0.07271</td>\n",
       "      <td>-0.097544</td>\n",
       "      <td>-0.071066</td>\n",
       "      <td>-0.079106</td>\n",
       "      <td>-0.119359</td>\n",
       "      <td>-0.35363</td>\n",
       "      <td>-0.089382</td>\n",
       "      <td>-0.447665</td>\n",
       "      <td>-0.422654</td>\n",
       "      <td>-0.325115</td>\n",
       "      <td>-0.450097</td>\n",
       "      <td>-0.211605</td>\n",
       "      <td>-0.281908</td>\n",
       "      <td>-0.36208</td>\n",
       "      <td>-0.483298</td>\n",
       "      <td>-0.308233</td>\n",
       "      <td>-0.34294</td>\n",
       "      <td>-0.323017</td>\n",
       "      <td>-0.045791</td>\n",
       "      <td>-0.057194</td>\n",
       "      <td>-0.054842</td>\n",
       "      <td>-0.031881</td>\n",
       "      <td>-0.015007</td>\n",
       "      <td>-0.037858</td>\n",
       "      <td>-0.072124</td>\n",
       "      <td>-0.067005</td>\n",
       "      <td>-0.079805</td>\n",
       "      <td>-0.040947</td>\n",
       "      <td>-0.0494</td>\n",
       "      <td>-0.047343</td>\n",
       "      <td>-0.032528</td>\n",
       "      <td>-0.061764</td>\n",
       "      <td>-0.050674</td>\n",
       "      <td>-0.052212</td>\n",
       "      <td>-0.058176</td>\n",
       "      <td>-0.053373</td>\n",
       "      <td>-0.08205</td>\n",
       "      <td>-0.230531</td>\n",
       "      <td>-0.22759</td>\n",
       "      <td>-0.053747</td>\n",
       "      <td>-0.069811</td>\n",
       "      <td>-0.04128</td>\n",
       "      <td>-0.041151</td>\n",
       "      <td>-0.343569</td>\n",
       "      <td>-0.171602</td>\n",
       "      <td>-0.278643</td>\n",
       "      <td>-0.040645</td>\n",
       "      <td>-0.045145</td>\n",
       "      <td>-0.042053</td>\n",
       "      <td>-0.08919</td>\n",
       "      <td>-0.095307</td>\n",
       "      <td>-0.066844</td>\n",
       "      <td>-0.069129</td>\n",
       "      <td>-0.10873</td>\n",
       "      <td>-0.108326</td>\n",
       "      <td>-0.443577</td>\n",
       "      <td>-0.321263</td>\n",
       "      <td>-0.43605</td>\n",
       "      <td>-0.238435</td>\n",
       "      <td>-0.377649</td>\n",
       "      <td>-0.39305</td>\n",
       "      <td>-0.465556</td>\n",
       "      <td>-0.492519</td>\n",
       "      <td>-0.148389</td>\n",
       "      <td>-0.309876</td>\n",
       "      <td>-0.345461</td>\n",
       "      <td>-0.340874</td>\n",
       "      <td>-0.343962</td>\n",
       "      <td>-0.271606</td>\n",
       "      <td>-0.225907</td>\n",
       "      <td>-0.319623</td>\n",
       "      <td>-0.438433</td>\n",
       "      <td>-0.041485</td>\n",
       "      <td>-0.041062</td>\n",
       "      <td>-0.044216</td>\n",
       "      <td>-0.019603</td>\n",
       "      <td>-0.02641</td>\n",
       "      <td>-0.027637</td>\n",
       "      <td>-0.012979</td>\n",
       "      <td>-0.057632</td>\n",
       "      <td>-0.062164</td>\n",
       "      <td>-0.059283</td>\n",
       "      <td>-0.036909</td>\n",
       "      <td>-0.03958</td>\n",
       "      <td>-0.038675</td>\n",
       "      <td>-0.023196</td>\n",
       "      <td>-0.032106</td>\n",
       "      <td>-0.028872</td>\n",
       "      <td>-0.053422</td>\n",
       "      <td>-0.034642</td>\n",
       "      <td>-0.170618</td>\n",
       "      <td>-0.882906</td>\n",
       "      <td>-0.630863</td>\n",
       "      <td>0.870768</td>\n",
       "      <td>0.596434</td>\n",
       "      <td>-0.131711</td>\n",
       "      <td>-0.040420</td>\n",
       "      <td>-0.062849</td>\n",
       "      <td>-0.045744</td>\n",
       "      <td>-0.058539</td>\n",
       "      <td>-0.055212</td>\n",
       "      <td>-0.100440</td>\n",
       "      <td>-0.093916</td>\n",
       "      <td>-0.099373</td>\n",
       "      <td>-0.454447</td>\n",
       "      <td>-0.059471</td>\n",
       "      <td>-0.029261</td>\n",
       "      <td>-0.050669</td>\n",
       "      <td>-0.089662</td>\n",
       "      <td>0.455425</td>\n",
       "      <td>-0.038594</td>\n",
       "      <td>0.212555</td>\n",
       "      <td>-0.221827</td>\n",
       "      <td>-0.249078</td>\n",
       "      <td>-0.228881</td>\n",
       "      <td>-0.048346</td>\n",
       "      <td>-0.062216</td>\n",
       "      <td>-0.057999</td>\n",
       "      <td>-0.054761</td>\n",
       "      <td>-0.088248</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.041168</td>\n",
       "      <td>-0.045422</td>\n",
       "      <td>-0.046141</td>\n",
       "      <td>-0.078694</td>\n",
       "      <td>-0.05516</td>\n",
       "      <td>-0.060439</td>\n",
       "      <td>-0.043013</td>\n",
       "      <td>-0.045611</td>\n",
       "      <td>-0.047175</td>\n",
       "      <td>-0.014289</td>\n",
       "      <td>-0.054151</td>\n",
       "      <td>-0.036347</td>\n",
       "      <td>-0.029533</td>\n",
       "      <td>-0.050234</td>\n",
       "      <td>-0.044481</td>\n",
       "      <td>0.298722</td>\n",
       "      <td>-0.387232</td>\n",
       "      <td>-0.034193</td>\n",
       "      <td>-0.142894</td>\n",
       "      <td>0.184399</td>\n",
       "      <td>-0.07117</td>\n",
       "      <td>0.077504</td>\n",
       "      <td>-0.032413</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>-0.560911</td>\n",
       "      <td>-0.506029</td>\n",
       "      <td>0.380593</td>\n",
       "      <td>-0.547637</td>\n",
       "      <td>-0.506005</td>\n",
       "      <td>-0.511042</td>\n",
       "      <td>-0.08243</td>\n",
       "      <td>-0.086243</td>\n",
       "      <td>-0.089706</td>\n",
       "      <td>-0.091688</td>\n",
       "      <td>-0.357827</td>\n",
       "      <td>-0.356561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551.0</td>\n",
       "      <td>-1.209963</td>\n",
       "      <td>-0.544587</td>\n",
       "      <td>0.407824</td>\n",
       "      <td>-0.434818</td>\n",
       "      <td>-0.041814</td>\n",
       "      <td>-1.083156</td>\n",
       "      <td>-0.551276</td>\n",
       "      <td>-0.546267</td>\n",
       "      <td>0.643397</td>\n",
       "      <td>-0.537535</td>\n",
       "      <td>-0.566493</td>\n",
       "      <td>-0.542801</td>\n",
       "      <td>-0.533175</td>\n",
       "      <td>-0.108377</td>\n",
       "      <td>-0.385432</td>\n",
       "      <td>-0.663889</td>\n",
       "      <td>-0.634533</td>\n",
       "      <td>2.897594</td>\n",
       "      <td>-0.069307</td>\n",
       "      <td>-0.544537</td>\n",
       "      <td>-1.007672</td>\n",
       "      <td>-0.083475</td>\n",
       "      <td>-0.339302</td>\n",
       "      <td>-0.004593</td>\n",
       "      <td>-0.99097</td>\n",
       "      <td>-0.413764</td>\n",
       "      <td>-0.083589</td>\n",
       "      <td>-1.227512</td>\n",
       "      <td>-0.193018</td>\n",
       "      <td>-1.019015</td>\n",
       "      <td>-0.526503</td>\n",
       "      <td>-0.527372</td>\n",
       "      <td>-0.553863</td>\n",
       "      <td>-1.859128</td>\n",
       "      <td>0.706862</td>\n",
       "      <td>1.764824</td>\n",
       "      <td>-0.272797</td>\n",
       "      <td>-0.389465</td>\n",
       "      <td>-0.093859</td>\n",
       "      <td>-0.49368</td>\n",
       "      <td>-0.294501</td>\n",
       "      <td>-0.529056</td>\n",
       "      <td>-0.542678</td>\n",
       "      <td>-0.300054</td>\n",
       "      <td>-0.965816</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>-0.553826</td>\n",
       "      <td>-0.205104</td>\n",
       "      <td>-0.540532</td>\n",
       "      <td>-0.524318</td>\n",
       "      <td>-0.298381</td>\n",
       "      <td>-0.326247</td>\n",
       "      <td>-0.559101</td>\n",
       "      <td>-0.533809</td>\n",
       "      <td>-0.039890</td>\n",
       "      <td>-0.010886</td>\n",
       "      <td>-0.397750</td>\n",
       "      <td>-0.055439</td>\n",
       "      <td>-0.228292</td>\n",
       "      <td>0.748619</td>\n",
       "      <td>-0.531932</td>\n",
       "      <td>-0.656132</td>\n",
       "      <td>-0.076617</td>\n",
       "      <td>-0.029009</td>\n",
       "      <td>-0.154066</td>\n",
       "      <td>-0.234589</td>\n",
       "      <td>-0.501808</td>\n",
       "      <td>-0.031981</td>\n",
       "      <td>-0.346458</td>\n",
       "      <td>-0.985232</td>\n",
       "      <td>-0.569585</td>\n",
       "      <td>-0.526942</td>\n",
       "      <td>-0.174917</td>\n",
       "      <td>-0.535487</td>\n",
       "      <td>-0.522041</td>\n",
       "      <td>-0.553407</td>\n",
       "      <td>-0.54016</td>\n",
       "      <td>-0.996581</td>\n",
       "      <td>3.349216</td>\n",
       "      <td>-0.066125</td>\n",
       "      <td>-0.065564</td>\n",
       "      <td>-0.422264</td>\n",
       "      <td>0.684057</td>\n",
       "      <td>-1.019282</td>\n",
       "      <td>-0.162702</td>\n",
       "      <td>-0.327293</td>\n",
       "      <td>-0.408597</td>\n",
       "      <td>-0.156338</td>\n",
       "      <td>-0.407192</td>\n",
       "      <td>-0.633584</td>\n",
       "      <td>-0.542823</td>\n",
       "      <td>-0.090673</td>\n",
       "      <td>-0.55872</td>\n",
       "      <td>-0.376049</td>\n",
       "      <td>-0.531279</td>\n",
       "      <td>-0.560236</td>\n",
       "      <td>0.744573</td>\n",
       "      <td>1.181086</td>\n",
       "      <td>-0.377186</td>\n",
       "      <td>-0.04969</td>\n",
       "      <td>-0.35455</td>\n",
       "      <td>-1.188271</td>\n",
       "      <td>-0.22275</td>\n",
       "      <td>-0.535084</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>-0.528523</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>-0.528749</td>\n",
       "      <td>-0.100484</td>\n",
       "      <td>-0.114522</td>\n",
       "      <td>-0.182099</td>\n",
       "      <td>-0.463749</td>\n",
       "      <td>-0.566417</td>\n",
       "      <td>-0.551901</td>\n",
       "      <td>-0.660177</td>\n",
       "      <td>-0.116566</td>\n",
       "      <td>-1.002589</td>\n",
       "      <td>-0.556132</td>\n",
       "      <td>-0.130335</td>\n",
       "      <td>-0.922256</td>\n",
       "      <td>-0.527387</td>\n",
       "      <td>-0.964954</td>\n",
       "      <td>2.254392</td>\n",
       "      <td>-0.532699</td>\n",
       "      <td>0.07973</td>\n",
       "      <td>0.728937</td>\n",
       "      <td>0.686806</td>\n",
       "      <td>-0.05709</td>\n",
       "      <td>-0.52808</td>\n",
       "      <td>-0.553281</td>\n",
       "      <td>-0.556269</td>\n",
       "      <td>-0.494734</td>\n",
       "      <td>-0.183244</td>\n",
       "      <td>-0.411473</td>\n",
       "      <td>-0.356303</td>\n",
       "      <td>-0.231481</td>\n",
       "      <td>-0.55055</td>\n",
       "      <td>0.080027</td>\n",
       "      <td>0.646860</td>\n",
       "      <td>-0.083471</td>\n",
       "      <td>-0.632061</td>\n",
       "      <td>-0.973044</td>\n",
       "      <td>-0.045786</td>\n",
       "      <td>0.704683</td>\n",
       "      <td>-0.028718</td>\n",
       "      <td>-0.526444</td>\n",
       "      <td>-0.348024</td>\n",
       "      <td>-0.550072</td>\n",
       "      <td>-0.381317</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>-0.94828</td>\n",
       "      <td>-0.977981</td>\n",
       "      <td>-0.34976</td>\n",
       "      <td>-0.14449</td>\n",
       "      <td>-0.241668</td>\n",
       "      <td>-0.542326</td>\n",
       "      <td>-0.556514</td>\n",
       "      <td>-0.042189</td>\n",
       "      <td>-0.533263</td>\n",
       "      <td>-0.284724</td>\n",
       "      <td>0.703487</td>\n",
       "      <td>-0.50769</td>\n",
       "      <td>-0.033802</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>-0.58175</td>\n",
       "      <td>-0.438362</td>\n",
       "      <td>-0.893489</td>\n",
       "      <td>-0.633937</td>\n",
       "      <td>-0.539156</td>\n",
       "      <td>2.389235</td>\n",
       "      <td>0.148851</td>\n",
       "      <td>-1.106951</td>\n",
       "      <td>1.333335</td>\n",
       "      <td>-0.203484</td>\n",
       "      <td>0.633778</td>\n",
       "      <td>1.611354</td>\n",
       "      <td>0.360192</td>\n",
       "      <td>10.638383</td>\n",
       "      <td>-0.101669</td>\n",
       "      <td>-0.090881</td>\n",
       "      <td>-0.086169</td>\n",
       "      <td>-0.039137</td>\n",
       "      <td>-0.059583</td>\n",
       "      <td>-0.215803</td>\n",
       "      <td>-0.056873</td>\n",
       "      <td>-0.046189</td>\n",
       "      <td>-0.054075</td>\n",
       "      <td>-0.028110</td>\n",
       "      <td>-0.054926</td>\n",
       "      <td>-0.087638</td>\n",
       "      <td>-0.047102</td>\n",
       "      <td>-0.080946</td>\n",
       "      <td>-0.127270</td>\n",
       "      <td>0.272533</td>\n",
       "      <td>0.313048</td>\n",
       "      <td>-0.117310</td>\n",
       "      <td>-0.016421</td>\n",
       "      <td>-0.155484</td>\n",
       "      <td>-0.155767</td>\n",
       "      <td>-0.099152</td>\n",
       "      <td>-0.193691</td>\n",
       "      <td>-0.326769</td>\n",
       "      <td>0.158614</td>\n",
       "      <td>0.381642</td>\n",
       "      <td>-0.133469</td>\n",
       "      <td>-0.08284</td>\n",
       "      <td>-0.127827</td>\n",
       "      <td>-0.214701</td>\n",
       "      <td>0.271492</td>\n",
       "      <td>0.189757</td>\n",
       "      <td>0.308174</td>\n",
       "      <td>0.248921</td>\n",
       "      <td>0.034181</td>\n",
       "      <td>0.123804</td>\n",
       "      <td>1.244264</td>\n",
       "      <td>-0.321885</td>\n",
       "      <td>-0.30961</td>\n",
       "      <td>0.177113</td>\n",
       "      <td>0.108959</td>\n",
       "      <td>-0.049281</td>\n",
       "      <td>0.049998</td>\n",
       "      <td>-0.061936</td>\n",
       "      <td>0.778417</td>\n",
       "      <td>-0.289522</td>\n",
       "      <td>-0.043091</td>\n",
       "      <td>-0.050719</td>\n",
       "      <td>-0.049673</td>\n",
       "      <td>0.511381</td>\n",
       "      <td>-0.090258</td>\n",
       "      <td>-0.055307</td>\n",
       "      <td>0.149530</td>\n",
       "      <td>-0.067677</td>\n",
       "      <td>-0.072755</td>\n",
       "      <td>1.923681</td>\n",
       "      <td>-0.187140</td>\n",
       "      <td>-0.045542</td>\n",
       "      <td>-0.053788</td>\n",
       "      <td>-0.052465</td>\n",
       "      <td>-0.058679</td>\n",
       "      <td>0.496019</td>\n",
       "      <td>-0.075511</td>\n",
       "      <td>-0.031701</td>\n",
       "      <td>-0.239792</td>\n",
       "      <td>-0.232437</td>\n",
       "      <td>-0.055918</td>\n",
       "      <td>-0.12476</td>\n",
       "      <td>-0.121427</td>\n",
       "      <td>-0.083953</td>\n",
       "      <td>-0.082158</td>\n",
       "      <td>-0.312521</td>\n",
       "      <td>-0.303912</td>\n",
       "      <td>-0.118531</td>\n",
       "      <td>-0.146723</td>\n",
       "      <td>-0.150773</td>\n",
       "      <td>-0.308673</td>\n",
       "      <td>-0.300664</td>\n",
       "      <td>-0.300284</td>\n",
       "      <td>-0.292522</td>\n",
       "      <td>-0.115576</td>\n",
       "      <td>-0.118405</td>\n",
       "      <td>-0.030455</td>\n",
       "      <td>-0.035149</td>\n",
       "      <td>-0.03225</td>\n",
       "      <td>-0.053456</td>\n",
       "      <td>-0.097952</td>\n",
       "      <td>-0.10278</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.052381</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>-0.324797</td>\n",
       "      <td>-0.288607</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>-0.306484</td>\n",
       "      <td>-0.041292</td>\n",
       "      <td>-0.046295</td>\n",
       "      <td>-0.046597</td>\n",
       "      <td>-0.07271</td>\n",
       "      <td>-0.097544</td>\n",
       "      <td>-0.071066</td>\n",
       "      <td>-0.079106</td>\n",
       "      <td>-0.119359</td>\n",
       "      <td>-0.35363</td>\n",
       "      <td>-0.089382</td>\n",
       "      <td>-0.447665</td>\n",
       "      <td>-0.422654</td>\n",
       "      <td>-0.325115</td>\n",
       "      <td>-0.450097</td>\n",
       "      <td>-0.211605</td>\n",
       "      <td>-0.281908</td>\n",
       "      <td>-0.36208</td>\n",
       "      <td>-0.483298</td>\n",
       "      <td>-0.308233</td>\n",
       "      <td>-0.34294</td>\n",
       "      <td>-0.323017</td>\n",
       "      <td>-0.045791</td>\n",
       "      <td>-0.057194</td>\n",
       "      <td>-0.054842</td>\n",
       "      <td>-0.031881</td>\n",
       "      <td>-0.015007</td>\n",
       "      <td>-0.037858</td>\n",
       "      <td>-0.072124</td>\n",
       "      <td>-0.067005</td>\n",
       "      <td>-0.079805</td>\n",
       "      <td>-0.040947</td>\n",
       "      <td>-0.0494</td>\n",
       "      <td>-0.047343</td>\n",
       "      <td>-0.032528</td>\n",
       "      <td>-0.061764</td>\n",
       "      <td>-0.050674</td>\n",
       "      <td>-0.052212</td>\n",
       "      <td>-0.058176</td>\n",
       "      <td>-0.053373</td>\n",
       "      <td>-0.08205</td>\n",
       "      <td>-0.230531</td>\n",
       "      <td>-0.22759</td>\n",
       "      <td>-0.053747</td>\n",
       "      <td>-0.069811</td>\n",
       "      <td>-0.04128</td>\n",
       "      <td>-0.041151</td>\n",
       "      <td>-0.343569</td>\n",
       "      <td>-0.171602</td>\n",
       "      <td>-0.278643</td>\n",
       "      <td>-0.040645</td>\n",
       "      <td>-0.045145</td>\n",
       "      <td>-0.042053</td>\n",
       "      <td>-0.08919</td>\n",
       "      <td>-0.095307</td>\n",
       "      <td>-0.066844</td>\n",
       "      <td>-0.069129</td>\n",
       "      <td>-0.10873</td>\n",
       "      <td>-0.108326</td>\n",
       "      <td>-0.443577</td>\n",
       "      <td>-0.321263</td>\n",
       "      <td>-0.43605</td>\n",
       "      <td>-0.238435</td>\n",
       "      <td>-0.377649</td>\n",
       "      <td>-0.39305</td>\n",
       "      <td>-0.465556</td>\n",
       "      <td>-0.492519</td>\n",
       "      <td>-0.148389</td>\n",
       "      <td>-0.309876</td>\n",
       "      <td>-0.345461</td>\n",
       "      <td>-0.340874</td>\n",
       "      <td>-0.343962</td>\n",
       "      <td>-0.271606</td>\n",
       "      <td>-0.225907</td>\n",
       "      <td>-0.319623</td>\n",
       "      <td>-0.438433</td>\n",
       "      <td>-0.041485</td>\n",
       "      <td>-0.041062</td>\n",
       "      <td>-0.044216</td>\n",
       "      <td>-0.019603</td>\n",
       "      <td>-0.02641</td>\n",
       "      <td>-0.027637</td>\n",
       "      <td>-0.012979</td>\n",
       "      <td>-0.057632</td>\n",
       "      <td>-0.062164</td>\n",
       "      <td>-0.059283</td>\n",
       "      <td>-0.036909</td>\n",
       "      <td>-0.03958</td>\n",
       "      <td>-0.038675</td>\n",
       "      <td>-0.023196</td>\n",
       "      <td>-0.032106</td>\n",
       "      <td>-0.028872</td>\n",
       "      <td>-0.053422</td>\n",
       "      <td>-0.070625</td>\n",
       "      <td>-0.170618</td>\n",
       "      <td>-0.882906</td>\n",
       "      <td>-0.630863</td>\n",
       "      <td>0.870768</td>\n",
       "      <td>-0.332543</td>\n",
       "      <td>-0.131711</td>\n",
       "      <td>0.019897</td>\n",
       "      <td>-0.062849</td>\n",
       "      <td>-0.045744</td>\n",
       "      <td>-0.058539</td>\n",
       "      <td>-0.055212</td>\n",
       "      <td>0.514546</td>\n",
       "      <td>0.537305</td>\n",
       "      <td>-0.099373</td>\n",
       "      <td>-0.454447</td>\n",
       "      <td>-0.059471</td>\n",
       "      <td>0.207641</td>\n",
       "      <td>-0.076203</td>\n",
       "      <td>-0.089662</td>\n",
       "      <td>2.643860</td>\n",
       "      <td>-0.038594</td>\n",
       "      <td>-0.221127</td>\n",
       "      <td>-0.221827</td>\n",
       "      <td>-0.249078</td>\n",
       "      <td>-0.228881</td>\n",
       "      <td>-0.048346</td>\n",
       "      <td>-0.062216</td>\n",
       "      <td>-0.057999</td>\n",
       "      <td>-0.054761</td>\n",
       "      <td>0.466291</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.041168</td>\n",
       "      <td>-0.045422</td>\n",
       "      <td>-0.046141</td>\n",
       "      <td>-0.078694</td>\n",
       "      <td>-0.05516</td>\n",
       "      <td>-0.060439</td>\n",
       "      <td>-0.043013</td>\n",
       "      <td>-0.045611</td>\n",
       "      <td>-0.047175</td>\n",
       "      <td>-0.014289</td>\n",
       "      <td>-0.054151</td>\n",
       "      <td>-0.036347</td>\n",
       "      <td>-0.029533</td>\n",
       "      <td>-0.050234</td>\n",
       "      <td>-0.044481</td>\n",
       "      <td>0.298722</td>\n",
       "      <td>-0.387232</td>\n",
       "      <td>-0.034193</td>\n",
       "      <td>-0.142894</td>\n",
       "      <td>0.184399</td>\n",
       "      <td>-0.07117</td>\n",
       "      <td>0.077504</td>\n",
       "      <td>-0.032413</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>-0.560911</td>\n",
       "      <td>-0.506029</td>\n",
       "      <td>0.380593</td>\n",
       "      <td>-0.547637</td>\n",
       "      <td>-0.506005</td>\n",
       "      <td>-0.511042</td>\n",
       "      <td>-0.08243</td>\n",
       "      <td>-0.086243</td>\n",
       "      <td>-0.089706</td>\n",
       "      <td>-0.091688</td>\n",
       "      <td>-0.357827</td>\n",
       "      <td>-0.356561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663552.0</td>\n",
       "      <td>0.348006</td>\n",
       "      <td>-0.544587</td>\n",
       "      <td>-0.803152</td>\n",
       "      <td>-0.434818</td>\n",
       "      <td>-0.041814</td>\n",
       "      <td>-1.083156</td>\n",
       "      <td>-0.551276</td>\n",
       "      <td>-0.546267</td>\n",
       "      <td>-1.449451</td>\n",
       "      <td>-0.537535</td>\n",
       "      <td>-0.566493</td>\n",
       "      <td>-0.542801</td>\n",
       "      <td>-0.533175</td>\n",
       "      <td>-0.108377</td>\n",
       "      <td>-0.385432</td>\n",
       "      <td>-0.663889</td>\n",
       "      <td>-0.634533</td>\n",
       "      <td>-0.136447</td>\n",
       "      <td>-0.069307</td>\n",
       "      <td>-0.544537</td>\n",
       "      <td>-1.007672</td>\n",
       "      <td>-0.083475</td>\n",
       "      <td>-0.339302</td>\n",
       "      <td>-0.004593</td>\n",
       "      <td>-0.99097</td>\n",
       "      <td>-0.413764</td>\n",
       "      <td>-0.083589</td>\n",
       "      <td>0.837200</td>\n",
       "      <td>-0.193018</td>\n",
       "      <td>-1.019015</td>\n",
       "      <td>-0.526503</td>\n",
       "      <td>-0.527372</td>\n",
       "      <td>-0.553863</td>\n",
       "      <td>0.519333</td>\n",
       "      <td>-0.972753</td>\n",
       "      <td>-1.059143</td>\n",
       "      <td>-0.272797</td>\n",
       "      <td>-0.389465</td>\n",
       "      <td>-0.093859</td>\n",
       "      <td>-0.49368</td>\n",
       "      <td>-0.294501</td>\n",
       "      <td>-0.529056</td>\n",
       "      <td>-0.542678</td>\n",
       "      <td>-0.300054</td>\n",
       "      <td>-0.965816</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>-0.553826</td>\n",
       "      <td>-0.205104</td>\n",
       "      <td>-0.540532</td>\n",
       "      <td>-0.524318</td>\n",
       "      <td>-0.298381</td>\n",
       "      <td>-0.326247</td>\n",
       "      <td>-0.559101</td>\n",
       "      <td>-0.533809</td>\n",
       "      <td>-0.039890</td>\n",
       "      <td>-1.102171</td>\n",
       "      <td>1.616519</td>\n",
       "      <td>-0.055439</td>\n",
       "      <td>-0.228292</td>\n",
       "      <td>-1.660800</td>\n",
       "      <td>-0.531932</td>\n",
       "      <td>-0.656132</td>\n",
       "      <td>-0.076617</td>\n",
       "      <td>-0.029009</td>\n",
       "      <td>-0.154066</td>\n",
       "      <td>-0.234589</td>\n",
       "      <td>-0.501808</td>\n",
       "      <td>-0.031981</td>\n",
       "      <td>-0.346458</td>\n",
       "      <td>-0.985232</td>\n",
       "      <td>-0.569585</td>\n",
       "      <td>-0.526942</td>\n",
       "      <td>-0.174917</td>\n",
       "      <td>-0.535487</td>\n",
       "      <td>-0.522041</td>\n",
       "      <td>-0.553407</td>\n",
       "      <td>-0.54016</td>\n",
       "      <td>-0.996581</td>\n",
       "      <td>-0.352363</td>\n",
       "      <td>-0.066125</td>\n",
       "      <td>-0.065564</td>\n",
       "      <td>-0.422264</td>\n",
       "      <td>-1.452824</td>\n",
       "      <td>-1.019282</td>\n",
       "      <td>-0.162702</td>\n",
       "      <td>4.877804</td>\n",
       "      <td>-0.408597</td>\n",
       "      <td>0.806283</td>\n",
       "      <td>-0.407192</td>\n",
       "      <td>-0.633584</td>\n",
       "      <td>-0.542823</td>\n",
       "      <td>-0.090673</td>\n",
       "      <td>-0.55872</td>\n",
       "      <td>-0.376049</td>\n",
       "      <td>-0.531279</td>\n",
       "      <td>-0.560236</td>\n",
       "      <td>-1.685703</td>\n",
       "      <td>0.706391</td>\n",
       "      <td>-0.377186</td>\n",
       "      <td>-0.04969</td>\n",
       "      <td>-0.35455</td>\n",
       "      <td>1.119419</td>\n",
       "      <td>-0.22275</td>\n",
       "      <td>-0.535084</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>-0.528523</td>\n",
       "      <td>6.434365</td>\n",
       "      <td>-0.528749</td>\n",
       "      <td>-0.100484</td>\n",
       "      <td>-0.114522</td>\n",
       "      <td>-0.182099</td>\n",
       "      <td>-0.463749</td>\n",
       "      <td>-0.566417</td>\n",
       "      <td>-0.551901</td>\n",
       "      <td>-0.660177</td>\n",
       "      <td>-0.116566</td>\n",
       "      <td>-1.002589</td>\n",
       "      <td>-0.556132</td>\n",
       "      <td>-0.130335</td>\n",
       "      <td>-0.922256</td>\n",
       "      <td>-0.527387</td>\n",
       "      <td>-0.964954</td>\n",
       "      <td>-0.390305</td>\n",
       "      <td>-0.532699</td>\n",
       "      <td>-1.72242</td>\n",
       "      <td>-0.957024</td>\n",
       "      <td>-1.465056</td>\n",
       "      <td>-0.05709</td>\n",
       "      <td>-0.52808</td>\n",
       "      <td>-0.553281</td>\n",
       "      <td>-0.556269</td>\n",
       "      <td>-0.494734</td>\n",
       "      <td>-0.183244</td>\n",
       "      <td>-0.411473</td>\n",
       "      <td>0.874067</td>\n",
       "      <td>-0.231481</td>\n",
       "      <td>-0.55055</td>\n",
       "      <td>-1.730432</td>\n",
       "      <td>-1.461539</td>\n",
       "      <td>-0.083471</td>\n",
       "      <td>-0.632061</td>\n",
       "      <td>-0.973044</td>\n",
       "      <td>-0.045786</td>\n",
       "      <td>-1.466143</td>\n",
       "      <td>-0.028718</td>\n",
       "      <td>-0.526444</td>\n",
       "      <td>-0.931627</td>\n",
       "      <td>-0.550072</td>\n",
       "      <td>-0.381317</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>-0.94828</td>\n",
       "      <td>-0.977981</td>\n",
       "      <td>-0.34976</td>\n",
       "      <td>-0.14449</td>\n",
       "      <td>-0.241668</td>\n",
       "      <td>-0.542326</td>\n",
       "      <td>-0.556514</td>\n",
       "      <td>-0.042189</td>\n",
       "      <td>-0.533263</td>\n",
       "      <td>-0.284724</td>\n",
       "      <td>-1.448103</td>\n",
       "      <td>-0.50769</td>\n",
       "      <td>-0.033802</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>-0.58175</td>\n",
       "      <td>-0.438362</td>\n",
       "      <td>0.816915</td>\n",
       "      <td>-0.633937</td>\n",
       "      <td>-0.539156</td>\n",
       "      <td>2.389235</td>\n",
       "      <td>0.620945</td>\n",
       "      <td>0.221506</td>\n",
       "      <td>0.018174</td>\n",
       "      <td>-0.203484</td>\n",
       "      <td>-0.717967</td>\n",
       "      <td>-0.402029</td>\n",
       "      <td>0.360192</td>\n",
       "      <td>-0.126642</td>\n",
       "      <td>-0.101669</td>\n",
       "      <td>-0.068223</td>\n",
       "      <td>-0.086169</td>\n",
       "      <td>-0.039137</td>\n",
       "      <td>-0.059583</td>\n",
       "      <td>-0.176940</td>\n",
       "      <td>-0.113225</td>\n",
       "      <td>-0.046189</td>\n",
       "      <td>-0.054075</td>\n",
       "      <td>-0.148321</td>\n",
       "      <td>-0.054926</td>\n",
       "      <td>-0.087638</td>\n",
       "      <td>-0.047102</td>\n",
       "      <td>-0.197484</td>\n",
       "      <td>-0.086648</td>\n",
       "      <td>-0.330759</td>\n",
       "      <td>-0.304877</td>\n",
       "      <td>0.522859</td>\n",
       "      <td>0.820162</td>\n",
       "      <td>0.322432</td>\n",
       "      <td>-0.155767</td>\n",
       "      <td>-0.099152</td>\n",
       "      <td>-0.193691</td>\n",
       "      <td>-0.326769</td>\n",
       "      <td>0.762375</td>\n",
       "      <td>1.071273</td>\n",
       "      <td>-0.133469</td>\n",
       "      <td>-0.08284</td>\n",
       "      <td>-0.127827</td>\n",
       "      <td>0.525924</td>\n",
       "      <td>1.568414</td>\n",
       "      <td>1.302749</td>\n",
       "      <td>1.669551</td>\n",
       "      <td>1.493239</td>\n",
       "      <td>0.034181</td>\n",
       "      <td>0.123804</td>\n",
       "      <td>0.034274</td>\n",
       "      <td>-0.321885</td>\n",
       "      <td>-0.30961</td>\n",
       "      <td>0.177113</td>\n",
       "      <td>0.108959</td>\n",
       "      <td>-0.049281</td>\n",
       "      <td>-0.074508</td>\n",
       "      <td>-0.061936</td>\n",
       "      <td>-0.329338</td>\n",
       "      <td>-0.289522</td>\n",
       "      <td>-0.043091</td>\n",
       "      <td>-0.050719</td>\n",
       "      <td>-0.049673</td>\n",
       "      <td>-0.083152</td>\n",
       "      <td>-0.090258</td>\n",
       "      <td>-0.055307</td>\n",
       "      <td>-0.079258</td>\n",
       "      <td>-0.067677</td>\n",
       "      <td>-0.072755</td>\n",
       "      <td>-0.288973</td>\n",
       "      <td>-0.187140</td>\n",
       "      <td>-0.045542</td>\n",
       "      <td>-0.053788</td>\n",
       "      <td>-0.052465</td>\n",
       "      <td>-0.058679</td>\n",
       "      <td>-0.085678</td>\n",
       "      <td>-0.075511</td>\n",
       "      <td>-0.031701</td>\n",
       "      <td>-0.239792</td>\n",
       "      <td>-0.232437</td>\n",
       "      <td>-0.055918</td>\n",
       "      <td>-0.12476</td>\n",
       "      <td>-0.121427</td>\n",
       "      <td>-0.083953</td>\n",
       "      <td>-0.082158</td>\n",
       "      <td>-0.312521</td>\n",
       "      <td>-0.303912</td>\n",
       "      <td>-0.118531</td>\n",
       "      <td>-0.146723</td>\n",
       "      <td>-0.150773</td>\n",
       "      <td>-0.308673</td>\n",
       "      <td>-0.300664</td>\n",
       "      <td>-0.300284</td>\n",
       "      <td>-0.292522</td>\n",
       "      <td>-0.115576</td>\n",
       "      <td>-0.118405</td>\n",
       "      <td>-0.030455</td>\n",
       "      <td>-0.035149</td>\n",
       "      <td>-0.03225</td>\n",
       "      <td>-0.053456</td>\n",
       "      <td>-0.097952</td>\n",
       "      <td>-0.10278</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.052381</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>-0.324797</td>\n",
       "      <td>-0.288607</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>-0.306484</td>\n",
       "      <td>-0.041292</td>\n",
       "      <td>-0.046295</td>\n",
       "      <td>-0.046597</td>\n",
       "      <td>-0.07271</td>\n",
       "      <td>-0.097544</td>\n",
       "      <td>-0.071066</td>\n",
       "      <td>-0.079106</td>\n",
       "      <td>-0.119359</td>\n",
       "      <td>-0.35363</td>\n",
       "      <td>-0.089382</td>\n",
       "      <td>-0.447665</td>\n",
       "      <td>-0.422654</td>\n",
       "      <td>-0.325115</td>\n",
       "      <td>-0.450097</td>\n",
       "      <td>-0.211605</td>\n",
       "      <td>-0.281908</td>\n",
       "      <td>-0.36208</td>\n",
       "      <td>-0.483298</td>\n",
       "      <td>-0.308233</td>\n",
       "      <td>-0.34294</td>\n",
       "      <td>-0.323017</td>\n",
       "      <td>-0.045791</td>\n",
       "      <td>-0.057194</td>\n",
       "      <td>-0.054842</td>\n",
       "      <td>-0.031881</td>\n",
       "      <td>-0.015007</td>\n",
       "      <td>-0.037858</td>\n",
       "      <td>-0.072124</td>\n",
       "      <td>-0.067005</td>\n",
       "      <td>-0.079805</td>\n",
       "      <td>-0.040947</td>\n",
       "      <td>-0.0494</td>\n",
       "      <td>-0.047343</td>\n",
       "      <td>-0.032528</td>\n",
       "      <td>-0.061764</td>\n",
       "      <td>-0.050674</td>\n",
       "      <td>-0.052212</td>\n",
       "      <td>-0.058176</td>\n",
       "      <td>-0.053373</td>\n",
       "      <td>-0.08205</td>\n",
       "      <td>-0.230531</td>\n",
       "      <td>-0.22759</td>\n",
       "      <td>-0.053747</td>\n",
       "      <td>-0.069811</td>\n",
       "      <td>-0.04128</td>\n",
       "      <td>-0.041151</td>\n",
       "      <td>-0.343569</td>\n",
       "      <td>-0.171602</td>\n",
       "      <td>-0.278643</td>\n",
       "      <td>-0.040645</td>\n",
       "      <td>-0.045145</td>\n",
       "      <td>-0.042053</td>\n",
       "      <td>-0.08919</td>\n",
       "      <td>-0.095307</td>\n",
       "      <td>-0.066844</td>\n",
       "      <td>-0.069129</td>\n",
       "      <td>-0.10873</td>\n",
       "      <td>-0.108326</td>\n",
       "      <td>-0.443577</td>\n",
       "      <td>-0.321263</td>\n",
       "      <td>-0.43605</td>\n",
       "      <td>-0.238435</td>\n",
       "      <td>-0.377649</td>\n",
       "      <td>-0.39305</td>\n",
       "      <td>-0.465556</td>\n",
       "      <td>-0.492519</td>\n",
       "      <td>-0.148389</td>\n",
       "      <td>-0.309876</td>\n",
       "      <td>-0.345461</td>\n",
       "      <td>-0.340874</td>\n",
       "      <td>-0.343962</td>\n",
       "      <td>-0.271606</td>\n",
       "      <td>-0.225907</td>\n",
       "      <td>-0.319623</td>\n",
       "      <td>-0.438433</td>\n",
       "      <td>-0.041485</td>\n",
       "      <td>-0.041062</td>\n",
       "      <td>-0.044216</td>\n",
       "      <td>-0.019603</td>\n",
       "      <td>-0.02641</td>\n",
       "      <td>-0.027637</td>\n",
       "      <td>-0.012979</td>\n",
       "      <td>-0.057632</td>\n",
       "      <td>-0.062164</td>\n",
       "      <td>-0.059283</td>\n",
       "      <td>-0.036909</td>\n",
       "      <td>-0.03958</td>\n",
       "      <td>-0.038675</td>\n",
       "      <td>-0.023196</td>\n",
       "      <td>-0.032106</td>\n",
       "      <td>-0.028872</td>\n",
       "      <td>-0.053422</td>\n",
       "      <td>-0.070625</td>\n",
       "      <td>-0.170618</td>\n",
       "      <td>0.199917</td>\n",
       "      <td>0.007098</td>\n",
       "      <td>-0.357205</td>\n",
       "      <td>-0.332543</td>\n",
       "      <td>-0.131711</td>\n",
       "      <td>-0.040420</td>\n",
       "      <td>-0.062849</td>\n",
       "      <td>-0.045744</td>\n",
       "      <td>-0.058539</td>\n",
       "      <td>-0.055212</td>\n",
       "      <td>-0.100440</td>\n",
       "      <td>-0.093916</td>\n",
       "      <td>-0.099373</td>\n",
       "      <td>-0.454447</td>\n",
       "      <td>-0.059471</td>\n",
       "      <td>-0.092981</td>\n",
       "      <td>-0.076203</td>\n",
       "      <td>-0.089662</td>\n",
       "      <td>-0.332187</td>\n",
       "      <td>-0.038594</td>\n",
       "      <td>-0.221127</td>\n",
       "      <td>2.714464</td>\n",
       "      <td>1.384578</td>\n",
       "      <td>2.190101</td>\n",
       "      <td>-0.048346</td>\n",
       "      <td>-0.062216</td>\n",
       "      <td>-0.057999</td>\n",
       "      <td>-0.054761</td>\n",
       "      <td>-0.088248</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.041168</td>\n",
       "      <td>-0.045422</td>\n",
       "      <td>-0.046141</td>\n",
       "      <td>-0.078694</td>\n",
       "      <td>-0.05516</td>\n",
       "      <td>-0.060439</td>\n",
       "      <td>-0.043013</td>\n",
       "      <td>-0.045611</td>\n",
       "      <td>-0.047175</td>\n",
       "      <td>-0.014289</td>\n",
       "      <td>-0.054151</td>\n",
       "      <td>-0.036347</td>\n",
       "      <td>-0.029533</td>\n",
       "      <td>-0.050234</td>\n",
       "      <td>-0.044481</td>\n",
       "      <td>0.298722</td>\n",
       "      <td>-0.387232</td>\n",
       "      <td>-0.034193</td>\n",
       "      <td>-0.142894</td>\n",
       "      <td>0.184399</td>\n",
       "      <td>-0.07117</td>\n",
       "      <td>0.077504</td>\n",
       "      <td>-0.032413</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>-0.560911</td>\n",
       "      <td>-0.506029</td>\n",
       "      <td>0.380593</td>\n",
       "      <td>-0.547637</td>\n",
       "      <td>-0.506005</td>\n",
       "      <td>-0.511042</td>\n",
       "      <td>-0.08243</td>\n",
       "      <td>-0.086243</td>\n",
       "      <td>-0.089706</td>\n",
       "      <td>-0.091688</td>\n",
       "      <td>-0.357827</td>\n",
       "      <td>-0.356561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3663553.0</td>\n",
       "      <td>-1.209963</td>\n",
       "      <td>-0.544587</td>\n",
       "      <td>-0.803152</td>\n",
       "      <td>-0.434818</td>\n",
       "      <td>-0.041814</td>\n",
       "      <td>-1.083156</td>\n",
       "      <td>-0.551276</td>\n",
       "      <td>-0.546267</td>\n",
       "      <td>-1.449451</td>\n",
       "      <td>-0.537535</td>\n",
       "      <td>-0.566493</td>\n",
       "      <td>-0.542801</td>\n",
       "      <td>-0.533175</td>\n",
       "      <td>-0.108377</td>\n",
       "      <td>-0.385432</td>\n",
       "      <td>-0.663889</td>\n",
       "      <td>-0.634533</td>\n",
       "      <td>-0.136447</td>\n",
       "      <td>-0.069307</td>\n",
       "      <td>-0.544537</td>\n",
       "      <td>-1.007672</td>\n",
       "      <td>-0.083475</td>\n",
       "      <td>-0.339302</td>\n",
       "      <td>-0.004593</td>\n",
       "      <td>-0.99097</td>\n",
       "      <td>-0.413764</td>\n",
       "      <td>-0.083589</td>\n",
       "      <td>-1.227512</td>\n",
       "      <td>-0.193018</td>\n",
       "      <td>-1.019015</td>\n",
       "      <td>-0.526503</td>\n",
       "      <td>-0.527372</td>\n",
       "      <td>-0.553863</td>\n",
       "      <td>0.519333</td>\n",
       "      <td>-0.972753</td>\n",
       "      <td>-1.059143</td>\n",
       "      <td>-0.272797</td>\n",
       "      <td>-0.389465</td>\n",
       "      <td>-0.093859</td>\n",
       "      <td>-0.49368</td>\n",
       "      <td>-0.294501</td>\n",
       "      <td>-0.529056</td>\n",
       "      <td>-0.542678</td>\n",
       "      <td>-0.300054</td>\n",
       "      <td>-0.965816</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>-0.553826</td>\n",
       "      <td>-0.205104</td>\n",
       "      <td>-0.540532</td>\n",
       "      <td>-0.524318</td>\n",
       "      <td>-0.298381</td>\n",
       "      <td>-0.326247</td>\n",
       "      <td>-0.559101</td>\n",
       "      <td>-0.533809</td>\n",
       "      <td>-0.039890</td>\n",
       "      <td>-1.102171</td>\n",
       "      <td>1.616519</td>\n",
       "      <td>-0.055439</td>\n",
       "      <td>-0.228292</td>\n",
       "      <td>-1.660800</td>\n",
       "      <td>-0.531932</td>\n",
       "      <td>-0.656132</td>\n",
       "      <td>-0.076617</td>\n",
       "      <td>-0.169905</td>\n",
       "      <td>4.574395</td>\n",
       "      <td>3.893920</td>\n",
       "      <td>-0.501808</td>\n",
       "      <td>-0.031981</td>\n",
       "      <td>-0.346458</td>\n",
       "      <td>-0.985232</td>\n",
       "      <td>-0.569585</td>\n",
       "      <td>-0.526942</td>\n",
       "      <td>-0.174917</td>\n",
       "      <td>-0.535487</td>\n",
       "      <td>-0.522041</td>\n",
       "      <td>-0.553407</td>\n",
       "      <td>-0.54016</td>\n",
       "      <td>-0.996581</td>\n",
       "      <td>-0.352363</td>\n",
       "      <td>-0.066125</td>\n",
       "      <td>-0.065564</td>\n",
       "      <td>-0.422264</td>\n",
       "      <td>-1.452824</td>\n",
       "      <td>-1.019282</td>\n",
       "      <td>-0.162702</td>\n",
       "      <td>-0.327293</td>\n",
       "      <td>-0.408597</td>\n",
       "      <td>-1.331973</td>\n",
       "      <td>-0.407192</td>\n",
       "      <td>-0.633584</td>\n",
       "      <td>-0.542823</td>\n",
       "      <td>-0.090673</td>\n",
       "      <td>-0.55872</td>\n",
       "      <td>-0.376049</td>\n",
       "      <td>-0.531279</td>\n",
       "      <td>-0.560236</td>\n",
       "      <td>-1.685703</td>\n",
       "      <td>0.706391</td>\n",
       "      <td>-0.377186</td>\n",
       "      <td>-0.04969</td>\n",
       "      <td>-0.35455</td>\n",
       "      <td>-1.188271</td>\n",
       "      <td>-0.22275</td>\n",
       "      <td>-0.535084</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>-0.528523</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>-0.528749</td>\n",
       "      <td>-0.100484</td>\n",
       "      <td>-0.114522</td>\n",
       "      <td>-0.182099</td>\n",
       "      <td>-0.463749</td>\n",
       "      <td>-0.566417</td>\n",
       "      <td>-0.551901</td>\n",
       "      <td>-0.660177</td>\n",
       "      <td>-0.116566</td>\n",
       "      <td>-1.002589</td>\n",
       "      <td>-0.556132</td>\n",
       "      <td>-0.130335</td>\n",
       "      <td>-0.922256</td>\n",
       "      <td>-0.527387</td>\n",
       "      <td>-0.964954</td>\n",
       "      <td>-0.390305</td>\n",
       "      <td>-0.532699</td>\n",
       "      <td>-1.72242</td>\n",
       "      <td>-0.957024</td>\n",
       "      <td>-1.465056</td>\n",
       "      <td>-0.05709</td>\n",
       "      <td>-0.52808</td>\n",
       "      <td>-0.553281</td>\n",
       "      <td>-0.556269</td>\n",
       "      <td>-0.494734</td>\n",
       "      <td>-0.183244</td>\n",
       "      <td>-0.411473</td>\n",
       "      <td>0.874067</td>\n",
       "      <td>-0.231481</td>\n",
       "      <td>-0.55055</td>\n",
       "      <td>-1.730432</td>\n",
       "      <td>-1.461539</td>\n",
       "      <td>-0.083471</td>\n",
       "      <td>-0.632061</td>\n",
       "      <td>-0.973044</td>\n",
       "      <td>-0.045786</td>\n",
       "      <td>-1.466143</td>\n",
       "      <td>-0.028718</td>\n",
       "      <td>-0.526444</td>\n",
       "      <td>-0.348024</td>\n",
       "      <td>-0.550072</td>\n",
       "      <td>-0.381317</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>-0.94828</td>\n",
       "      <td>-0.977981</td>\n",
       "      <td>-0.34976</td>\n",
       "      <td>-0.14449</td>\n",
       "      <td>-0.241668</td>\n",
       "      <td>-0.542326</td>\n",
       "      <td>-0.556514</td>\n",
       "      <td>-0.042189</td>\n",
       "      <td>-0.533263</td>\n",
       "      <td>3.297984</td>\n",
       "      <td>-1.448103</td>\n",
       "      <td>-0.50769</td>\n",
       "      <td>-0.033802</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>-0.58175</td>\n",
       "      <td>-0.438362</td>\n",
       "      <td>-1.627023</td>\n",
       "      <td>-0.633937</td>\n",
       "      <td>-0.539156</td>\n",
       "      <td>2.389237</td>\n",
       "      <td>-0.278085</td>\n",
       "      <td>1.655211</td>\n",
       "      <td>0.583570</td>\n",
       "      <td>-0.203484</td>\n",
       "      <td>-1.821892</td>\n",
       "      <td>0.042876</td>\n",
       "      <td>0.360192</td>\n",
       "      <td>-0.171873</td>\n",
       "      <td>-0.101669</td>\n",
       "      <td>-0.060670</td>\n",
       "      <td>-0.060075</td>\n",
       "      <td>-0.039137</td>\n",
       "      <td>-0.059583</td>\n",
       "      <td>-0.138077</td>\n",
       "      <td>-0.056873</td>\n",
       "      <td>-0.046189</td>\n",
       "      <td>-0.054075</td>\n",
       "      <td>0.031995</td>\n",
       "      <td>-0.054926</td>\n",
       "      <td>-0.044879</td>\n",
       "      <td>-0.047102</td>\n",
       "      <td>-0.143100</td>\n",
       "      <td>-0.046025</td>\n",
       "      <td>-0.457768</td>\n",
       "      <td>-0.434967</td>\n",
       "      <td>-0.323817</td>\n",
       "      <td>-0.449137</td>\n",
       "      <td>-0.309651</td>\n",
       "      <td>-0.155767</td>\n",
       "      <td>-0.099152</td>\n",
       "      <td>-0.193691</td>\n",
       "      <td>-0.326769</td>\n",
       "      <td>-0.490714</td>\n",
       "      <td>-0.360038</td>\n",
       "      <td>-0.133469</td>\n",
       "      <td>-0.08284</td>\n",
       "      <td>-0.127827</td>\n",
       "      <td>-0.597782</td>\n",
       "      <td>0.271492</td>\n",
       "      <td>0.189757</td>\n",
       "      <td>0.308174</td>\n",
       "      <td>0.248921</td>\n",
       "      <td>0.034181</td>\n",
       "      <td>0.123804</td>\n",
       "      <td>0.034274</td>\n",
       "      <td>-0.321885</td>\n",
       "      <td>-0.30961</td>\n",
       "      <td>0.177113</td>\n",
       "      <td>0.108959</td>\n",
       "      <td>-0.001529</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>-0.025731</td>\n",
       "      <td>0.778417</td>\n",
       "      <td>0.772454</td>\n",
       "      <td>-0.043091</td>\n",
       "      <td>-0.050719</td>\n",
       "      <td>-0.049673</td>\n",
       "      <td>-0.083152</td>\n",
       "      <td>-0.090258</td>\n",
       "      <td>-0.026255</td>\n",
       "      <td>-0.035805</td>\n",
       "      <td>-0.045051</td>\n",
       "      <td>0.488008</td>\n",
       "      <td>0.288043</td>\n",
       "      <td>0.220803</td>\n",
       "      <td>-0.045542</td>\n",
       "      <td>-0.053788</td>\n",
       "      <td>-0.052465</td>\n",
       "      <td>-0.058679</td>\n",
       "      <td>-0.085678</td>\n",
       "      <td>-0.075511</td>\n",
       "      <td>-0.031701</td>\n",
       "      <td>-0.239792</td>\n",
       "      <td>-0.232437</td>\n",
       "      <td>-0.055918</td>\n",
       "      <td>-0.12476</td>\n",
       "      <td>-0.121427</td>\n",
       "      <td>-0.083953</td>\n",
       "      <td>-0.082158</td>\n",
       "      <td>-0.312521</td>\n",
       "      <td>-0.303912</td>\n",
       "      <td>-0.118531</td>\n",
       "      <td>-0.146723</td>\n",
       "      <td>-0.150773</td>\n",
       "      <td>-0.308673</td>\n",
       "      <td>-0.300664</td>\n",
       "      <td>-0.300284</td>\n",
       "      <td>-0.292522</td>\n",
       "      <td>-0.115576</td>\n",
       "      <td>-0.118405</td>\n",
       "      <td>-0.030455</td>\n",
       "      <td>-0.035149</td>\n",
       "      <td>-0.03225</td>\n",
       "      <td>-0.053456</td>\n",
       "      <td>-0.097952</td>\n",
       "      <td>-0.10278</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.052381</td>\n",
       "      <td>-0.089246</td>\n",
       "      <td>-0.324797</td>\n",
       "      <td>-0.288607</td>\n",
       "      <td>-0.06896</td>\n",
       "      <td>-0.306484</td>\n",
       "      <td>-0.041292</td>\n",
       "      <td>-0.046295</td>\n",
       "      <td>-0.046597</td>\n",
       "      <td>-0.07271</td>\n",
       "      <td>-0.097544</td>\n",
       "      <td>-0.071066</td>\n",
       "      <td>-0.079106</td>\n",
       "      <td>-0.119359</td>\n",
       "      <td>-0.35363</td>\n",
       "      <td>-0.089382</td>\n",
       "      <td>-0.447665</td>\n",
       "      <td>-0.422654</td>\n",
       "      <td>-0.325115</td>\n",
       "      <td>-0.450097</td>\n",
       "      <td>-0.211605</td>\n",
       "      <td>-0.281908</td>\n",
       "      <td>-0.36208</td>\n",
       "      <td>-0.483298</td>\n",
       "      <td>-0.308233</td>\n",
       "      <td>-0.34294</td>\n",
       "      <td>-0.323017</td>\n",
       "      <td>-0.045791</td>\n",
       "      <td>-0.057194</td>\n",
       "      <td>-0.054842</td>\n",
       "      <td>-0.031881</td>\n",
       "      <td>-0.015007</td>\n",
       "      <td>-0.037858</td>\n",
       "      <td>-0.072124</td>\n",
       "      <td>-0.067005</td>\n",
       "      <td>-0.079805</td>\n",
       "      <td>-0.040947</td>\n",
       "      <td>-0.0494</td>\n",
       "      <td>-0.047343</td>\n",
       "      <td>-0.032528</td>\n",
       "      <td>-0.061764</td>\n",
       "      <td>-0.050674</td>\n",
       "      <td>-0.052212</td>\n",
       "      <td>-0.058176</td>\n",
       "      <td>-0.053373</td>\n",
       "      <td>-0.08205</td>\n",
       "      <td>-0.230531</td>\n",
       "      <td>-0.22759</td>\n",
       "      <td>-0.053747</td>\n",
       "      <td>-0.069811</td>\n",
       "      <td>-0.04128</td>\n",
       "      <td>-0.041151</td>\n",
       "      <td>-0.343569</td>\n",
       "      <td>-0.171602</td>\n",
       "      <td>-0.278643</td>\n",
       "      <td>-0.040645</td>\n",
       "      <td>-0.045145</td>\n",
       "      <td>-0.042053</td>\n",
       "      <td>-0.08919</td>\n",
       "      <td>-0.095307</td>\n",
       "      <td>-0.066844</td>\n",
       "      <td>-0.069129</td>\n",
       "      <td>-0.10873</td>\n",
       "      <td>-0.108326</td>\n",
       "      <td>-0.443577</td>\n",
       "      <td>-0.321263</td>\n",
       "      <td>-0.43605</td>\n",
       "      <td>-0.238435</td>\n",
       "      <td>-0.377649</td>\n",
       "      <td>-0.39305</td>\n",
       "      <td>-0.465556</td>\n",
       "      <td>-0.492519</td>\n",
       "      <td>-0.148389</td>\n",
       "      <td>-0.309876</td>\n",
       "      <td>-0.345461</td>\n",
       "      <td>-0.340874</td>\n",
       "      <td>-0.343962</td>\n",
       "      <td>-0.271606</td>\n",
       "      <td>-0.225907</td>\n",
       "      <td>-0.319623</td>\n",
       "      <td>-0.438433</td>\n",
       "      <td>-0.041485</td>\n",
       "      <td>-0.041062</td>\n",
       "      <td>-0.044216</td>\n",
       "      <td>-0.019603</td>\n",
       "      <td>-0.02641</td>\n",
       "      <td>-0.027637</td>\n",
       "      <td>-0.012979</td>\n",
       "      <td>-0.057632</td>\n",
       "      <td>-0.062164</td>\n",
       "      <td>-0.059283</td>\n",
       "      <td>-0.036909</td>\n",
       "      <td>-0.03958</td>\n",
       "      <td>-0.038675</td>\n",
       "      <td>-0.023196</td>\n",
       "      <td>-0.032106</td>\n",
       "      <td>-0.028872</td>\n",
       "      <td>-0.005653</td>\n",
       "      <td>-0.034642</td>\n",
       "      <td>-0.170618</td>\n",
       "      <td>0.199917</td>\n",
       "      <td>0.007098</td>\n",
       "      <td>0.563775</td>\n",
       "      <td>0.596434</td>\n",
       "      <td>-0.131711</td>\n",
       "      <td>-0.040420</td>\n",
       "      <td>-0.062849</td>\n",
       "      <td>-0.045744</td>\n",
       "      <td>-0.058539</td>\n",
       "      <td>-0.055212</td>\n",
       "      <td>-0.100440</td>\n",
       "      <td>-0.093916</td>\n",
       "      <td>-0.099373</td>\n",
       "      <td>-0.454447</td>\n",
       "      <td>-0.030437</td>\n",
       "      <td>-0.051142</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>0.462045</td>\n",
       "      <td>0.184965</td>\n",
       "      <td>0.571425</td>\n",
       "      <td>0.161584</td>\n",
       "      <td>0.484342</td>\n",
       "      <td>0.813949</td>\n",
       "      <td>0.352877</td>\n",
       "      <td>-0.048346</td>\n",
       "      <td>-0.062216</td>\n",
       "      <td>-0.057999</td>\n",
       "      <td>-0.054761</td>\n",
       "      <td>-0.088248</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.041168</td>\n",
       "      <td>-0.045422</td>\n",
       "      <td>-0.046141</td>\n",
       "      <td>-0.078694</td>\n",
       "      <td>-0.05516</td>\n",
       "      <td>-0.060439</td>\n",
       "      <td>-0.043013</td>\n",
       "      <td>-0.045611</td>\n",
       "      <td>-0.047175</td>\n",
       "      <td>-0.014289</td>\n",
       "      <td>-0.054151</td>\n",
       "      <td>-0.036347</td>\n",
       "      <td>-0.029533</td>\n",
       "      <td>-0.050234</td>\n",
       "      <td>-0.044481</td>\n",
       "      <td>0.298722</td>\n",
       "      <td>-0.387232</td>\n",
       "      <td>-0.034193</td>\n",
       "      <td>-0.142894</td>\n",
       "      <td>0.184399</td>\n",
       "      <td>-0.07117</td>\n",
       "      <td>0.077504</td>\n",
       "      <td>-0.032413</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>-0.560911</td>\n",
       "      <td>-0.506029</td>\n",
       "      <td>0.380593</td>\n",
       "      <td>-0.547637</td>\n",
       "      <td>-0.506005</td>\n",
       "      <td>-0.511042</td>\n",
       "      <td>-0.08243</td>\n",
       "      <td>-0.086243</td>\n",
       "      <td>-0.089706</td>\n",
       "      <td>-0.091688</td>\n",
       "      <td>-0.357827</td>\n",
       "      <td>-0.356561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID       V35       V31        M4  R_emaildomain      V122  \\\n",
       "0      3663549.0 -1.209963 -0.544587 -0.803152      -0.434818 -0.041814   \n",
       "1      3663550.0 -1.209963 -0.544587  0.407824      -0.434818 -0.041814   \n",
       "2      3663551.0 -1.209963 -0.544587  0.407824      -0.434818 -0.041814   \n",
       "3      3663552.0  0.348006 -0.544587 -0.803152      -0.434818 -0.041814   \n",
       "4      3663553.0 -1.209963 -0.544587 -0.803152      -0.434818 -0.041814   \n",
       "\n",
       "        V75       V84     id_38       V69       V57       V93       V63  \\\n",
       "0  0.799095 -0.551276 -0.546267  0.643397 -0.537535 -0.566493 -0.542801   \n",
       "1 -1.083156 -0.551276 -0.546267  0.643397 -0.537535 -0.566493 -0.542801   \n",
       "2 -1.083156 -0.551276 -0.546267  0.643397 -0.537535 -0.566493 -0.542801   \n",
       "3 -1.083156 -0.551276 -0.546267 -1.449451 -0.537535 -0.566493 -0.542801   \n",
       "4 -1.083156 -0.551276 -0.546267 -1.449451 -0.537535 -0.566493 -0.542801   \n",
       "\n",
       "       V240      V297       V65       V50       V42       V83      V112  \\\n",
       "0 -0.533175 -0.108377 -0.385432 -0.663889 -0.634533 -0.136447 -0.069307   \n",
       "1 -0.533175 -0.108377 -0.385432 -0.663889 -0.634533 -0.136447 -0.069307   \n",
       "2 -0.533175 -0.108377 -0.385432 -0.663889 -0.634533  2.897594 -0.069307   \n",
       "3 -0.533175 -0.108377 -0.385432 -0.663889 -0.634533 -0.136447 -0.069307   \n",
       "4 -0.533175 -0.108377 -0.385432 -0.663889 -0.634533 -0.136447 -0.069307   \n",
       "\n",
       "        V32        V3     id_24       V41      V305       V4       V25  \\\n",
       "0 -0.544537 -1.007672 -0.083475 -0.339302 -0.004593 -0.99097  1.079944   \n",
       "1 -0.544537 -1.007672 -0.083475 -0.339302 -0.004593 -0.99097 -0.413764   \n",
       "2 -0.544537 -1.007672 -0.083475 -0.339302 -0.004593 -0.99097 -0.413764   \n",
       "3 -0.544537 -1.007672 -0.083475 -0.339302 -0.004593 -0.99097 -0.413764   \n",
       "4 -0.544537 -1.007672 -0.083475 -0.339302 -0.004593 -0.99097 -0.413764   \n",
       "\n",
       "       V110        M7      V301        M2      V197       V18      V304  \\\n",
       "0 -0.083589 -0.949928 -0.193018 -1.019015 -0.526503 -0.527372 -0.553863   \n",
       "1 -0.083589  0.837200 -0.193018  0.273469 -0.526503 -0.527372 -0.553863   \n",
       "2 -0.083589 -1.227512 -0.193018 -1.019015 -0.526503 -0.527372 -0.553863   \n",
       "3 -0.083589  0.837200 -0.193018 -1.019015 -0.526503 -0.527372 -0.553863   \n",
       "4 -0.083589 -1.227512 -0.193018 -1.019015 -0.526503 -0.527372 -0.553863   \n",
       "\n",
       "         M5       V53       V76     id_18      V325     id_27    id_16  \\\n",
       "0  0.519333  0.706862  0.841976 -0.272797 -0.389465 -0.093859 -0.49368   \n",
       "1  0.519333  0.706862 -1.059143 -0.272797 -0.389465 -0.093859 -0.49368   \n",
       "2 -1.859128  0.706862  1.764824 -0.272797 -0.389465 -0.093859 -0.49368   \n",
       "3  0.519333 -0.972753 -1.059143 -0.272797 -0.389465 -0.093859 -0.49368   \n",
       "4  0.519333 -0.972753 -1.059143 -0.272797 -0.389465 -0.093859 -0.49368   \n",
       "\n",
       "      id_34      V175       V64      V141        V8       V15      V173  \\\n",
       "0 -0.294501 -0.529056 -0.542678 -0.300054 -0.965816 -0.515288 -0.553826   \n",
       "1 -0.294501 -0.529056 -0.542678 -0.300054 -0.965816 -0.515288 -0.553826   \n",
       "2 -0.294501 -0.529056 -0.542678 -0.300054 -0.965816 -0.515288 -0.553826   \n",
       "3 -0.294501 -0.529056 -0.542678 -0.300054 -0.965816 -0.515288 -0.553826   \n",
       "4 -0.294501 -0.529056 -0.542678 -0.300054 -0.965816 -0.515288 -0.553826   \n",
       "\n",
       "      id_32       V79      V194      V142  DeviceInfo       V94      V250  \\\n",
       "0 -0.205104 -0.540532 -0.524318 -0.298381   -0.326247 -0.559101 -0.533809   \n",
       "1 -0.205104 -0.540532 -0.524318 -0.298381   -0.326247 -0.559101 -0.533809   \n",
       "2 -0.205104 -0.540532 -0.524318 -0.298381   -0.326247 -0.559101 -0.533809   \n",
       "3 -0.205104 -0.540532 -0.524318 -0.298381   -0.326247 -0.559101 -0.533809   \n",
       "4 -0.205104 -0.540532 -0.524318 -0.298381   -0.326247 -0.559101 -0.533809   \n",
       "\n",
       "        V19        M3      V288      V113      V328       V48     id_15  \\\n",
       "0 -1.462481 -0.010886 -0.397750 -0.055439 -0.228292 -1.660800 -0.531932   \n",
       "1 -0.039890 -0.010886 -0.397750 -0.055439 -0.228292  0.748619 -0.531932   \n",
       "2 -0.039890 -0.010886 -0.397750 -0.055439 -0.228292  0.748619 -0.531932   \n",
       "3 -0.039890 -1.102171  1.616519 -0.055439 -0.228292 -1.660800 -0.531932   \n",
       "4 -0.039890 -1.102171  1.616519 -0.055439 -0.228292 -1.660800 -0.531932   \n",
       "\n",
       "        V51      V153     card4      V286       V98     id_35      V119  \\\n",
       "0 -0.656132 -0.076617 -0.029009 -0.154066 -0.234589 -0.501808 -0.031981   \n",
       "1 -0.656132 -0.076617 -0.029009 -0.154066 -0.234589 -0.501808 -0.031981   \n",
       "2 -0.656132 -0.076617 -0.029009 -0.154066 -0.234589 -0.501808 -0.031981   \n",
       "3 -0.656132 -0.076617 -0.029009 -0.154066 -0.234589 -0.501808 -0.031981   \n",
       "4 -0.656132 -0.076617 -0.169905  4.574395  3.893920 -0.501808 -0.031981   \n",
       "\n",
       "        V27        V9       V92      V251       V61     id_28      V195  \\\n",
       "0 -0.346458 -0.985232 -0.569585 -0.526942 -1.149454 -0.535487 -0.522041   \n",
       "1 -0.346458 -0.985232 -0.569585 -0.526942 -0.174917 -0.535487 -0.522041   \n",
       "2 -0.346458 -0.985232 -0.569585 -0.526942 -0.174917 -0.535487 -0.522041   \n",
       "3 -0.346458 -0.985232 -0.569585 -0.526942 -0.174917 -0.535487 -0.522041   \n",
       "4 -0.346458 -0.985232 -0.569585 -0.526942 -0.174917 -0.535487 -0.522041   \n",
       "\n",
       "      id_36      V34        V7       V23      V108      V121       V88  \\\n",
       "0 -0.553407 -0.54016 -0.996581 -0.352363 -0.066125 -0.065564 -0.422264   \n",
       "1 -0.553407 -0.54016 -0.996581 -0.352363 -0.066125 -0.065564 -0.422264   \n",
       "2 -0.553407 -0.54016 -0.996581  3.349216 -0.066125 -0.065564 -0.422264   \n",
       "3 -0.553407 -0.54016 -0.996581 -0.352363 -0.066125 -0.065564 -0.422264   \n",
       "4 -0.553407 -0.54016 -0.996581 -0.352363 -0.066125 -0.065564 -0.422264   \n",
       "\n",
       "        V29       V12      V115       V47       V26        M9       V66  \\\n",
       "0  0.684057  0.816550 -0.162702 -0.327293  0.780794 -1.331973  0.773818   \n",
       "1  0.684057 -1.019282 -0.162702 -0.327293 -0.408597  0.806283 -0.407192   \n",
       "2  0.684057 -1.019282 -0.162702 -0.327293 -0.408597 -0.156338 -0.407192   \n",
       "3 -1.452824 -1.019282 -0.162702  4.877804 -0.408597  0.806283 -0.407192   \n",
       "4 -1.452824 -1.019282 -0.162702 -0.327293 -0.408597 -1.331973 -0.407192   \n",
       "\n",
       "        V43       V59      V114    id_37       V89      V223       V74  \\\n",
       "0 -0.633584 -0.542823 -0.090673 -0.55872 -0.376049 -0.531279 -0.560236   \n",
       "1 -0.633584 -0.542823 -0.090673 -0.55872 -0.376049 -0.531279 -0.560236   \n",
       "2 -0.633584 -0.542823 -0.090673 -0.55872 -0.376049 -0.531279 -0.560236   \n",
       "3 -0.633584 -0.542823 -0.090673 -0.55872 -0.376049 -0.531279 -0.560236   \n",
       "4 -0.633584 -0.542823 -0.090673 -0.55872 -0.376049 -0.531279 -0.560236   \n",
       "\n",
       "        V49  P_emaildomain       V68     V111    id_04       V36     V124  \\\n",
       "0 -1.685703       0.706391 -0.377186 -0.04969 -0.35455 -1.188271 -0.22275   \n",
       "1  0.744573      -0.928992 -0.377186 -0.04969 -0.35455 -1.188271 -0.22275   \n",
       "2  0.744573       1.181086 -0.377186 -0.04969 -0.35455 -1.188271 -0.22275   \n",
       "3 -1.685703       0.706391 -0.377186 -0.04969 -0.35455  1.119419 -0.22275   \n",
       "4 -1.685703       0.706391 -0.377186 -0.04969 -0.35455 -1.188271 -0.22275   \n",
       "\n",
       "        V58      V107       V33       V46       V21       V82      V109  \\\n",
       "0 -0.535084 -0.003584 -0.528523 -0.272727 -0.528749 -0.100484 -0.114522   \n",
       "1 -0.535084 -0.003584 -0.528523 -0.272727 -0.528749 -0.100484 -0.114522   \n",
       "2 -0.535084 -0.003584 -0.528523 -0.272727 -0.528749 -0.100484 -0.114522   \n",
       "3 -0.535084 -0.003584 -0.528523  6.434365 -0.528749 -0.100484 -0.114522   \n",
       "4 -0.535084 -0.003584 -0.528523 -0.272727 -0.528749 -0.100484 -0.114522   \n",
       "\n",
       "       V125     id_31     id_12       V73       V52      V116       V13  \\\n",
       "0 -0.182099 -0.463749 -0.566417 -0.551901 -0.660177 -0.116566  0.843152   \n",
       "1 -0.182099 -0.463749 -0.566417 -0.551901 -0.660177 -0.116566 -1.002589   \n",
       "2 -0.182099 -0.463749 -0.566417 -0.551901 -0.660177 -0.116566 -1.002589   \n",
       "3 -0.182099 -0.463749 -0.566417 -0.551901 -0.660177 -0.116566 -1.002589   \n",
       "4 -0.182099 -0.463749 -0.566417 -0.551901 -0.660177 -0.116566 -1.002589   \n",
       "\n",
       "       V302      V104        M1       V17        V6       V24     id_29  \\\n",
       "0 -0.556132 -0.130335 -0.922256 -0.527387 -0.964954 -0.390305 -0.532699   \n",
       "1 -0.556132 -0.130335 -0.922256 -0.527387 -0.964954 -0.390305 -0.532699   \n",
       "2 -0.556132 -0.130335 -0.922256 -0.527387 -0.964954  2.254392 -0.532699   \n",
       "3 -0.556132 -0.130335 -0.922256 -0.527387 -0.964954 -0.390305 -0.532699   \n",
       "4 -0.556132 -0.130335 -0.922256 -0.527387 -0.964954 -0.390305 -0.532699   \n",
       "\n",
       "       V10       V54       V30     V154      V22       V72       V71  \\\n",
       "0 -1.72242  0.728937  0.686806 -0.05709 -0.52808 -0.553281 -0.556269   \n",
       "1  0.07973  0.728937  0.686806 -0.05709 -0.52808 -0.553281 -0.556269   \n",
       "2  0.07973  0.728937  0.686806 -0.05709 -0.52808 -0.553281 -0.556269   \n",
       "3 -1.72242 -0.957024 -1.465056 -0.05709 -0.52808 -0.553281 -0.556269   \n",
       "4 -1.72242 -0.957024 -1.465056 -0.05709 -0.52808 -0.553281 -0.556269   \n",
       "\n",
       "       V247      V300       V67      V289       V62      V85       V11  \\\n",
       "0 -0.494734 -0.183244  0.669091 -0.356303 -1.117969 -0.55055 -1.730432   \n",
       "1 -0.494734 -0.183244 -0.411473 -0.356303 -0.231481 -0.55055  0.080027   \n",
       "2 -0.494734 -0.183244 -0.411473 -0.356303 -0.231481 -0.55055  0.080027   \n",
       "3 -0.494734 -0.183244 -0.411473  0.874067 -0.231481 -0.55055 -1.730432   \n",
       "4 -0.494734 -0.183244 -0.411473  0.874067 -0.231481 -0.55055 -1.730432   \n",
       "\n",
       "        V70     id_30       V40        V5       V20       V91      V117  \\\n",
       "0  0.646860 -0.083471 -0.632061 -0.973044 -1.560152 -1.466143 -0.028718   \n",
       "1  0.646860 -0.083471 -0.632061 -0.973044 -0.045786  0.704683 -0.028718   \n",
       "2  0.646860 -0.083471 -0.632061 -0.973044 -0.045786  0.704683 -0.028718   \n",
       "3 -1.461539 -0.083471 -0.632061 -0.973044 -0.045786 -1.466143 -0.028718   \n",
       "4 -1.461539 -0.083471 -0.632061 -0.973044 -0.045786 -1.466143 -0.028718   \n",
       "\n",
       "   ProductCD        M6  DeviceType       V14       V16       V1        V2  \\\n",
       "0  -0.526444 -0.348024   -0.550072 -0.381317 -0.515288 -0.94828 -0.977981   \n",
       "1  -0.526444 -0.348024   -0.550072 -0.381317 -0.515288 -0.94828 -0.977981   \n",
       "2  -0.526444 -0.348024   -0.550072 -0.381317 -0.515288 -0.94828 -0.977981   \n",
       "3  -0.526444 -0.931627   -0.550072 -0.381317 -0.515288 -0.94828 -0.977981   \n",
       "4  -0.526444 -0.348024   -0.550072 -0.381317 -0.515288 -0.94828 -0.977981   \n",
       "\n",
       "       V28     V123      V327       V60      V174      V118      V241  \\\n",
       "0 -0.34976 -0.14449 -0.241668 -0.542326 -0.556514 -0.042189 -0.533263   \n",
       "1 -0.34976 -0.14449 -0.241668 -0.542326 -0.556514 -0.042189 -0.533263   \n",
       "2 -0.34976 -0.14449 -0.241668 -0.542326 -0.556514 -0.042189 -0.533263   \n",
       "3 -0.34976 -0.14449 -0.241668 -0.542326 -0.556514 -0.042189 -0.533263   \n",
       "4 -0.34976 -0.14449 -0.241668 -0.542326 -0.556514 -0.042189 -0.533263   \n",
       "\n",
       "       V284       V90     V260      V120     id_23    card6       V55  \\\n",
       "0 -0.284724 -1.448103 -0.50769 -0.033802 -0.089246 -0.58175 -0.438362   \n",
       "1 -0.284724  0.703487 -0.50769 -0.033802 -0.089246 -0.58175 -0.438362   \n",
       "2 -0.284724  0.703487 -0.50769 -0.033802 -0.089246 -0.58175 -0.438362   \n",
       "3 -0.284724 -1.448103 -0.50769 -0.033802 -0.089246 -0.58175 -0.438362   \n",
       "4  3.297984 -1.448103 -0.50769 -0.033802 -0.089246 -0.58175 -0.438362   \n",
       "\n",
       "         M8       V39      V184  TransactionDT  TransactionAmt     card1  \\\n",
       "0 -1.627023 -0.633937 -0.539156       2.389216       -0.427233  0.103203   \n",
       "1  0.816915 -0.633937 -0.539156       2.389225       -0.356595 -1.148561   \n",
       "2 -0.893489 -0.633937 -0.539156       2.389235        0.148851 -1.106951   \n",
       "3  0.816915 -0.633937 -0.539156       2.389235        0.620945  0.221506   \n",
       "4 -1.627023 -0.633937 -0.539156       2.389237       -0.278085  1.655211   \n",
       "\n",
       "      card2     card3     card5     addr1     addr2      dist1     dist2  \\\n",
       "0 -1.512083 -0.203484  0.633778 -0.665955  0.360192  -0.192433 -0.101669   \n",
       "1 -1.512083 -0.203484  0.633778  0.306803  0.360192  -0.180097 -0.101669   \n",
       "2  1.333335 -0.203484  0.633778  1.611354  0.360192  10.638383 -0.101669   \n",
       "3  0.018174 -0.203484 -0.717967 -0.402029  0.360192  -0.126642 -0.101669   \n",
       "4  0.583570 -0.203484 -1.821892  0.042876  0.360192  -0.171873 -0.101669   \n",
       "\n",
       "         C1        C2        C3        C4        C5        C6        C7  \\\n",
       "0 -0.060670 -0.060075 -0.039137 -0.059583 -0.099214 -0.070961 -0.046189   \n",
       "1 -0.083328 -0.086169 -0.039137 -0.059583 -0.215803 -0.113225 -0.046189   \n",
       "2 -0.090881 -0.086169 -0.039137 -0.059583 -0.215803 -0.056873 -0.046189   \n",
       "3 -0.068223 -0.086169 -0.039137 -0.059583 -0.176940 -0.113225 -0.046189   \n",
       "4 -0.060670 -0.060075 -0.039137 -0.059583 -0.138077 -0.056873 -0.046189   \n",
       "\n",
       "         C8        C9       C10       C11       C12       C13       C14  \\\n",
       "0 -0.054075  0.092101 -0.054926 -0.055569 -0.035446  0.641595 -0.046025   \n",
       "1 -0.054075 -0.148321 -0.054926 -0.098328 -0.035446 -0.158638 -0.127270   \n",
       "2 -0.054075 -0.028110 -0.054926 -0.087638 -0.047102 -0.080946 -0.127270   \n",
       "3 -0.054075 -0.148321 -0.054926 -0.087638 -0.047102 -0.197484 -0.086648   \n",
       "4 -0.054075  0.031995 -0.054926 -0.044879 -0.047102 -0.143100 -0.046025   \n",
       "\n",
       "         D1        D2        D3        D4        D5        D6        D7  \\\n",
       "0  2.063359  2.147310  0.233750  1.720210  0.106599 -0.155767 -0.099152   \n",
       "1  0.348739  0.391102 -0.179262  3.081821 -0.201734 -0.155767 -0.099152   \n",
       "2  0.272533  0.313048 -0.117310 -0.016421 -0.155484 -0.155767 -0.099152   \n",
       "3 -0.330759 -0.304877  0.522859  0.820162  0.322432 -0.155767 -0.099152   \n",
       "4 -0.457768 -0.434967 -0.323817 -0.449137 -0.309651 -0.155767 -0.099152   \n",
       "\n",
       "         D8        D9       D10       D11       D12      D13       D14  \\\n",
       "0 -0.193691 -0.326769  1.764846  0.817541 -0.133469 -0.08284 -0.127827   \n",
       "1 -0.193691 -0.326769  0.699720  3.621611 -0.133469 -0.08284 -0.127827   \n",
       "2 -0.193691 -0.326769  0.158614  0.381642 -0.133469 -0.08284 -0.127827   \n",
       "3 -0.193691 -0.326769  0.762375  1.071273 -0.133469 -0.08284 -0.127827   \n",
       "4 -0.193691 -0.326769 -0.490714 -0.360038 -0.133469 -0.08284 -0.127827   \n",
       "\n",
       "        D15       V37       V38       V44       V45       V56       V77  \\\n",
       "0  1.378919  0.271492  0.189757  0.308174  0.248921  0.034181  0.123804   \n",
       "1  2.528164  0.271492  0.189757  0.308174  0.248921  0.034181  0.123804   \n",
       "2 -0.214701  0.271492  0.189757  0.308174  0.248921  0.034181  0.123804   \n",
       "3  0.525924  1.568414  1.302749  1.669551  1.493239  0.034181  0.123804   \n",
       "4 -0.597782  0.271492  0.189757  0.308174  0.248921  0.034181  0.123804   \n",
       "\n",
       "        V78       V80      V81       V86       V87       V95       V96  \\\n",
       "0  0.034274 -0.321885 -0.30961  0.177113  0.108959 -0.049281 -0.049607   \n",
       "1  0.034274 -0.321885 -0.30961  0.177113  0.108959 -0.049281  0.025097   \n",
       "2  1.244264 -0.321885 -0.30961  0.177113  0.108959 -0.049281  0.049998   \n",
       "3  0.034274 -0.321885 -0.30961  0.177113  0.108959 -0.049281 -0.074508   \n",
       "4  0.034274 -0.321885 -0.30961  0.177113  0.108959 -0.001529  0.000196   \n",
       "\n",
       "        V97       V99      V100      V101      V102      V103      V105  \\\n",
       "0 -0.061936  0.039914 -0.289522 -0.043091 -0.050719 -0.049673 -0.083152   \n",
       "1 -0.025731  1.147669  0.772454 -0.043091 -0.050719 -0.049673 -0.083152   \n",
       "2 -0.061936  0.778417 -0.289522 -0.043091 -0.050719 -0.049673  0.511381   \n",
       "3 -0.061936 -0.329338 -0.289522 -0.043091 -0.050719 -0.049673 -0.083152   \n",
       "4 -0.025731  0.778417  0.772454 -0.043091 -0.050719 -0.049673 -0.083152   \n",
       "\n",
       "       V106      V126      V127      V128      V129      V130      V131  \\\n",
       "0 -0.090258 -0.055307 -0.067925 -0.067677 -0.072755 -0.138481 -0.187140   \n",
       "1 -0.090258 -0.055307 -0.013079 -0.042038 -0.072755  0.589811  0.275136   \n",
       "2 -0.090258 -0.055307  0.149530 -0.067677 -0.072755  1.923681 -0.187140   \n",
       "3 -0.090258 -0.055307 -0.079258 -0.067677 -0.072755 -0.288973 -0.187140   \n",
       "4 -0.090258 -0.026255 -0.035805 -0.045051  0.488008  0.288043  0.220803   \n",
       "\n",
       "       V132      V133      V134      V135      V136      V137      V138  \\\n",
       "0 -0.045542 -0.053788 -0.052465 -0.058679 -0.085678 -0.075511 -0.031701   \n",
       "1 -0.045542 -0.053788 -0.052465 -0.058679 -0.085678 -0.075511 -0.031701   \n",
       "2 -0.045542 -0.053788 -0.052465 -0.058679  0.496019 -0.075511 -0.031701   \n",
       "3 -0.045542 -0.053788 -0.052465 -0.058679 -0.085678 -0.075511 -0.031701   \n",
       "4 -0.045542 -0.053788 -0.052465 -0.058679 -0.085678 -0.075511 -0.031701   \n",
       "\n",
       "       V139      V140      V143     V144      V145      V146      V147  \\\n",
       "0 -0.239792 -0.232437 -0.055918 -0.12476 -0.121427 -0.083953 -0.082158   \n",
       "1 -0.239792 -0.232437 -0.055918 -0.12476 -0.121427 -0.083953 -0.082158   \n",
       "2 -0.239792 -0.232437 -0.055918 -0.12476 -0.121427 -0.083953 -0.082158   \n",
       "3 -0.239792 -0.232437 -0.055918 -0.12476 -0.121427 -0.083953 -0.082158   \n",
       "4 -0.239792 -0.232437 -0.055918 -0.12476 -0.121427 -0.083953 -0.082158   \n",
       "\n",
       "       V148      V149      V150      V151      V152      V155      V156  \\\n",
       "0 -0.312521 -0.303912 -0.118531 -0.146723 -0.150773 -0.308673 -0.300664   \n",
       "1 -0.312521 -0.303912 -0.118531 -0.146723 -0.150773 -0.308673 -0.300664   \n",
       "2 -0.312521 -0.303912 -0.118531 -0.146723 -0.150773 -0.308673 -0.300664   \n",
       "3 -0.312521 -0.303912 -0.118531 -0.146723 -0.150773 -0.308673 -0.300664   \n",
       "4 -0.312521 -0.303912 -0.118531 -0.146723 -0.150773 -0.308673 -0.300664   \n",
       "\n",
       "       V157      V158      V159      V160      V161      V162     V163  \\\n",
       "0 -0.300284 -0.292522 -0.115576 -0.118405 -0.030455 -0.035149 -0.03225   \n",
       "1 -0.300284 -0.292522 -0.115576 -0.118405 -0.030455 -0.035149 -0.03225   \n",
       "2 -0.300284 -0.292522 -0.115576 -0.118405 -0.030455 -0.035149 -0.03225   \n",
       "3 -0.300284 -0.292522 -0.115576 -0.118405 -0.030455 -0.035149 -0.03225   \n",
       "4 -0.300284 -0.292522 -0.115576 -0.118405 -0.030455 -0.035149 -0.03225   \n",
       "\n",
       "       V164      V165     V166      V167      V168      V169      V170  \\\n",
       "0 -0.053456 -0.097952 -0.10278 -0.045024 -0.052381 -0.089246 -0.324797   \n",
       "1 -0.053456 -0.097952 -0.10278 -0.045024 -0.052381 -0.089246 -0.324797   \n",
       "2 -0.053456 -0.097952 -0.10278 -0.045024 -0.052381 -0.089246 -0.324797   \n",
       "3 -0.053456 -0.097952 -0.10278 -0.045024 -0.052381 -0.089246 -0.324797   \n",
       "4 -0.053456 -0.097952 -0.10278 -0.045024 -0.052381 -0.089246 -0.324797   \n",
       "\n",
       "       V171     V172      V176      V177      V178      V179     V180  \\\n",
       "0 -0.288607 -0.06896 -0.306484 -0.041292 -0.046295 -0.046597 -0.07271   \n",
       "1 -0.288607 -0.06896 -0.306484 -0.041292 -0.046295 -0.046597 -0.07271   \n",
       "2 -0.288607 -0.06896 -0.306484 -0.041292 -0.046295 -0.046597 -0.07271   \n",
       "3 -0.288607 -0.06896 -0.306484 -0.041292 -0.046295 -0.046597 -0.07271   \n",
       "4 -0.288607 -0.06896 -0.306484 -0.041292 -0.046295 -0.046597 -0.07271   \n",
       "\n",
       "       V181      V182      V183      V185     V186      V187      V188  \\\n",
       "0 -0.097544 -0.071066 -0.079106 -0.119359 -0.35363 -0.089382 -0.447665   \n",
       "1 -0.097544 -0.071066 -0.079106 -0.119359 -0.35363 -0.089382 -0.447665   \n",
       "2 -0.097544 -0.071066 -0.079106 -0.119359 -0.35363 -0.089382 -0.447665   \n",
       "3 -0.097544 -0.071066 -0.079106 -0.119359 -0.35363 -0.089382 -0.447665   \n",
       "4 -0.097544 -0.071066 -0.079106 -0.119359 -0.35363 -0.089382 -0.447665   \n",
       "\n",
       "       V189      V190      V191      V192      V193     V196      V198  \\\n",
       "0 -0.422654 -0.325115 -0.450097 -0.211605 -0.281908 -0.36208 -0.483298   \n",
       "1 -0.422654 -0.325115 -0.450097 -0.211605 -0.281908 -0.36208 -0.483298   \n",
       "2 -0.422654 -0.325115 -0.450097 -0.211605 -0.281908 -0.36208 -0.483298   \n",
       "3 -0.422654 -0.325115 -0.450097 -0.211605 -0.281908 -0.36208 -0.483298   \n",
       "4 -0.422654 -0.325115 -0.450097 -0.211605 -0.281908 -0.36208 -0.483298   \n",
       "\n",
       "       V199     V200      V201      V202      V203      V204      V205  \\\n",
       "0 -0.308233 -0.34294 -0.323017 -0.045791 -0.057194 -0.054842 -0.031881   \n",
       "1 -0.308233 -0.34294 -0.323017 -0.045791 -0.057194 -0.054842 -0.031881   \n",
       "2 -0.308233 -0.34294 -0.323017 -0.045791 -0.057194 -0.054842 -0.031881   \n",
       "3 -0.308233 -0.34294 -0.323017 -0.045791 -0.057194 -0.054842 -0.031881   \n",
       "4 -0.308233 -0.34294 -0.323017 -0.045791 -0.057194 -0.054842 -0.031881   \n",
       "\n",
       "       V206      V207      V208      V209      V210      V211    V212  \\\n",
       "0 -0.015007 -0.037858 -0.072124 -0.067005 -0.079805 -0.040947 -0.0494   \n",
       "1 -0.015007 -0.037858 -0.072124 -0.067005 -0.079805 -0.040947 -0.0494   \n",
       "2 -0.015007 -0.037858 -0.072124 -0.067005 -0.079805 -0.040947 -0.0494   \n",
       "3 -0.015007 -0.037858 -0.072124 -0.067005 -0.079805 -0.040947 -0.0494   \n",
       "4 -0.015007 -0.037858 -0.072124 -0.067005 -0.079805 -0.040947 -0.0494   \n",
       "\n",
       "       V213      V214      V215      V216      V217      V218      V219  \\\n",
       "0 -0.047343 -0.032528 -0.061764 -0.050674 -0.052212 -0.058176 -0.053373   \n",
       "1 -0.047343 -0.032528 -0.061764 -0.050674 -0.052212 -0.058176 -0.053373   \n",
       "2 -0.047343 -0.032528 -0.061764 -0.050674 -0.052212 -0.058176 -0.053373   \n",
       "3 -0.047343 -0.032528 -0.061764 -0.050674 -0.052212 -0.058176 -0.053373   \n",
       "4 -0.047343 -0.032528 -0.061764 -0.050674 -0.052212 -0.058176 -0.053373   \n",
       "\n",
       "      V220      V221     V222      V224      V225     V226      V227  \\\n",
       "0 -0.08205 -0.230531 -0.22759 -0.053747 -0.069811 -0.04128 -0.041151   \n",
       "1 -0.08205 -0.230531 -0.22759 -0.053747 -0.069811 -0.04128 -0.041151   \n",
       "2 -0.08205 -0.230531 -0.22759 -0.053747 -0.069811 -0.04128 -0.041151   \n",
       "3 -0.08205 -0.230531 -0.22759 -0.053747 -0.069811 -0.04128 -0.041151   \n",
       "4 -0.08205 -0.230531 -0.22759 -0.053747 -0.069811 -0.04128 -0.041151   \n",
       "\n",
       "       V228      V229      V230      V231      V232      V233     V234  \\\n",
       "0 -0.343569 -0.171602 -0.278643 -0.040645 -0.045145 -0.042053 -0.08919   \n",
       "1 -0.343569 -0.171602 -0.278643 -0.040645 -0.045145 -0.042053 -0.08919   \n",
       "2 -0.343569 -0.171602 -0.278643 -0.040645 -0.045145 -0.042053 -0.08919   \n",
       "3 -0.343569 -0.171602 -0.278643 -0.040645 -0.045145 -0.042053 -0.08919   \n",
       "4 -0.343569 -0.171602 -0.278643 -0.040645 -0.045145 -0.042053 -0.08919   \n",
       "\n",
       "       V235      V236      V237     V238      V239      V242      V243  \\\n",
       "0 -0.095307 -0.066844 -0.069129 -0.10873 -0.108326 -0.443577 -0.321263   \n",
       "1 -0.095307 -0.066844 -0.069129 -0.10873 -0.108326 -0.443577 -0.321263   \n",
       "2 -0.095307 -0.066844 -0.069129 -0.10873 -0.108326 -0.443577 -0.321263   \n",
       "3 -0.095307 -0.066844 -0.069129 -0.10873 -0.108326 -0.443577 -0.321263   \n",
       "4 -0.095307 -0.066844 -0.069129 -0.10873 -0.108326 -0.443577 -0.321263   \n",
       "\n",
       "      V244      V245      V246     V248      V249      V252      V253  \\\n",
       "0 -0.43605 -0.238435 -0.377649 -0.39305 -0.465556 -0.492519 -0.148389   \n",
       "1 -0.43605 -0.238435 -0.377649 -0.39305 -0.465556 -0.492519 -0.148389   \n",
       "2 -0.43605 -0.238435 -0.377649 -0.39305 -0.465556 -0.492519 -0.148389   \n",
       "3 -0.43605 -0.238435 -0.377649 -0.39305 -0.465556 -0.492519 -0.148389   \n",
       "4 -0.43605 -0.238435 -0.377649 -0.39305 -0.465556 -0.492519 -0.148389   \n",
       "\n",
       "       V254      V255      V256      V257      V258      V259      V261  \\\n",
       "0 -0.309876 -0.345461 -0.340874 -0.343962 -0.271606 -0.225907 -0.319623   \n",
       "1 -0.309876 -0.345461 -0.340874 -0.343962 -0.271606 -0.225907 -0.319623   \n",
       "2 -0.309876 -0.345461 -0.340874 -0.343962 -0.271606 -0.225907 -0.319623   \n",
       "3 -0.309876 -0.345461 -0.340874 -0.343962 -0.271606 -0.225907 -0.319623   \n",
       "4 -0.309876 -0.345461 -0.340874 -0.343962 -0.271606 -0.225907 -0.319623   \n",
       "\n",
       "       V262      V263      V264      V265      V266     V267      V268  \\\n",
       "0 -0.438433 -0.041485 -0.041062 -0.044216 -0.019603 -0.02641 -0.027637   \n",
       "1 -0.438433 -0.041485 -0.041062 -0.044216 -0.019603 -0.02641 -0.027637   \n",
       "2 -0.438433 -0.041485 -0.041062 -0.044216 -0.019603 -0.02641 -0.027637   \n",
       "3 -0.438433 -0.041485 -0.041062 -0.044216 -0.019603 -0.02641 -0.027637   \n",
       "4 -0.438433 -0.041485 -0.041062 -0.044216 -0.019603 -0.02641 -0.027637   \n",
       "\n",
       "       V269      V270      V271      V272      V273     V274      V275  \\\n",
       "0 -0.012979 -0.057632 -0.062164 -0.059283 -0.036909 -0.03958 -0.038675   \n",
       "1 -0.012979 -0.057632 -0.062164 -0.059283 -0.036909 -0.03958 -0.038675   \n",
       "2 -0.012979 -0.057632 -0.062164 -0.059283 -0.036909 -0.03958 -0.038675   \n",
       "3 -0.012979 -0.057632 -0.062164 -0.059283 -0.036909 -0.03958 -0.038675   \n",
       "4 -0.012979 -0.057632 -0.062164 -0.059283 -0.036909 -0.03958 -0.038675   \n",
       "\n",
       "       V276      V277      V278      V279      V280      V281      V282  \\\n",
       "0 -0.023196 -0.032106 -0.028872 -0.053422 -0.070625 -0.170618 -0.882906   \n",
       "1 -0.023196 -0.032106 -0.028872 -0.053422 -0.034642 -0.170618 -0.882906   \n",
       "2 -0.023196 -0.032106 -0.028872 -0.053422 -0.070625 -0.170618 -0.882906   \n",
       "3 -0.023196 -0.032106 -0.028872 -0.053422 -0.070625 -0.170618  0.199917   \n",
       "4 -0.023196 -0.032106 -0.028872 -0.005653 -0.034642 -0.170618  0.199917   \n",
       "\n",
       "       V283      V285      V287      V290      V291      V292      V293  \\\n",
       "0 -0.630863 -0.050212 -0.332543 -0.131711 -0.040420 -0.062849 -0.045744   \n",
       "1 -0.630863  0.870768  0.596434 -0.131711 -0.040420 -0.062849 -0.045744   \n",
       "2 -0.630863  0.870768 -0.332543 -0.131711  0.019897 -0.062849 -0.045744   \n",
       "3  0.007098 -0.357205 -0.332543 -0.131711 -0.040420 -0.062849 -0.045744   \n",
       "4  0.007098  0.563775  0.596434 -0.131711 -0.040420 -0.062849 -0.045744   \n",
       "\n",
       "       V294      V295      V296      V298      V299      V303      V306  \\\n",
       "0 -0.058539 -0.055212 -0.100440 -0.093916 -0.099373 -0.454447 -0.059471   \n",
       "1 -0.058539 -0.055212 -0.100440 -0.093916 -0.099373 -0.454447 -0.059471   \n",
       "2 -0.058539 -0.055212  0.514546  0.537305 -0.099373 -0.454447 -0.059471   \n",
       "3 -0.058539 -0.055212 -0.100440 -0.093916 -0.099373 -0.454447 -0.059471   \n",
       "4 -0.058539 -0.055212 -0.100440 -0.093916 -0.099373 -0.454447 -0.030437   \n",
       "\n",
       "       V307      V308      V309      V310      V311      V312      V313  \\\n",
       "0 -0.082069 -0.076203 -0.089662 -0.197308 -0.038594 -0.221127 -0.221827   \n",
       "1 -0.029261 -0.050669 -0.089662  0.455425 -0.038594  0.212555 -0.221827   \n",
       "2  0.207641 -0.076203 -0.089662  2.643860 -0.038594 -0.221127 -0.221827   \n",
       "3 -0.092981 -0.076203 -0.089662 -0.332187 -0.038594 -0.221127  2.714464   \n",
       "4 -0.051142 -0.053670  0.462045  0.184965  0.571425  0.161584  0.484342   \n",
       "\n",
       "       V314      V315      V316      V317      V318      V319      V320  \\\n",
       "0 -0.249078 -0.228881 -0.048346 -0.062216 -0.057999 -0.054761 -0.088248   \n",
       "1 -0.249078 -0.228881 -0.048346 -0.062216 -0.057999 -0.054761 -0.088248   \n",
       "2 -0.249078 -0.228881 -0.048346 -0.062216 -0.057999 -0.054761  0.466291   \n",
       "3  1.384578  2.190101 -0.048346 -0.062216 -0.057999 -0.054761 -0.088248   \n",
       "4  0.813949  0.352877 -0.048346 -0.062216 -0.057999 -0.054761 -0.088248   \n",
       "\n",
       "       V321      V322      V323      V324      V326     V329      V330  \\\n",
       "0 -0.073425 -0.041168 -0.045422 -0.046141 -0.078694 -0.05516 -0.060439   \n",
       "1 -0.073425 -0.041168 -0.045422 -0.046141 -0.078694 -0.05516 -0.060439   \n",
       "2 -0.073425 -0.041168 -0.045422 -0.046141 -0.078694 -0.05516 -0.060439   \n",
       "3 -0.073425 -0.041168 -0.045422 -0.046141 -0.078694 -0.05516 -0.060439   \n",
       "4 -0.073425 -0.041168 -0.045422 -0.046141 -0.078694 -0.05516 -0.060439   \n",
       "\n",
       "       V331      V332      V333      V334      V335      V336      V337  \\\n",
       "0 -0.043013 -0.045611 -0.047175 -0.014289 -0.054151 -0.036347 -0.029533   \n",
       "1 -0.043013 -0.045611 -0.047175 -0.014289 -0.054151 -0.036347 -0.029533   \n",
       "2 -0.043013 -0.045611 -0.047175 -0.014289 -0.054151 -0.036347 -0.029533   \n",
       "3 -0.043013 -0.045611 -0.047175 -0.014289 -0.054151 -0.036347 -0.029533   \n",
       "4 -0.043013 -0.045611 -0.047175 -0.014289 -0.054151 -0.036347 -0.029533   \n",
       "\n",
       "       V338      V339     id_01     id_02     id_03     id_05     id_06  \\\n",
       "0 -0.050234 -0.044481  0.298722 -0.387232 -0.034193 -0.142894  0.184399   \n",
       "1 -0.050234 -0.044481  0.298722 -0.387232 -0.034193 -0.142894  0.184399   \n",
       "2 -0.050234 -0.044481  0.298722 -0.387232 -0.034193 -0.142894  0.184399   \n",
       "3 -0.050234 -0.044481  0.298722 -0.387232 -0.034193 -0.142894  0.184399   \n",
       "4 -0.050234 -0.044481  0.298722 -0.387232 -0.034193 -0.142894  0.184399   \n",
       "\n",
       "     id_07     id_08     id_09     id_10     id_11     id_13     id_14  \\\n",
       "0 -0.07117  0.077504 -0.032413  0.037666 -0.560911 -0.506029  0.380593   \n",
       "1 -0.07117  0.077504 -0.032413  0.037666 -0.560911 -0.506029  0.380593   \n",
       "2 -0.07117  0.077504 -0.032413  0.037666 -0.560911 -0.506029  0.380593   \n",
       "3 -0.07117  0.077504 -0.032413  0.037666 -0.560911 -0.506029  0.380593   \n",
       "4 -0.07117  0.077504 -0.032413  0.037666 -0.560911 -0.506029  0.380593   \n",
       "\n",
       "      id_17     id_19     id_20    id_21     id_22     id_25     id_26  \\\n",
       "0 -0.547637 -0.506005 -0.511042 -0.08243 -0.086243 -0.089706 -0.091688   \n",
       "1 -0.547637 -0.506005 -0.511042 -0.08243 -0.086243 -0.089706 -0.091688   \n",
       "2 -0.547637 -0.506005 -0.511042 -0.08243 -0.086243 -0.089706 -0.091688   \n",
       "3 -0.547637 -0.506005 -0.511042 -0.08243 -0.086243 -0.089706 -0.091688   \n",
       "4 -0.547637 -0.506005 -0.511042 -0.08243 -0.086243 -0.089706 -0.091688   \n",
       "\n",
       "   Screen_Width  Screen_Height  \n",
       "0     -0.357827      -0.356561  \n",
       "1     -0.357827      -0.356561  \n",
       "2     -0.357827      -0.356561  \n",
       "3     -0.357827      -0.356561  \n",
       "4     -0.357827      -0.356561  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scaled = pd.DataFrame(np.hstack([test[[\"TransactionID\"]], test_scaled]), columns=[\"TransactionID\"] + list(test_scaled.columns))\n",
    "test_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.to_csv(\"data/preprocessed_train.csv\", index=False)\n",
    "X_val_scaled.to_csv(\"data/preprocessed_val.csv\", index=False)\n",
    "\n",
    "y_train.to_csv(\"data/y_train.csv\", index=False)\n",
    "y_val.to_csv(\"data/y_val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaled.to_csv(\"data/test_for_model_eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we start with baseline - SVM with preselected features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try different approaches for reducing dimensionality in dataset to compare it with GA:\n",
    "- PCA - Principal Component Analysis\n",
    "- ICA - Independent Component Analysis\n",
    "- Truncated SVD - Truncated Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "X_train_scaled = pd.read_csv(\"data/preprocessed_train.csv\")\n",
    "X_val_scaled = pd.read_csv(\"data/preprocessed_val.csv\")\n",
    "y_train = pd.read_csv(\"data/y_train.csv\")\n",
    "y_val = pd.read_csv(\"data/y_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('data/test_for_model_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_ids = X_test[\"TransactionID\"].astype(int)\n",
    "X_test = X_test.drop(columns=[\"TransactionID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_flat = y_train.values.ravel()\n",
    "y_val_flat = y_val.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Account for class imbalance\n",
    "# Convert y_train to numpy array (since it's read as DataFrame)\n",
    "y_train_array = y_train['isFraud'].values\n",
    "\n",
    "# Get unique classes and compute weights\n",
    "unique_classes = np.unique(y_train_array)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=unique_classes,\n",
    "    y=y_train_array\n",
    ")\n",
    "\n",
    "# Create dictionary of class weights\n",
    "class_weights_dict = dict(zip(unique_classes, class_weights))\n",
    "class_weights_dict = {int(k): float(v) for k, v in class_weights_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=30)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_val_pca = pca.transform(X_val_scaled)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM after PCA Training ROC AUC: 0.776448371320197\n"
     ]
    }
   ],
   "source": [
    "# Define model with default hyperparameters\n",
    "model_svm_pca = LinearSVC(class_weight=class_weights_dict) # Since we have huge dataset we cannot use normal SVC\n",
    "clf_pca = CalibratedClassifierCV(model_cvm_pca) # Since SVM by default cannot predict probabilities, we enhance it with classifier\n",
    "clf_pca.fit(X_train_pca, y_train_flat)\n",
    "y_pred_svm_pca = clf_pca.predict_proba(X_val_pca)[:, 1]\n",
    "print(\"SVM after PCA Training ROC AUC:\", roc_auc_score(y_val_flat, y_pred_svm_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save result to test it in Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_pca_test = clf_pca.predict_proba(X_test_pca)\n",
    "fraud_probs = y_pred_svm_pca_test[:, 1]\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'TransactionID': transaction_ids,\n",
    "    'isFraud': fraud_probs\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submissions/svm_pca.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle result: 0.768107; 0.809067\n",
    "#### Validation ROC AUC: 0.7764"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/decomposition/_fastica.py:127: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ica = FastICA(n_components=30, random_state=42)\n",
    "X_train_ica= ica.fit_transform(X_train_scaled)\n",
    "X_val_ica = ica.transform(X_val_scaled)\n",
    "X_test_ica = ica.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model after ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM after ICA Training ROC AUC: 0.812649836031573\n"
     ]
    }
   ],
   "source": [
    "# Define model with default hyperparameters\n",
    "model_svm_ica = LinearSVC(class_weight=class_weights_dict) # Since we have huge dataset we cannot use normal SVC\n",
    "clf_ica = CalibratedClassifierCV(model_svm_ica) # Since SVM by default cannot predict probabilities, we enhance it with classifier\n",
    "clf_ica.fit(X_train_ica, y_train_flat)\n",
    "y_pred_svm_ica = clf_ica.predict_proba(X_val_ica)[:, 1]\n",
    "print(\"SVM after ICA Training ROC AUC:\", roc_auc_score(y_val_flat, y_pred_svm_ica))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save result to test it in Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_ica_test = clf_ica.predict_proba(X_test_ica)\n",
    "fraud_probs = y_pred_svm_ica_test[:, 1]\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'TransactionID': transaction_ids,\n",
    "    'isFraud': fraud_probs\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submissions/svm_ica.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle results: 0.798548; 0.837181\n",
    "#### Validation ROC AUC: 0.8126"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=30, random_state=42)\n",
    "X_train_svd = svd.fit_transform(X_train_scaled)\n",
    "X_val_svd = svd.transform(X_val_scaled)\n",
    "X_test_svd = svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model after SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM after ICA Training ROC AUC: 0.8124530282772098\n"
     ]
    }
   ],
   "source": [
    "# Define model with default hyperparameters\n",
    "model_svm_svd = LinearSVC(class_weight=class_weights_dict) # Since we have huge dataset we cannot use normal SVC\n",
    "clf_svd = CalibratedClassifierCV(model_svm_svd) # Since SVM by default cannot predict probabilities, we enhance it with classifier\n",
    "clf_svd.fit(X_train_svd, y_train_flat)\n",
    "y_pred_svm_svd = clf_svd.predict_proba(X_val_svd)[:, 1]\n",
    "print(\"SVM after ICA Training ROC AUC:\", roc_auc_score(y_val_flat, y_pred_svm_svd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save results to test it in Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_svd_test = clf_svd.predict_proba(X_test_svd)\n",
    "fraud_probs = y_pred_svm_svd_test[:, 1]\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'TransactionID': transaction_ids,\n",
    "    'isFraud': fraud_probs\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submissions/svm_svd.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle results: 0.798845; 0.837388\n",
    "#### Validation ROC AUC: 0.8125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algorithm with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.7552\n",
      "Individual 1/30: Fitness = 0.7552\n",
      "Feature subset evaluated: ROC AUC = 0.7866\n",
      "Individual 2/30: Fitness = 0.7866\n",
      "Feature subset evaluated: ROC AUC = 0.7852\n",
      "Individual 3/30: Fitness = 0.7852\n",
      "Feature subset evaluated: ROC AUC = 0.7859\n",
      "Individual 4/30: Fitness = 0.7859\n",
      "Feature subset evaluated: ROC AUC = 0.7848\n",
      "Individual 5/30: Fitness = 0.7848\n",
      "Feature subset evaluated: ROC AUC = 0.8015\n",
      "Individual 6/30: Fitness = 0.8015\n",
      "Feature subset evaluated: ROC AUC = 0.7867\n",
      "Individual 7/30: Fitness = 0.7867\n",
      "Feature subset evaluated: ROC AUC = 0.8045\n",
      "Individual 8/30: Fitness = 0.8045\n",
      "Feature subset evaluated: ROC AUC = 0.7914\n",
      "Individual 9/30: Fitness = 0.7914\n",
      "Feature subset evaluated: ROC AUC = 0.7602\n",
      "Individual 10/30: Fitness = 0.7602\n",
      "Feature subset evaluated: ROC AUC = 0.7545\n",
      "Individual 11/30: Fitness = 0.7545\n",
      "Feature subset evaluated: ROC AUC = 0.7860\n",
      "Individual 12/30: Fitness = 0.7860\n",
      "Feature subset evaluated: ROC AUC = 0.7657\n",
      "Individual 13/30: Fitness = 0.7657\n",
      "Feature subset evaluated: ROC AUC = 0.7905\n",
      "Individual 14/30: Fitness = 0.7905\n",
      "Feature subset evaluated: ROC AUC = 0.7960\n",
      "Individual 15/30: Fitness = 0.7960\n",
      "Feature subset evaluated: ROC AUC = 0.7825\n",
      "Individual 16/30: Fitness = 0.7825\n",
      "Feature subset evaluated: ROC AUC = 0.7936\n",
      "Individual 17/30: Fitness = 0.7936\n",
      "Feature subset evaluated: ROC AUC = 0.7606\n",
      "Individual 18/30: Fitness = 0.7606\n",
      "Feature subset evaluated: ROC AUC = 0.7505\n",
      "Individual 19/30: Fitness = 0.7505\n",
      "Feature subset evaluated: ROC AUC = 0.7438\n",
      "Individual 20/30: Fitness = 0.7438\n",
      "Feature subset evaluated: ROC AUC = 0.7712\n",
      "Individual 21/30: Fitness = 0.7712\n",
      "Feature subset evaluated: ROC AUC = 0.7565\n",
      "Individual 22/30: Fitness = 0.7565\n",
      "Feature subset evaluated: ROC AUC = 0.7929\n",
      "Individual 23/30: Fitness = 0.7929\n",
      "Feature subset evaluated: ROC AUC = 0.7625\n",
      "Individual 24/30: Fitness = 0.7625\n",
      "Feature subset evaluated: ROC AUC = 0.7692\n",
      "Individual 25/30: Fitness = 0.7692\n",
      "Feature subset evaluated: ROC AUC = 0.7747\n",
      "Individual 26/30: Fitness = 0.7747\n",
      "Feature subset evaluated: ROC AUC = 0.7967\n",
      "Individual 27/30: Fitness = 0.7967\n",
      "Feature subset evaluated: ROC AUC = 0.7626\n",
      "Individual 28/30: Fitness = 0.7626\n",
      "Feature subset evaluated: ROC AUC = 0.7802\n",
      "Individual 29/30: Fitness = 0.7802\n",
      "Feature subset evaluated: ROC AUC = 0.7927\n",
      "Individual 30/30: Fitness = 0.7927\n",
      "\n",
      "Best fitness in generation 1: 0.8045\n",
      "Current best features: ['V63', 'M5', 'id_18', 'id_34', 'V141', 'V8', 'id_32', 'V61', 'V108', 'V68', 'V58', 'V154', 'V70', 'M6', 'V120', 'C8', 'V135', 'V149', 'V151', 'V162', 'V206', 'V225', 'V239', 'V254', 'V255', 'V257', 'V283', 'V287', 'V317', 'id_20']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 2/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8045\n",
      "Individual 1/30: Fitness = 0.8045\n",
      "Feature subset evaluated: ROC AUC = 0.8015\n",
      "Individual 2/30: Fitness = 0.8015\n",
      "Feature subset evaluated: ROC AUC = 0.7967\n",
      "Individual 3/30: Fitness = 0.7967\n",
      "Feature subset evaluated: ROC AUC = 0.7960\n",
      "Individual 4/30: Fitness = 0.7960\n",
      "Feature subset evaluated: ROC AUC = 0.7936\n",
      "Individual 5/30: Fitness = 0.7936\n",
      "Feature subset evaluated: ROC AUC = 0.7929\n",
      "Individual 6/30: Fitness = 0.7929\n",
      "Feature subset evaluated: ROC AUC = 0.7927\n",
      "Individual 7/30: Fitness = 0.7927\n",
      "Feature subset evaluated: ROC AUC = 0.7914\n",
      "Individual 8/30: Fitness = 0.7914\n",
      "Feature subset evaluated: ROC AUC = 0.7905\n",
      "Individual 9/30: Fitness = 0.7905\n",
      "Feature subset evaluated: ROC AUC = 0.7867\n",
      "Individual 10/30: Fitness = 0.7867\n",
      "Feature subset evaluated: ROC AUC = 0.7866\n",
      "Individual 11/30: Fitness = 0.7866\n",
      "Feature subset evaluated: ROC AUC = 0.7860\n",
      "Individual 12/30: Fitness = 0.7860\n",
      "Feature subset evaluated: ROC AUC = 0.7859\n",
      "Individual 13/30: Fitness = 0.7859\n",
      "Feature subset evaluated: ROC AUC = 0.7852\n",
      "Individual 14/30: Fitness = 0.7852\n",
      "Feature subset evaluated: ROC AUC = 0.7848\n",
      "Individual 15/30: Fitness = 0.7848\n",
      "Feature subset evaluated: ROC AUC = 0.7933\n",
      "Individual 16/30: Fitness = 0.7933\n",
      "Feature subset evaluated: ROC AUC = 0.8061\n",
      "Individual 17/30: Fitness = 0.8061\n",
      "Feature subset evaluated: ROC AUC = 0.7778\n",
      "Individual 18/30: Fitness = 0.7778\n",
      "Feature subset evaluated: ROC AUC = 0.8063\n",
      "Individual 19/30: Fitness = 0.8063\n",
      "Feature subset evaluated: ROC AUC = 0.8043\n",
      "Individual 20/30: Fitness = 0.8043\n",
      "Feature subset evaluated: ROC AUC = 0.7817\n",
      "Individual 21/30: Fitness = 0.7817\n",
      "Feature subset evaluated: ROC AUC = 0.7734\n",
      "Individual 22/30: Fitness = 0.7734\n",
      "Feature subset evaluated: ROC AUC = 0.8045\n",
      "Individual 23/30: Fitness = 0.8045\n",
      "Feature subset evaluated: ROC AUC = 0.7843\n",
      "Individual 24/30: Fitness = 0.7843\n",
      "Feature subset evaluated: ROC AUC = 0.7975\n",
      "Individual 25/30: Fitness = 0.7975\n",
      "Feature subset evaluated: ROC AUC = 0.7969\n",
      "Individual 26/30: Fitness = 0.7969\n",
      "Feature subset evaluated: ROC AUC = 0.7890\n",
      "Individual 27/30: Fitness = 0.7890\n",
      "Feature subset evaluated: ROC AUC = 0.8035\n",
      "Individual 28/30: Fitness = 0.8035\n",
      "Feature subset evaluated: ROC AUC = 0.8029\n",
      "Individual 29/30: Fitness = 0.8029\n",
      "Feature subset evaluated: ROC AUC = 0.7972\n",
      "Individual 30/30: Fitness = 0.7972\n",
      "\n",
      "Best fitness in generation 2: 0.8063\n",
      "Current best features: ['V63', 'M5', 'V53', 'id_18', 'id_27', 'V175', 'V8', 'V79', 'V250', 'V108', 'V58', 'V33', 'V70', 'V40', 'M6', 'V123', 'V120', 'C8', 'V38', 'V151', 'V162', 'V225', 'V256', 'V257', 'V283', 'V287', 'V290', 'V294', 'V303', 'id_20']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 3/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8063\n",
      "Individual 1/30: Fitness = 0.8063\n",
      "Feature subset evaluated: ROC AUC = 0.8061\n",
      "Individual 2/30: Fitness = 0.8061\n",
      "Feature subset evaluated: ROC AUC = 0.8045\n",
      "Individual 3/30: Fitness = 0.8045\n",
      "Feature subset evaluated: ROC AUC = 0.8045\n",
      "Individual 4/30: Fitness = 0.8045\n",
      "Feature subset evaluated: ROC AUC = 0.8043\n",
      "Individual 5/30: Fitness = 0.8043\n",
      "Feature subset evaluated: ROC AUC = 0.8035\n",
      "Individual 6/30: Fitness = 0.8035\n",
      "Feature subset evaluated: ROC AUC = 0.8029\n",
      "Individual 7/30: Fitness = 0.8029\n",
      "Feature subset evaluated: ROC AUC = 0.8015\n",
      "Individual 8/30: Fitness = 0.8015\n",
      "Feature subset evaluated: ROC AUC = 0.7975\n",
      "Individual 9/30: Fitness = 0.7975\n",
      "Feature subset evaluated: ROC AUC = 0.7972\n",
      "Individual 10/30: Fitness = 0.7972\n",
      "Feature subset evaluated: ROC AUC = 0.7969\n",
      "Individual 11/30: Fitness = 0.7969\n",
      "Feature subset evaluated: ROC AUC = 0.7967\n",
      "Individual 12/30: Fitness = 0.7967\n",
      "Feature subset evaluated: ROC AUC = 0.7960\n",
      "Individual 13/30: Fitness = 0.7960\n",
      "Feature subset evaluated: ROC AUC = 0.7936\n",
      "Individual 14/30: Fitness = 0.7936\n",
      "Feature subset evaluated: ROC AUC = 0.7933\n",
      "Individual 15/30: Fitness = 0.7933\n",
      "Feature subset evaluated: ROC AUC = 0.7944\n",
      "Individual 16/30: Fitness = 0.7944\n",
      "Feature subset evaluated: ROC AUC = 0.7996\n",
      "Individual 17/30: Fitness = 0.7996\n",
      "Feature subset evaluated: ROC AUC = 0.7962\n",
      "Individual 18/30: Fitness = 0.7962\n",
      "Feature subset evaluated: ROC AUC = 0.7929\n",
      "Individual 19/30: Fitness = 0.7929\n",
      "Feature subset evaluated: ROC AUC = 0.8003\n",
      "Individual 20/30: Fitness = 0.8003\n",
      "Feature subset evaluated: ROC AUC = 0.7740\n",
      "Individual 21/30: Fitness = 0.7740\n",
      "Feature subset evaluated: ROC AUC = 0.7962\n",
      "Individual 22/30: Fitness = 0.7962\n",
      "Feature subset evaluated: ROC AUC = 0.7943\n",
      "Individual 23/30: Fitness = 0.7943\n",
      "Feature subset evaluated: ROC AUC = 0.7895\n",
      "Individual 24/30: Fitness = 0.7895\n",
      "Feature subset evaluated: ROC AUC = 0.7975\n",
      "Individual 25/30: Fitness = 0.7975\n",
      "Feature subset evaluated: ROC AUC = 0.7984\n",
      "Individual 26/30: Fitness = 0.7984\n",
      "Feature subset evaluated: ROC AUC = 0.8016\n",
      "Individual 27/30: Fitness = 0.8016\n",
      "Feature subset evaluated: ROC AUC = 0.7976\n",
      "Individual 28/30: Fitness = 0.7976\n",
      "Feature subset evaluated: ROC AUC = 0.7849\n",
      "Individual 29/30: Fitness = 0.7849\n",
      "Feature subset evaluated: ROC AUC = 0.7995\n",
      "Individual 30/30: Fitness = 0.7995\n",
      "\n",
      "Best fitness in generation 3: 0.8063\n",
      "Current best features: ['V63', 'M5', 'V53', 'id_18', 'id_27', 'V175', 'V8', 'V79', 'V250', 'V108', 'V58', 'V33', 'V70', 'V40', 'M6', 'V123', 'V120', 'C8', 'V38', 'V151', 'V162', 'V225', 'V256', 'V257', 'V283', 'V287', 'V290', 'V294', 'V303', 'id_20']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 4/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8063\n",
      "Individual 1/30: Fitness = 0.8063\n",
      "Feature subset evaluated: ROC AUC = 0.8061\n",
      "Individual 2/30: Fitness = 0.8061\n",
      "Feature subset evaluated: ROC AUC = 0.8045\n",
      "Individual 3/30: Fitness = 0.8045\n",
      "Feature subset evaluated: ROC AUC = 0.8045\n",
      "Individual 4/30: Fitness = 0.8045\n",
      "Feature subset evaluated: ROC AUC = 0.8043\n",
      "Individual 5/30: Fitness = 0.8043\n",
      "Feature subset evaluated: ROC AUC = 0.8035\n",
      "Individual 6/30: Fitness = 0.8035\n",
      "Feature subset evaluated: ROC AUC = 0.8029\n",
      "Individual 7/30: Fitness = 0.8029\n",
      "Feature subset evaluated: ROC AUC = 0.8016\n",
      "Individual 8/30: Fitness = 0.8016\n",
      "Feature subset evaluated: ROC AUC = 0.8015\n",
      "Individual 9/30: Fitness = 0.8015\n",
      "Feature subset evaluated: ROC AUC = 0.8003\n",
      "Individual 10/30: Fitness = 0.8003\n",
      "Feature subset evaluated: ROC AUC = 0.7996\n",
      "Individual 11/30: Fitness = 0.7996\n",
      "Feature subset evaluated: ROC AUC = 0.7995\n",
      "Individual 12/30: Fitness = 0.7995\n",
      "Feature subset evaluated: ROC AUC = 0.7984\n",
      "Individual 13/30: Fitness = 0.7984\n",
      "Feature subset evaluated: ROC AUC = 0.7976\n",
      "Individual 14/30: Fitness = 0.7976\n",
      "Feature subset evaluated: ROC AUC = 0.7975\n",
      "Individual 15/30: Fitness = 0.7975\n",
      "Feature subset evaluated: ROC AUC = 0.8115\n",
      "Individual 16/30: Fitness = 0.8115\n",
      "Feature subset evaluated: ROC AUC = 0.8098\n",
      "Individual 17/30: Fitness = 0.8098\n",
      "Feature subset evaluated: ROC AUC = 0.7996\n",
      "Individual 18/30: Fitness = 0.7996\n",
      "Feature subset evaluated: ROC AUC = 0.7995\n",
      "Individual 19/30: Fitness = 0.7995\n",
      "Feature subset evaluated: ROC AUC = 0.7915\n",
      "Individual 20/30: Fitness = 0.7915\n",
      "Feature subset evaluated: ROC AUC = 0.8008\n",
      "Individual 21/30: Fitness = 0.8008\n",
      "Feature subset evaluated: ROC AUC = 0.7792\n",
      "Individual 22/30: Fitness = 0.7792\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 23/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.7957\n",
      "Individual 24/30: Fitness = 0.7957\n",
      "Feature subset evaluated: ROC AUC = 0.7918\n",
      "Individual 25/30: Fitness = 0.7918\n",
      "Feature subset evaluated: ROC AUC = 0.7708\n",
      "Individual 26/30: Fitness = 0.7708\n",
      "Feature subset evaluated: ROC AUC = 0.8100\n",
      "Individual 27/30: Fitness = 0.8100\n",
      "Feature subset evaluated: ROC AUC = 0.8029\n",
      "Individual 28/30: Fitness = 0.8029\n",
      "Feature subset evaluated: ROC AUC = 0.8005\n",
      "Individual 29/30: Fitness = 0.8005\n",
      "Feature subset evaluated: ROC AUC = 0.7952\n",
      "Individual 30/30: Fitness = 0.7952\n",
      "\n",
      "Best fitness in generation 4: 0.8115\n",
      "Current best features: ['V75', 'V141', 'V15', 'id_32', 'V113', 'V61', 'id_28', 'V49', 'V58', 'V17', 'V154', 'M6', 'V2', 'card6', 'V135', 'V148', 'V151', 'V166', 'V230', 'V239', 'V254', 'V255', 'V257', 'V283', 'V292', 'V307', 'V315', 'V317', 'id_17', 'id_20']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 5/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8115\n",
      "Individual 1/30: Fitness = 0.8115\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 2/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8100\n",
      "Individual 3/30: Fitness = 0.8100\n",
      "Feature subset evaluated: ROC AUC = 0.8098\n",
      "Individual 4/30: Fitness = 0.8098\n",
      "Feature subset evaluated: ROC AUC = 0.8063\n",
      "Individual 5/30: Fitness = 0.8063\n",
      "Feature subset evaluated: ROC AUC = 0.8061\n",
      "Individual 6/30: Fitness = 0.8061\n",
      "Feature subset evaluated: ROC AUC = 0.8045\n",
      "Individual 7/30: Fitness = 0.8045\n",
      "Feature subset evaluated: ROC AUC = 0.8045\n",
      "Individual 8/30: Fitness = 0.8045\n",
      "Feature subset evaluated: ROC AUC = 0.8043\n",
      "Individual 9/30: Fitness = 0.8043\n",
      "Feature subset evaluated: ROC AUC = 0.8035\n",
      "Individual 10/30: Fitness = 0.8035\n",
      "Feature subset evaluated: ROC AUC = 0.8029\n",
      "Individual 11/30: Fitness = 0.8029\n",
      "Feature subset evaluated: ROC AUC = 0.8029\n",
      "Individual 12/30: Fitness = 0.8029\n",
      "Feature subset evaluated: ROC AUC = 0.8016\n",
      "Individual 13/30: Fitness = 0.8016\n",
      "Feature subset evaluated: ROC AUC = 0.8015\n",
      "Individual 14/30: Fitness = 0.8015\n",
      "Feature subset evaluated: ROC AUC = 0.8008\n",
      "Individual 15/30: Fitness = 0.8008\n",
      "Feature subset evaluated: ROC AUC = 0.8103\n",
      "Individual 16/30: Fitness = 0.8103\n",
      "Feature subset evaluated: ROC AUC = 0.8034\n",
      "Individual 17/30: Fitness = 0.8034\n",
      "Feature subset evaluated: ROC AUC = 0.8003\n",
      "Individual 18/30: Fitness = 0.8003\n",
      "Feature subset evaluated: ROC AUC = 0.7982\n",
      "Individual 19/30: Fitness = 0.7982\n",
      "Feature subset evaluated: ROC AUC = 0.7999\n",
      "Individual 20/30: Fitness = 0.7999\n",
      "Feature subset evaluated: ROC AUC = 0.8060\n",
      "Individual 21/30: Fitness = 0.8060\n",
      "Feature subset evaluated: ROC AUC = 0.7954\n",
      "Individual 22/30: Fitness = 0.7954\n",
      "Feature subset evaluated: ROC AUC = 0.8029\n",
      "Individual 23/30: Fitness = 0.8029\n",
      "Feature subset evaluated: ROC AUC = 0.8081\n",
      "Individual 24/30: Fitness = 0.8081\n",
      "Feature subset evaluated: ROC AUC = 0.7936\n",
      "Individual 25/30: Fitness = 0.7936\n",
      "Feature subset evaluated: ROC AUC = 0.8061\n",
      "Individual 26/30: Fitness = 0.8061\n",
      "Feature subset evaluated: ROC AUC = 0.7937\n",
      "Individual 27/30: Fitness = 0.7937\n",
      "Feature subset evaluated: ROC AUC = 0.8084\n",
      "Individual 28/30: Fitness = 0.8084\n",
      "Feature subset evaluated: ROC AUC = 0.8063\n",
      "Individual 29/30: Fitness = 0.8063\n",
      "Feature subset evaluated: ROC AUC = 0.8067\n",
      "Individual 30/30: Fitness = 0.8067\n",
      "\n",
      "Best fitness in generation 5: 0.8115\n",
      "Current best features: ['V75', 'V141', 'V15', 'id_32', 'V113', 'V61', 'id_28', 'V49', 'V58', 'V17', 'V154', 'M6', 'V2', 'card6', 'V135', 'V148', 'V151', 'V166', 'V230', 'V239', 'V254', 'V255', 'V257', 'V283', 'V292', 'V307', 'V315', 'V317', 'id_17', 'id_20']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 6/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8115\n",
      "Individual 1/30: Fitness = 0.8115\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 2/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8103\n",
      "Individual 3/30: Fitness = 0.8103\n",
      "Feature subset evaluated: ROC AUC = 0.8100\n",
      "Individual 4/30: Fitness = 0.8100\n",
      "Feature subset evaluated: ROC AUC = 0.8098\n",
      "Individual 5/30: Fitness = 0.8098\n",
      "Feature subset evaluated: ROC AUC = 0.8084\n",
      "Individual 6/30: Fitness = 0.8084\n",
      "Feature subset evaluated: ROC AUC = 0.8081\n",
      "Individual 7/30: Fitness = 0.8081\n",
      "Feature subset evaluated: ROC AUC = 0.8067\n",
      "Individual 8/30: Fitness = 0.8067\n",
      "Feature subset evaluated: ROC AUC = 0.8063\n",
      "Individual 9/30: Fitness = 0.8063\n",
      "Feature subset evaluated: ROC AUC = 0.8063\n",
      "Individual 10/30: Fitness = 0.8063\n",
      "Feature subset evaluated: ROC AUC = 0.8061\n",
      "Individual 11/30: Fitness = 0.8061\n",
      "Feature subset evaluated: ROC AUC = 0.8061\n",
      "Individual 12/30: Fitness = 0.8061\n",
      "Feature subset evaluated: ROC AUC = 0.8060\n",
      "Individual 13/30: Fitness = 0.8060\n",
      "Feature subset evaluated: ROC AUC = 0.8045\n",
      "Individual 14/30: Fitness = 0.8045\n",
      "Feature subset evaluated: ROC AUC = 0.8045\n",
      "Individual 15/30: Fitness = 0.8045\n",
      "Feature subset evaluated: ROC AUC = 0.8081\n",
      "Individual 16/30: Fitness = 0.8081\n",
      "Feature subset evaluated: ROC AUC = 0.7869\n",
      "Individual 17/30: Fitness = 0.7869\n",
      "Feature subset evaluated: ROC AUC = 0.7929\n",
      "Individual 18/30: Fitness = 0.7929\n",
      "Feature subset evaluated: ROC AUC = 0.8051\n",
      "Individual 19/30: Fitness = 0.8051\n",
      "Feature subset evaluated: ROC AUC = 0.8038\n",
      "Individual 20/30: Fitness = 0.8038\n",
      "Feature subset evaluated: ROC AUC = 0.8095\n",
      "Individual 21/30: Fitness = 0.8095\n",
      "Feature subset evaluated: ROC AUC = 0.7995\n",
      "Individual 22/30: Fitness = 0.7995\n",
      "Feature subset evaluated: ROC AUC = 0.8047\n",
      "Individual 23/30: Fitness = 0.8047\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 24/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8015\n",
      "Individual 25/30: Fitness = 0.8015\n",
      "Feature subset evaluated: ROC AUC = 0.8118\n",
      "Individual 26/30: Fitness = 0.8118\n",
      "Feature subset evaluated: ROC AUC = 0.7958\n",
      "Individual 27/30: Fitness = 0.7958\n",
      "Feature subset evaluated: ROC AUC = 0.7888\n",
      "Individual 28/30: Fitness = 0.7888\n",
      "Feature subset evaluated: ROC AUC = 0.7979\n",
      "Individual 29/30: Fitness = 0.7979\n",
      "Feature subset evaluated: ROC AUC = 0.7903\n",
      "Individual 30/30: Fitness = 0.7903\n",
      "\n",
      "Best fitness in generation 6: 0.8118\n",
      "Current best features: ['V75', 'V84', 'V69', 'V42', 'V3', 'V328', 'V51', 'V195', 'V58', 'V116', 'V72', 'V70', 'V14', 'V123', 'card6', 'C7', 'C12', 'D5', 'V127', 'V132', 'V136', 'V166', 'V180', 'V236', 'V242', 'V252', 'V283', 'V315', 'id_17', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 7/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8118\n",
      "Individual 1/30: Fitness = 0.8118\n",
      "Feature subset evaluated: ROC AUC = 0.8115\n",
      "Individual 2/30: Fitness = 0.8115\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 3/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 4/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8103\n",
      "Individual 5/30: Fitness = 0.8103\n",
      "Feature subset evaluated: ROC AUC = 0.8100\n",
      "Individual 6/30: Fitness = 0.8100\n",
      "Feature subset evaluated: ROC AUC = 0.8098\n",
      "Individual 7/30: Fitness = 0.8098\n",
      "Feature subset evaluated: ROC AUC = 0.8095\n",
      "Individual 8/30: Fitness = 0.8095\n",
      "Feature subset evaluated: ROC AUC = 0.8084\n",
      "Individual 9/30: Fitness = 0.8084\n",
      "Feature subset evaluated: ROC AUC = 0.8081\n",
      "Individual 10/30: Fitness = 0.8081\n",
      "Feature subset evaluated: ROC AUC = 0.8081\n",
      "Individual 11/30: Fitness = 0.8081\n",
      "Feature subset evaluated: ROC AUC = 0.8067\n",
      "Individual 12/30: Fitness = 0.8067\n",
      "Feature subset evaluated: ROC AUC = 0.8063\n",
      "Individual 13/30: Fitness = 0.8063\n",
      "Feature subset evaluated: ROC AUC = 0.8063\n",
      "Individual 14/30: Fitness = 0.8063\n",
      "Feature subset evaluated: ROC AUC = 0.8061\n",
      "Individual 15/30: Fitness = 0.8061\n",
      "Feature subset evaluated: ROC AUC = 0.8118\n",
      "Individual 16/30: Fitness = 0.8118\n",
      "Feature subset evaluated: ROC AUC = 0.7972\n",
      "Individual 17/30: Fitness = 0.7972\n",
      "Feature subset evaluated: ROC AUC = 0.7964\n",
      "Individual 18/30: Fitness = 0.7964\n",
      "Feature subset evaluated: ROC AUC = 0.7932\n",
      "Individual 19/30: Fitness = 0.7932\n",
      "Feature subset evaluated: ROC AUC = 0.8053\n",
      "Individual 20/30: Fitness = 0.8053\n",
      "Feature subset evaluated: ROC AUC = 0.8081\n",
      "Individual 21/30: Fitness = 0.8081\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 22/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 23/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.7944\n",
      "Individual 24/30: Fitness = 0.7944\n",
      "Feature subset evaluated: ROC AUC = 0.8064\n",
      "Individual 25/30: Fitness = 0.8064\n",
      "Feature subset evaluated: ROC AUC = 0.8055\n",
      "Individual 26/30: Fitness = 0.8055\n",
      "Feature subset evaluated: ROC AUC = 0.8027\n",
      "Individual 27/30: Fitness = 0.8027\n",
      "Feature subset evaluated: ROC AUC = 0.8114\n",
      "Individual 28/30: Fitness = 0.8114\n",
      "Feature subset evaluated: ROC AUC = 0.8014\n",
      "Individual 29/30: Fitness = 0.8014\n",
      "Feature subset evaluated: ROC AUC = 0.7886\n",
      "Individual 30/30: Fitness = 0.7886\n",
      "\n",
      "Best fitness in generation 7: 0.8199\n",
      "Current best features: ['V75', 'V42', 'M5', 'V53', 'V8', 'V113', 'V119', 'V33', 'id_31', 'V70', 'V40', 'V60', 'card6', 'V77', 'V127', 'V148', 'V151', 'V162', 'V236', 'V257', 'V259', 'V267', 'V283', 'V290', 'V294', 'V307', 'V310', 'V329', 'id_11', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 8/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 1/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8118\n",
      "Individual 2/30: Fitness = 0.8118\n",
      "Feature subset evaluated: ROC AUC = 0.8118\n",
      "Individual 3/30: Fitness = 0.8118\n",
      "Feature subset evaluated: ROC AUC = 0.8115\n",
      "Individual 4/30: Fitness = 0.8115\n",
      "Feature subset evaluated: ROC AUC = 0.8114\n",
      "Individual 5/30: Fitness = 0.8114\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 6/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 7/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 8/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8103\n",
      "Individual 9/30: Fitness = 0.8103\n",
      "Feature subset evaluated: ROC AUC = 0.8100\n",
      "Individual 10/30: Fitness = 0.8100\n",
      "Feature subset evaluated: ROC AUC = 0.8098\n",
      "Individual 11/30: Fitness = 0.8098\n",
      "Feature subset evaluated: ROC AUC = 0.8095\n",
      "Individual 12/30: Fitness = 0.8095\n",
      "Feature subset evaluated: ROC AUC = 0.8084\n",
      "Individual 13/30: Fitness = 0.8084\n",
      "Feature subset evaluated: ROC AUC = 0.8081\n",
      "Individual 14/30: Fitness = 0.8081\n",
      "Feature subset evaluated: ROC AUC = 0.8081\n",
      "Individual 15/30: Fitness = 0.8081\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 16/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8147\n",
      "Individual 17/30: Fitness = 0.8147\n",
      "Feature subset evaluated: ROC AUC = 0.8135\n",
      "Individual 18/30: Fitness = 0.8135\n",
      "Feature subset evaluated: ROC AUC = 0.8096\n",
      "Individual 19/30: Fitness = 0.8096\n",
      "Feature subset evaluated: ROC AUC = 0.8063\n",
      "Individual 20/30: Fitness = 0.8063\n",
      "Feature subset evaluated: ROC AUC = 0.8029\n",
      "Individual 21/30: Fitness = 0.8029\n",
      "Feature subset evaluated: ROC AUC = 0.8159\n",
      "Individual 22/30: Fitness = 0.8159\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 23/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8021\n",
      "Individual 24/30: Fitness = 0.8021\n",
      "Feature subset evaluated: ROC AUC = 0.7939\n",
      "Individual 25/30: Fitness = 0.7939\n",
      "Feature subset evaluated: ROC AUC = 0.7875\n",
      "Individual 26/30: Fitness = 0.7875\n",
      "Feature subset evaluated: ROC AUC = 0.8081\n",
      "Individual 27/30: Fitness = 0.8081\n",
      "Feature subset evaluated: ROC AUC = 0.8071\n",
      "Individual 28/30: Fitness = 0.8071\n",
      "Feature subset evaluated: ROC AUC = 0.7941\n",
      "Individual 29/30: Fitness = 0.7941\n",
      "Feature subset evaluated: ROC AUC = 0.8058\n",
      "Individual 30/30: Fitness = 0.8058\n",
      "\n",
      "Best fitness in generation 8: 0.8199\n",
      "Current best features: ['V75', 'V42', 'M5', 'V53', 'V8', 'V113', 'V119', 'V33', 'id_31', 'V70', 'V40', 'V60', 'card6', 'V77', 'V127', 'V148', 'V151', 'V162', 'V236', 'V257', 'V259', 'V267', 'V283', 'V290', 'V294', 'V307', 'V310', 'V329', 'id_11', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 9/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 1/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8159\n",
      "Individual 2/30: Fitness = 0.8159\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 3/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8147\n",
      "Individual 4/30: Fitness = 0.8147\n",
      "Feature subset evaluated: ROC AUC = 0.8135\n",
      "Individual 5/30: Fitness = 0.8135\n",
      "Feature subset evaluated: ROC AUC = 0.8118\n",
      "Individual 6/30: Fitness = 0.8118\n",
      "Feature subset evaluated: ROC AUC = 0.8118\n",
      "Individual 7/30: Fitness = 0.8118\n",
      "Feature subset evaluated: ROC AUC = 0.8115\n",
      "Individual 8/30: Fitness = 0.8115\n",
      "Feature subset evaluated: ROC AUC = 0.8114\n",
      "Individual 9/30: Fitness = 0.8114\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 10/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 11/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 12/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 13/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8103\n",
      "Individual 14/30: Fitness = 0.8103\n",
      "Feature subset evaluated: ROC AUC = 0.8100\n",
      "Individual 15/30: Fitness = 0.8100\n",
      "Feature subset evaluated: ROC AUC = 0.8161\n",
      "Individual 16/30: Fitness = 0.8161\n",
      "Feature subset evaluated: ROC AUC = 0.7964\n",
      "Individual 17/30: Fitness = 0.7964\n",
      "Feature subset evaluated: ROC AUC = 0.8101\n",
      "Individual 18/30: Fitness = 0.8101\n",
      "Feature subset evaluated: ROC AUC = 0.8035\n",
      "Individual 19/30: Fitness = 0.8035\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 20/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.7795\n",
      "Individual 21/30: Fitness = 0.7795\n",
      "Feature subset evaluated: ROC AUC = 0.8063\n",
      "Individual 22/30: Fitness = 0.8063\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 23/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8070\n",
      "Individual 24/30: Fitness = 0.8070\n",
      "Feature subset evaluated: ROC AUC = 0.8101\n",
      "Individual 25/30: Fitness = 0.8101\n",
      "Feature subset evaluated: ROC AUC = 0.8020\n",
      "Individual 26/30: Fitness = 0.8020\n",
      "Feature subset evaluated: ROC AUC = 0.8036\n",
      "Individual 27/30: Fitness = 0.8036\n",
      "Feature subset evaluated: ROC AUC = 0.8025\n",
      "Individual 28/30: Fitness = 0.8025\n",
      "Feature subset evaluated: ROC AUC = 0.8114\n",
      "Individual 29/30: Fitness = 0.8114\n",
      "Feature subset evaluated: ROC AUC = 0.7953\n",
      "Individual 30/30: Fitness = 0.7953\n",
      "\n",
      "Best fitness in generation 9: 0.8199\n",
      "Current best features: ['V75', 'V42', 'M5', 'V53', 'V8', 'V113', 'V119', 'V33', 'id_31', 'V70', 'V40', 'V60', 'card6', 'V77', 'V127', 'V148', 'V151', 'V162', 'V236', 'V257', 'V259', 'V267', 'V283', 'V290', 'V294', 'V307', 'V310', 'V329', 'id_11', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 10/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 1/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 2/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8161\n",
      "Individual 3/30: Fitness = 0.8161\n",
      "Feature subset evaluated: ROC AUC = 0.8159\n",
      "Individual 4/30: Fitness = 0.8159\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 5/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8147\n",
      "Individual 6/30: Fitness = 0.8147\n",
      "Feature subset evaluated: ROC AUC = 0.8135\n",
      "Individual 7/30: Fitness = 0.8135\n",
      "Feature subset evaluated: ROC AUC = 0.8118\n",
      "Individual 8/30: Fitness = 0.8118\n",
      "Feature subset evaluated: ROC AUC = 0.8118\n",
      "Individual 9/30: Fitness = 0.8118\n",
      "Feature subset evaluated: ROC AUC = 0.8115\n",
      "Individual 10/30: Fitness = 0.8115\n",
      "Feature subset evaluated: ROC AUC = 0.8114\n",
      "Individual 11/30: Fitness = 0.8114\n",
      "Feature subset evaluated: ROC AUC = 0.8114\n",
      "Individual 12/30: Fitness = 0.8114\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 13/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 14/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 15/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.7818\n",
      "Individual 16/30: Fitness = 0.7818\n",
      "Feature subset evaluated: ROC AUC = 0.8084\n",
      "Individual 17/30: Fitness = 0.8084\n",
      "Feature subset evaluated: ROC AUC = 0.7882\n",
      "Individual 18/30: Fitness = 0.7882\n",
      "Feature subset evaluated: ROC AUC = 0.7932\n",
      "Individual 19/30: Fitness = 0.7932\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 20/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8049\n",
      "Individual 21/30: Fitness = 0.8049\n",
      "Feature subset evaluated: ROC AUC = 0.7925\n",
      "Individual 22/30: Fitness = 0.7925\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 23/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.7916\n",
      "Individual 24/30: Fitness = 0.7916\n",
      "Feature subset evaluated: ROC AUC = 0.8068\n",
      "Individual 25/30: Fitness = 0.8068\n",
      "Feature subset evaluated: ROC AUC = 0.7948\n",
      "Individual 26/30: Fitness = 0.7948\n",
      "Feature subset evaluated: ROC AUC = 0.7976\n",
      "Individual 27/30: Fitness = 0.7976\n",
      "Feature subset evaluated: ROC AUC = 0.8078\n",
      "Individual 28/30: Fitness = 0.8078\n",
      "Feature subset evaluated: ROC AUC = 0.8022\n",
      "Individual 29/30: Fitness = 0.8022\n",
      "Feature subset evaluated: ROC AUC = 0.8095\n",
      "Individual 30/30: Fitness = 0.8095\n",
      "\n",
      "Best fitness in generation 10: 0.8199\n",
      "Current best features: ['V75', 'V42', 'M5', 'V53', 'V8', 'V113', 'V119', 'V33', 'id_31', 'V70', 'V40', 'V60', 'card6', 'V77', 'V127', 'V148', 'V151', 'V162', 'V236', 'V257', 'V259', 'V267', 'V283', 'V290', 'V294', 'V307', 'V310', 'V329', 'id_11', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 11/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 1/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 2/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 3/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8161\n",
      "Individual 4/30: Fitness = 0.8161\n",
      "Feature subset evaluated: ROC AUC = 0.8159\n",
      "Individual 5/30: Fitness = 0.8159\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 6/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8147\n",
      "Individual 7/30: Fitness = 0.8147\n",
      "Feature subset evaluated: ROC AUC = 0.8135\n",
      "Individual 8/30: Fitness = 0.8135\n",
      "Feature subset evaluated: ROC AUC = 0.8118\n",
      "Individual 9/30: Fitness = 0.8118\n",
      "Feature subset evaluated: ROC AUC = 0.8118\n",
      "Individual 10/30: Fitness = 0.8118\n",
      "Feature subset evaluated: ROC AUC = 0.8115\n",
      "Individual 11/30: Fitness = 0.8115\n",
      "Feature subset evaluated: ROC AUC = 0.8114\n",
      "Individual 12/30: Fitness = 0.8114\n",
      "Feature subset evaluated: ROC AUC = 0.8114\n",
      "Individual 13/30: Fitness = 0.8114\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 14/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 15/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 16/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8096\n",
      "Individual 17/30: Fitness = 0.8096\n",
      "Feature subset evaluated: ROC AUC = 0.7952\n",
      "Individual 18/30: Fitness = 0.7952\n",
      "Feature subset evaluated: ROC AUC = 0.8151\n",
      "Individual 19/30: Fitness = 0.8151\n",
      "Feature subset evaluated: ROC AUC = 0.7940\n",
      "Individual 20/30: Fitness = 0.7940\n",
      "Feature subset evaluated: ROC AUC = 0.8045\n",
      "Individual 21/30: Fitness = 0.8045\n",
      "Feature subset evaluated: ROC AUC = 0.8062\n",
      "Individual 22/30: Fitness = 0.8062\n",
      "Feature subset evaluated: ROC AUC = 0.7962\n",
      "Individual 23/30: Fitness = 0.7962\n",
      "Feature subset evaluated: ROC AUC = 0.7952\n",
      "Individual 24/30: Fitness = 0.7952\n",
      "Feature subset evaluated: ROC AUC = 0.8054\n",
      "Individual 25/30: Fitness = 0.8054\n",
      "Feature subset evaluated: ROC AUC = 0.8153\n",
      "Individual 26/30: Fitness = 0.8153\n",
      "Feature subset evaluated: ROC AUC = 0.8107\n",
      "Individual 27/30: Fitness = 0.8107\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 28/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8036\n",
      "Individual 29/30: Fitness = 0.8036\n",
      "Feature subset evaluated: ROC AUC = 0.7761\n",
      "Individual 30/30: Fitness = 0.7761\n",
      "\n",
      "Best fitness in generation 11: 0.8199\n",
      "Current best features: ['V75', 'V42', 'M5', 'V53', 'V8', 'V113', 'V119', 'V33', 'id_31', 'V70', 'V40', 'V60', 'card6', 'V77', 'V127', 'V148', 'V151', 'V162', 'V236', 'V257', 'V259', 'V267', 'V283', 'V290', 'V294', 'V307', 'V310', 'V329', 'id_11', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 12/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 1/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 2/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 3/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 4/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8161\n",
      "Individual 5/30: Fitness = 0.8161\n",
      "Feature subset evaluated: ROC AUC = 0.8159\n",
      "Individual 6/30: Fitness = 0.8159\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 7/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 8/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8153\n",
      "Individual 9/30: Fitness = 0.8153\n",
      "Feature subset evaluated: ROC AUC = 0.8151\n",
      "Individual 10/30: Fitness = 0.8151\n",
      "Feature subset evaluated: ROC AUC = 0.8147\n",
      "Individual 11/30: Fitness = 0.8147\n",
      "Feature subset evaluated: ROC AUC = 0.8135\n",
      "Individual 12/30: Fitness = 0.8135\n",
      "Feature subset evaluated: ROC AUC = 0.8118\n",
      "Individual 13/30: Fitness = 0.8118\n",
      "Feature subset evaluated: ROC AUC = 0.8118\n",
      "Individual 14/30: Fitness = 0.8118\n",
      "Feature subset evaluated: ROC AUC = 0.8115\n",
      "Individual 15/30: Fitness = 0.8115\n",
      "Feature subset evaluated: ROC AUC = 0.8135\n",
      "Individual 16/30: Fitness = 0.8135\n",
      "Feature subset evaluated: ROC AUC = 0.8066\n",
      "Individual 17/30: Fitness = 0.8066\n",
      "Feature subset evaluated: ROC AUC = 0.8129\n",
      "Individual 18/30: Fitness = 0.8129\n",
      "Feature subset evaluated: ROC AUC = 0.7961\n",
      "Individual 19/30: Fitness = 0.7961\n",
      "Feature subset evaluated: ROC AUC = 0.8115\n",
      "Individual 20/30: Fitness = 0.8115\n",
      "Feature subset evaluated: ROC AUC = 0.8142\n",
      "Individual 21/30: Fitness = 0.8142\n",
      "Feature subset evaluated: ROC AUC = 0.7943\n",
      "Individual 22/30: Fitness = 0.7943\n",
      "Feature subset evaluated: ROC AUC = 0.8122\n",
      "Individual 23/30: Fitness = 0.8122\n",
      "Feature subset evaluated: ROC AUC = 0.7938\n",
      "Individual 24/30: Fitness = 0.7938\n",
      "Feature subset evaluated: ROC AUC = 0.8104\n",
      "Individual 25/30: Fitness = 0.8104\n",
      "Feature subset evaluated: ROC AUC = 0.8086\n",
      "Individual 26/30: Fitness = 0.8086\n",
      "Feature subset evaluated: ROC AUC = 0.8146\n",
      "Individual 27/30: Fitness = 0.8146\n",
      "Feature subset evaluated: ROC AUC = 0.8132\n",
      "Individual 28/30: Fitness = 0.8132\n",
      "Feature subset evaluated: ROC AUC = 0.8054\n",
      "Individual 29/30: Fitness = 0.8054\n",
      "Feature subset evaluated: ROC AUC = 0.8133\n",
      "Individual 30/30: Fitness = 0.8133\n",
      "\n",
      "Best fitness in generation 12: 0.8199\n",
      "Current best features: ['V75', 'V42', 'M5', 'V53', 'V8', 'V113', 'V119', 'V33', 'id_31', 'V70', 'V40', 'V60', 'card6', 'V77', 'V127', 'V148', 'V151', 'V162', 'V236', 'V257', 'V259', 'V267', 'V283', 'V290', 'V294', 'V307', 'V310', 'V329', 'id_11', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 13/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 1/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 2/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 3/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 4/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8161\n",
      "Individual 5/30: Fitness = 0.8161\n",
      "Feature subset evaluated: ROC AUC = 0.8159\n",
      "Individual 6/30: Fitness = 0.8159\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 7/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 8/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8153\n",
      "Individual 9/30: Fitness = 0.8153\n",
      "Feature subset evaluated: ROC AUC = 0.8151\n",
      "Individual 10/30: Fitness = 0.8151\n",
      "Feature subset evaluated: ROC AUC = 0.8147\n",
      "Individual 11/30: Fitness = 0.8147\n",
      "Feature subset evaluated: ROC AUC = 0.8146\n",
      "Individual 12/30: Fitness = 0.8146\n",
      "Feature subset evaluated: ROC AUC = 0.8142\n",
      "Individual 13/30: Fitness = 0.8142\n",
      "Feature subset evaluated: ROC AUC = 0.8135\n",
      "Individual 14/30: Fitness = 0.8135\n",
      "Feature subset evaluated: ROC AUC = 0.8135\n",
      "Individual 15/30: Fitness = 0.8135\n",
      "Feature subset evaluated: ROC AUC = 0.8160\n",
      "Individual 16/30: Fitness = 0.8160\n",
      "Feature subset evaluated: ROC AUC = 0.8130\n",
      "Individual 17/30: Fitness = 0.8130\n",
      "Feature subset evaluated: ROC AUC = 0.8119\n",
      "Individual 18/30: Fitness = 0.8119\n",
      "Feature subset evaluated: ROC AUC = 0.8096\n",
      "Individual 19/30: Fitness = 0.8096\n",
      "Feature subset evaluated: ROC AUC = 0.8112\n",
      "Individual 20/30: Fitness = 0.8112\n",
      "Feature subset evaluated: ROC AUC = 0.8109\n",
      "Individual 21/30: Fitness = 0.8109\n",
      "Feature subset evaluated: ROC AUC = 0.8061\n",
      "Individual 22/30: Fitness = 0.8061\n",
      "Feature subset evaluated: ROC AUC = 0.8172\n",
      "Individual 23/30: Fitness = 0.8172\n",
      "Feature subset evaluated: ROC AUC = 0.7920\n",
      "Individual 24/30: Fitness = 0.7920\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 25/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8132\n",
      "Individual 26/30: Fitness = 0.8132\n",
      "Feature subset evaluated: ROC AUC = 0.8082\n",
      "Individual 27/30: Fitness = 0.8082\n",
      "Feature subset evaluated: ROC AUC = 0.8032\n",
      "Individual 28/30: Fitness = 0.8032\n",
      "Feature subset evaluated: ROC AUC = 0.7985\n",
      "Individual 29/30: Fitness = 0.7985\n",
      "Feature subset evaluated: ROC AUC = 0.8142\n",
      "Individual 30/30: Fitness = 0.8142\n",
      "\n",
      "Best fitness in generation 13: 0.8199\n",
      "Current best features: ['V75', 'V42', 'M5', 'V53', 'V8', 'V113', 'V119', 'V33', 'id_31', 'V70', 'V40', 'V60', 'card6', 'V77', 'V127', 'V148', 'V151', 'V162', 'V236', 'V257', 'V259', 'V267', 'V283', 'V290', 'V294', 'V307', 'V310', 'V329', 'id_11', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 14/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 1/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 2/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8172\n",
      "Individual 3/30: Fitness = 0.8172\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 4/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 5/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8161\n",
      "Individual 6/30: Fitness = 0.8161\n",
      "Feature subset evaluated: ROC AUC = 0.8160\n",
      "Individual 7/30: Fitness = 0.8160\n",
      "Feature subset evaluated: ROC AUC = 0.8159\n",
      "Individual 8/30: Fitness = 0.8159\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 9/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 10/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 11/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8153\n",
      "Individual 12/30: Fitness = 0.8153\n",
      "Feature subset evaluated: ROC AUC = 0.8151\n",
      "Individual 13/30: Fitness = 0.8151\n",
      "Feature subset evaluated: ROC AUC = 0.8147\n",
      "Individual 14/30: Fitness = 0.8147\n",
      "Feature subset evaluated: ROC AUC = 0.8146\n",
      "Individual 15/30: Fitness = 0.8146\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 16/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8115\n",
      "Individual 17/30: Fitness = 0.8115\n",
      "Feature subset evaluated: ROC AUC = 0.8156\n",
      "Individual 18/30: Fitness = 0.8156\n",
      "Feature subset evaluated: ROC AUC = 0.8129\n",
      "Individual 19/30: Fitness = 0.8129\n",
      "Feature subset evaluated: ROC AUC = 0.8148\n",
      "Individual 20/30: Fitness = 0.8148\n",
      "Feature subset evaluated: ROC AUC = 0.7991\n",
      "Individual 21/30: Fitness = 0.7991\n",
      "Feature subset evaluated: ROC AUC = 0.8048\n",
      "Individual 22/30: Fitness = 0.8048\n",
      "Feature subset evaluated: ROC AUC = 0.8042\n",
      "Individual 23/30: Fitness = 0.8042\n",
      "Feature subset evaluated: ROC AUC = 0.8091\n",
      "Individual 24/30: Fitness = 0.8091\n",
      "Feature subset evaluated: ROC AUC = 0.7972\n",
      "Individual 25/30: Fitness = 0.7972\n",
      "Feature subset evaluated: ROC AUC = 0.8109\n",
      "Individual 26/30: Fitness = 0.8109\n",
      "Feature subset evaluated: ROC AUC = 0.7939\n",
      "Individual 27/30: Fitness = 0.7939\n",
      "Feature subset evaluated: ROC AUC = 0.8079\n",
      "Individual 28/30: Fitness = 0.8079\n",
      "Feature subset evaluated: ROC AUC = 0.8188\n",
      "Individual 29/30: Fitness = 0.8188\n",
      "Feature subset evaluated: ROC AUC = 0.8123\n",
      "Individual 30/30: Fitness = 0.8123\n",
      "\n",
      "Best fitness in generation 14: 0.8199\n",
      "Current best features: ['V75', 'V42', 'M5', 'V53', 'V8', 'V113', 'V119', 'V33', 'id_31', 'V70', 'V40', 'V60', 'card6', 'V77', 'V127', 'V148', 'V151', 'V162', 'V236', 'V257', 'V259', 'V267', 'V283', 'V290', 'V294', 'V307', 'V310', 'V329', 'id_11', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 15/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 1/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8188\n",
      "Individual 2/30: Fitness = 0.8188\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 3/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8172\n",
      "Individual 4/30: Fitness = 0.8172\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 5/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 6/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8161\n",
      "Individual 7/30: Fitness = 0.8161\n",
      "Feature subset evaluated: ROC AUC = 0.8160\n",
      "Individual 8/30: Fitness = 0.8160\n",
      "Feature subset evaluated: ROC AUC = 0.8159\n",
      "Individual 9/30: Fitness = 0.8159\n",
      "Feature subset evaluated: ROC AUC = 0.8156\n",
      "Individual 10/30: Fitness = 0.8156\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 11/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 12/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 13/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 14/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8153\n",
      "Individual 15/30: Fitness = 0.8153\n",
      "Feature subset evaluated: ROC AUC = 0.8177\n",
      "Individual 16/30: Fitness = 0.8177\n",
      "Feature subset evaluated: ROC AUC = 0.8166\n",
      "Individual 17/30: Fitness = 0.8166\n",
      "Feature subset evaluated: ROC AUC = 0.8061\n",
      "Individual 18/30: Fitness = 0.8061\n",
      "Feature subset evaluated: ROC AUC = 0.8099\n",
      "Individual 19/30: Fitness = 0.8099\n",
      "Feature subset evaluated: ROC AUC = 0.8116\n",
      "Individual 20/30: Fitness = 0.8116\n",
      "Feature subset evaluated: ROC AUC = 0.8143\n",
      "Individual 21/30: Fitness = 0.8143\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 22/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8054\n",
      "Individual 23/30: Fitness = 0.8054\n",
      "Feature subset evaluated: ROC AUC = 0.8105\n",
      "Individual 24/30: Fitness = 0.8105\n",
      "Feature subset evaluated: ROC AUC = 0.8075\n",
      "Individual 25/30: Fitness = 0.8075\n",
      "Feature subset evaluated: ROC AUC = 0.8103\n",
      "Individual 26/30: Fitness = 0.8103\n",
      "Feature subset evaluated: ROC AUC = 0.8041\n",
      "Individual 27/30: Fitness = 0.8041\n",
      "Feature subset evaluated: ROC AUC = 0.8161\n",
      "Individual 28/30: Fitness = 0.8161\n",
      "Feature subset evaluated: ROC AUC = 0.8132\n",
      "Individual 29/30: Fitness = 0.8132\n",
      "Feature subset evaluated: ROC AUC = 0.8182\n",
      "Individual 30/30: Fitness = 0.8182\n",
      "\n",
      "Best fitness in generation 15: 0.8199\n",
      "Current best features: ['V75', 'V42', 'M5', 'V53', 'V8', 'V113', 'V119', 'V33', 'id_31', 'V70', 'V40', 'V60', 'card6', 'V77', 'V127', 'V148', 'V151', 'V162', 'V236', 'V257', 'V259', 'V267', 'V283', 'V290', 'V294', 'V307', 'V310', 'V329', 'id_11', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 16/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 1/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8188\n",
      "Individual 2/30: Fitness = 0.8188\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 3/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8182\n",
      "Individual 4/30: Fitness = 0.8182\n",
      "Feature subset evaluated: ROC AUC = 0.8177\n",
      "Individual 5/30: Fitness = 0.8177\n",
      "Feature subset evaluated: ROC AUC = 0.8172\n",
      "Individual 6/30: Fitness = 0.8172\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 7/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 8/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8166\n",
      "Individual 9/30: Fitness = 0.8166\n",
      "Feature subset evaluated: ROC AUC = 0.8161\n",
      "Individual 10/30: Fitness = 0.8161\n",
      "Feature subset evaluated: ROC AUC = 0.8161\n",
      "Individual 11/30: Fitness = 0.8161\n",
      "Feature subset evaluated: ROC AUC = 0.8160\n",
      "Individual 12/30: Fitness = 0.8160\n",
      "Feature subset evaluated: ROC AUC = 0.8159\n",
      "Individual 13/30: Fitness = 0.8159\n",
      "Feature subset evaluated: ROC AUC = 0.8156\n",
      "Individual 14/30: Fitness = 0.8156\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 15/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.7976\n",
      "Individual 16/30: Fitness = 0.7976\n",
      "Feature subset evaluated: ROC AUC = 0.8114\n",
      "Individual 17/30: Fitness = 0.8114\n",
      "Feature subset evaluated: ROC AUC = 0.8083\n",
      "Individual 18/30: Fitness = 0.8083\n",
      "Feature subset evaluated: ROC AUC = 0.8074\n",
      "Individual 19/30: Fitness = 0.8074\n",
      "Feature subset evaluated: ROC AUC = 0.8135\n",
      "Individual 20/30: Fitness = 0.8135\n",
      "Feature subset evaluated: ROC AUC = 0.8105\n",
      "Individual 21/30: Fitness = 0.8105\n",
      "Feature subset evaluated: ROC AUC = 0.8078\n",
      "Individual 22/30: Fitness = 0.8078\n",
      "Feature subset evaluated: ROC AUC = 0.7904\n",
      "Individual 23/30: Fitness = 0.7904\n",
      "Feature subset evaluated: ROC AUC = 0.8143\n",
      "Individual 24/30: Fitness = 0.8143\n",
      "Feature subset evaluated: ROC AUC = 0.8116\n",
      "Individual 25/30: Fitness = 0.8116\n",
      "Feature subset evaluated: ROC AUC = 0.8069\n",
      "Individual 26/30: Fitness = 0.8069\n",
      "Feature subset evaluated: ROC AUC = 0.8098\n",
      "Individual 27/30: Fitness = 0.8098\n",
      "Feature subset evaluated: ROC AUC = 0.8098\n",
      "Individual 28/30: Fitness = 0.8098\n",
      "Feature subset evaluated: ROC AUC = 0.8103\n",
      "Individual 29/30: Fitness = 0.8103\n",
      "Feature subset evaluated: ROC AUC = 0.8065\n",
      "Individual 30/30: Fitness = 0.8065\n",
      "\n",
      "Best fitness in generation 16: 0.8199\n",
      "Current best features: ['V75', 'V42', 'M5', 'V53', 'V8', 'V113', 'V119', 'V33', 'id_31', 'V70', 'V40', 'V60', 'card6', 'V77', 'V127', 'V148', 'V151', 'V162', 'V236', 'V257', 'V259', 'V267', 'V283', 'V290', 'V294', 'V307', 'V310', 'V329', 'id_11', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 17/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 1/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8188\n",
      "Individual 2/30: Fitness = 0.8188\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 3/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8182\n",
      "Individual 4/30: Fitness = 0.8182\n",
      "Feature subset evaluated: ROC AUC = 0.8177\n",
      "Individual 5/30: Fitness = 0.8177\n",
      "Feature subset evaluated: ROC AUC = 0.8172\n",
      "Individual 6/30: Fitness = 0.8172\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 7/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 8/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8166\n",
      "Individual 9/30: Fitness = 0.8166\n",
      "Feature subset evaluated: ROC AUC = 0.8161\n",
      "Individual 10/30: Fitness = 0.8161\n",
      "Feature subset evaluated: ROC AUC = 0.8161\n",
      "Individual 11/30: Fitness = 0.8161\n",
      "Feature subset evaluated: ROC AUC = 0.8160\n",
      "Individual 12/30: Fitness = 0.8160\n",
      "Feature subset evaluated: ROC AUC = 0.8159\n",
      "Individual 13/30: Fitness = 0.8159\n",
      "Feature subset evaluated: ROC AUC = 0.8156\n",
      "Individual 14/30: Fitness = 0.8156\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 15/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8140\n",
      "Individual 16/30: Fitness = 0.8140\n",
      "Feature subset evaluated: ROC AUC = 0.8061\n",
      "Individual 17/30: Fitness = 0.8061\n",
      "Feature subset evaluated: ROC AUC = 0.8058\n",
      "Individual 18/30: Fitness = 0.8058\n",
      "Feature subset evaluated: ROC AUC = 0.8154\n",
      "Individual 19/30: Fitness = 0.8154\n",
      "Feature subset evaluated: ROC AUC = 0.8086\n",
      "Individual 20/30: Fitness = 0.8086\n",
      "Feature subset evaluated: ROC AUC = 0.8003\n",
      "Individual 21/30: Fitness = 0.8003\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 22/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.7835\n",
      "Individual 23/30: Fitness = 0.7835\n",
      "Feature subset evaluated: ROC AUC = 0.8073\n",
      "Individual 24/30: Fitness = 0.8073\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 25/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8084\n",
      "Individual 26/30: Fitness = 0.8084\n",
      "Feature subset evaluated: ROC AUC = 0.7972\n",
      "Individual 27/30: Fitness = 0.7972\n",
      "Feature subset evaluated: ROC AUC = 0.8085\n",
      "Individual 28/30: Fitness = 0.8085\n",
      "Feature subset evaluated: ROC AUC = 0.8028\n",
      "Individual 29/30: Fitness = 0.8028\n",
      "Feature subset evaluated: ROC AUC = 0.8054\n",
      "Individual 30/30: Fitness = 0.8054\n",
      "\n",
      "Best fitness in generation 17: 0.8205\n",
      "Current best features: ['V42', 'id_18', 'id_32', 'V79', 'V113', 'V328', 'id_28', 'V49', 'id_31', 'V154', 'V70', 'V2', 'V123', 'card6', 'V127', 'V135', 'V148', 'V166', 'V242', 'V254', 'V257', 'V259', 'V267', 'V281', 'V283', 'V310', 'V317', 'id_11', 'id_20', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 18/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 1/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 2/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8188\n",
      "Individual 3/30: Fitness = 0.8188\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 4/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8182\n",
      "Individual 5/30: Fitness = 0.8182\n",
      "Feature subset evaluated: ROC AUC = 0.8177\n",
      "Individual 6/30: Fitness = 0.8177\n",
      "Feature subset evaluated: ROC AUC = 0.8172\n",
      "Individual 7/30: Fitness = 0.8172\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 8/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 9/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 10/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8166\n",
      "Individual 11/30: Fitness = 0.8166\n",
      "Feature subset evaluated: ROC AUC = 0.8161\n",
      "Individual 12/30: Fitness = 0.8161\n",
      "Feature subset evaluated: ROC AUC = 0.8161\n",
      "Individual 13/30: Fitness = 0.8161\n",
      "Feature subset evaluated: ROC AUC = 0.8160\n",
      "Individual 14/30: Fitness = 0.8160\n",
      "Feature subset evaluated: ROC AUC = 0.8159\n",
      "Individual 15/30: Fitness = 0.8159\n",
      "Feature subset evaluated: ROC AUC = 0.8057\n",
      "Individual 16/30: Fitness = 0.8057\n",
      "Feature subset evaluated: ROC AUC = 0.8117\n",
      "Individual 17/30: Fitness = 0.8117\n",
      "Feature subset evaluated: ROC AUC = 0.7667\n",
      "Individual 18/30: Fitness = 0.7667\n",
      "Feature subset evaluated: ROC AUC = 0.8067\n",
      "Individual 19/30: Fitness = 0.8067\n",
      "Feature subset evaluated: ROC AUC = 0.8176\n",
      "Individual 20/30: Fitness = 0.8176\n",
      "Feature subset evaluated: ROC AUC = 0.8167\n",
      "Individual 21/30: Fitness = 0.8167\n",
      "Feature subset evaluated: ROC AUC = 0.8145\n",
      "Individual 22/30: Fitness = 0.8145\n",
      "Feature subset evaluated: ROC AUC = 0.8206\n",
      "Individual 23/30: Fitness = 0.8206\n",
      "Feature subset evaluated: ROC AUC = 0.8036\n",
      "Individual 24/30: Fitness = 0.8036\n",
      "Feature subset evaluated: ROC AUC = 0.8156\n",
      "Individual 25/30: Fitness = 0.8156\n",
      "Feature subset evaluated: ROC AUC = 0.7930\n",
      "Individual 26/30: Fitness = 0.7930\n",
      "Feature subset evaluated: ROC AUC = 0.7958\n",
      "Individual 27/30: Fitness = 0.7958\n",
      "Feature subset evaluated: ROC AUC = 0.8169\n",
      "Individual 28/30: Fitness = 0.8169\n",
      "Feature subset evaluated: ROC AUC = 0.8069\n",
      "Individual 29/30: Fitness = 0.8069\n",
      "Feature subset evaluated: ROC AUC = 0.8087\n",
      "Individual 30/30: Fitness = 0.8087\n",
      "\n",
      "Best fitness in generation 18: 0.8206\n",
      "Current best features: ['V42', 'M5', 'V53', 'id_18', 'V113', 'V328', 'V119', 'V33', 'id_31', 'V70', 'V60', 'card6', 'TransactionDT', 'C3', 'V77', 'V127', 'V148', 'V151', 'V162', 'V236', 'V257', 'V283', 'V294', 'V310', 'V315', 'V329', 'V331', 'id_17', 'id_20', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 19/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8206\n",
      "Individual 1/30: Fitness = 0.8206\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 2/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 3/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8188\n",
      "Individual 4/30: Fitness = 0.8188\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 5/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8182\n",
      "Individual 6/30: Fitness = 0.8182\n",
      "Feature subset evaluated: ROC AUC = 0.8177\n",
      "Individual 7/30: Fitness = 0.8177\n",
      "Feature subset evaluated: ROC AUC = 0.8176\n",
      "Individual 8/30: Fitness = 0.8176\n",
      "Feature subset evaluated: ROC AUC = 0.8172\n",
      "Individual 9/30: Fitness = 0.8172\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 10/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 11/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 12/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8169\n",
      "Individual 13/30: Fitness = 0.8169\n",
      "Feature subset evaluated: ROC AUC = 0.8167\n",
      "Individual 14/30: Fitness = 0.8167\n",
      "Feature subset evaluated: ROC AUC = 0.8166\n",
      "Individual 15/30: Fitness = 0.8166\n",
      "Feature subset evaluated: ROC AUC = 0.8133\n",
      "Individual 16/30: Fitness = 0.8133\n",
      "Feature subset evaluated: ROC AUC = 0.8052\n",
      "Individual 17/30: Fitness = 0.8052\n",
      "Feature subset evaluated: ROC AUC = 0.8054\n",
      "Individual 18/30: Fitness = 0.8054\n",
      "Feature subset evaluated: ROC AUC = 0.7981\n",
      "Individual 19/30: Fitness = 0.7981\n",
      "Feature subset evaluated: ROC AUC = 0.8165\n",
      "Individual 20/30: Fitness = 0.8165\n",
      "Feature subset evaluated: ROC AUC = 0.8017\n",
      "Individual 21/30: Fitness = 0.8017\n",
      "Feature subset evaluated: ROC AUC = 0.8124\n",
      "Individual 22/30: Fitness = 0.8124\n",
      "Feature subset evaluated: ROC AUC = 0.8179\n",
      "Individual 23/30: Fitness = 0.8179\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 24/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8074\n",
      "Individual 25/30: Fitness = 0.8074\n",
      "Feature subset evaluated: ROC AUC = 0.8119\n",
      "Individual 26/30: Fitness = 0.8119\n",
      "Feature subset evaluated: ROC AUC = 0.8126\n",
      "Individual 27/30: Fitness = 0.8126\n",
      "Feature subset evaluated: ROC AUC = 0.8097\n",
      "Individual 28/30: Fitness = 0.8097\n",
      "Feature subset evaluated: ROC AUC = 0.8143\n",
      "Individual 29/30: Fitness = 0.8143\n",
      "Feature subset evaluated: ROC AUC = 0.8139\n",
      "Individual 30/30: Fitness = 0.8139\n",
      "\n",
      "Best fitness in generation 19: 0.8206\n",
      "Current best features: ['V42', 'M5', 'V53', 'id_18', 'V113', 'V328', 'V119', 'V33', 'id_31', 'V70', 'V60', 'card6', 'TransactionDT', 'C3', 'V77', 'V127', 'V148', 'V151', 'V162', 'V236', 'V257', 'V283', 'V294', 'V310', 'V315', 'V329', 'V331', 'id_17', 'id_20', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 20/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8206\n",
      "Individual 1/30: Fitness = 0.8206\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 2/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 3/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 4/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8188\n",
      "Individual 5/30: Fitness = 0.8188\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 6/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8182\n",
      "Individual 7/30: Fitness = 0.8182\n",
      "Feature subset evaluated: ROC AUC = 0.8179\n",
      "Individual 8/30: Fitness = 0.8179\n",
      "Feature subset evaluated: ROC AUC = 0.8177\n",
      "Individual 9/30: Fitness = 0.8177\n",
      "Feature subset evaluated: ROC AUC = 0.8176\n",
      "Individual 10/30: Fitness = 0.8176\n",
      "Feature subset evaluated: ROC AUC = 0.8172\n",
      "Individual 11/30: Fitness = 0.8172\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 12/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 13/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 14/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8169\n",
      "Individual 15/30: Fitness = 0.8169\n",
      "Feature subset evaluated: ROC AUC = 0.8180\n",
      "Individual 16/30: Fitness = 0.8180\n",
      "Feature subset evaluated: ROC AUC = 0.8151\n",
      "Individual 17/30: Fitness = 0.8151\n",
      "Feature subset evaluated: ROC AUC = 0.8077\n",
      "Individual 18/30: Fitness = 0.8077\n",
      "Feature subset evaluated: ROC AUC = 0.8106\n",
      "Individual 19/30: Fitness = 0.8106\n",
      "Feature subset evaluated: ROC AUC = 0.8119\n",
      "Individual 20/30: Fitness = 0.8119\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 21/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8123\n",
      "Individual 22/30: Fitness = 0.8123\n",
      "Feature subset evaluated: ROC AUC = 0.7840\n",
      "Individual 23/30: Fitness = 0.7840\n",
      "Feature subset evaluated: ROC AUC = 0.8023\n",
      "Individual 24/30: Fitness = 0.8023\n",
      "Feature subset evaluated: ROC AUC = 0.7971\n",
      "Individual 25/30: Fitness = 0.7971\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 26/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8180\n",
      "Individual 27/30: Fitness = 0.8180\n",
      "Feature subset evaluated: ROC AUC = 0.7913\n",
      "Individual 28/30: Fitness = 0.7913\n",
      "Feature subset evaluated: ROC AUC = 0.8083\n",
      "Individual 29/30: Fitness = 0.8083\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 30/30: Fitness = 0.8170\n",
      "\n",
      "Best fitness in generation 20: 0.8206\n",
      "Current best features: ['V42', 'M5', 'V53', 'id_18', 'V113', 'V328', 'V119', 'V33', 'id_31', 'V70', 'V60', 'card6', 'TransactionDT', 'C3', 'V77', 'V127', 'V148', 'V151', 'V162', 'V236', 'V257', 'V283', 'V294', 'V310', 'V315', 'V329', 'V331', 'id_17', 'id_20', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 21/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8206\n",
      "Individual 1/30: Fitness = 0.8206\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 2/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 3/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 4/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 5/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8188\n",
      "Individual 6/30: Fitness = 0.8188\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 7/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8182\n",
      "Individual 8/30: Fitness = 0.8182\n",
      "Feature subset evaluated: ROC AUC = 0.8180\n",
      "Individual 9/30: Fitness = 0.8180\n",
      "Feature subset evaluated: ROC AUC = 0.8180\n",
      "Individual 10/30: Fitness = 0.8180\n",
      "Feature subset evaluated: ROC AUC = 0.8179\n",
      "Individual 11/30: Fitness = 0.8179\n",
      "Feature subset evaluated: ROC AUC = 0.8177\n",
      "Individual 12/30: Fitness = 0.8177\n",
      "Feature subset evaluated: ROC AUC = 0.8176\n",
      "Individual 13/30: Fitness = 0.8176\n",
      "Feature subset evaluated: ROC AUC = 0.8172\n",
      "Individual 14/30: Fitness = 0.8172\n",
      "Feature subset evaluated: ROC AUC = 0.8170\n",
      "Individual 15/30: Fitness = 0.8170\n",
      "Feature subset evaluated: ROC AUC = 0.8175\n",
      "Individual 16/30: Fitness = 0.8175\n",
      "Feature subset evaluated: ROC AUC = 0.8054\n",
      "Individual 17/30: Fitness = 0.8054\n",
      "Feature subset evaluated: ROC AUC = 0.8195\n",
      "Individual 18/30: Fitness = 0.8195\n",
      "Feature subset evaluated: ROC AUC = 0.8134\n",
      "Individual 19/30: Fitness = 0.8134\n",
      "Feature subset evaluated: ROC AUC = 0.8046\n",
      "Individual 20/30: Fitness = 0.8046\n",
      "Feature subset evaluated: ROC AUC = 0.8176\n",
      "Individual 21/30: Fitness = 0.8176\n",
      "Feature subset evaluated: ROC AUC = 0.8038\n",
      "Individual 22/30: Fitness = 0.8038\n",
      "Feature subset evaluated: ROC AUC = 0.8089\n",
      "Individual 23/30: Fitness = 0.8089\n",
      "Feature subset evaluated: ROC AUC = 0.8109\n",
      "Individual 24/30: Fitness = 0.8109\n",
      "Feature subset evaluated: ROC AUC = 0.8085\n",
      "Individual 25/30: Fitness = 0.8085\n",
      "Feature subset evaluated: ROC AUC = 0.8083\n",
      "Individual 26/30: Fitness = 0.8083\n",
      "Feature subset evaluated: ROC AUC = 0.7872\n",
      "Individual 27/30: Fitness = 0.7872\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 28/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8103\n",
      "Individual 29/30: Fitness = 0.8103\n",
      "Feature subset evaluated: ROC AUC = 0.8186\n",
      "Individual 30/30: Fitness = 0.8186\n",
      "\n",
      "Best fitness in generation 21: 0.8206\n",
      "Current best features: ['V42', 'M5', 'V53', 'id_18', 'V113', 'V328', 'V119', 'V33', 'id_31', 'V70', 'V60', 'card6', 'TransactionDT', 'C3', 'V77', 'V127', 'V148', 'V151', 'V162', 'V236', 'V257', 'V283', 'V294', 'V310', 'V315', 'V329', 'V331', 'id_17', 'id_20', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 22/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8206\n",
      "Individual 1/30: Fitness = 0.8206\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 2/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 3/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 4/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 5/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8195\n",
      "Individual 6/30: Fitness = 0.8195\n",
      "Feature subset evaluated: ROC AUC = 0.8188\n",
      "Individual 7/30: Fitness = 0.8188\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 8/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 9/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8186\n",
      "Individual 10/30: Fitness = 0.8186\n",
      "Feature subset evaluated: ROC AUC = 0.8182\n",
      "Individual 11/30: Fitness = 0.8182\n",
      "Feature subset evaluated: ROC AUC = 0.8180\n",
      "Individual 12/30: Fitness = 0.8180\n",
      "Feature subset evaluated: ROC AUC = 0.8180\n",
      "Individual 13/30: Fitness = 0.8180\n",
      "Feature subset evaluated: ROC AUC = 0.8179\n",
      "Individual 14/30: Fitness = 0.8179\n",
      "Feature subset evaluated: ROC AUC = 0.8177\n",
      "Individual 15/30: Fitness = 0.8177\n",
      "Feature subset evaluated: ROC AUC = 0.8057\n",
      "Individual 16/30: Fitness = 0.8057\n",
      "Feature subset evaluated: ROC AUC = 0.8105\n",
      "Individual 17/30: Fitness = 0.8105\n",
      "Feature subset evaluated: ROC AUC = 0.8044\n",
      "Individual 18/30: Fitness = 0.8044\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 19/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8146\n",
      "Individual 20/30: Fitness = 0.8146\n",
      "Feature subset evaluated: ROC AUC = 0.8189\n",
      "Individual 21/30: Fitness = 0.8189\n",
      "Feature subset evaluated: ROC AUC = 0.8153\n",
      "Individual 22/30: Fitness = 0.8153\n",
      "Feature subset evaluated: ROC AUC = 0.7974\n",
      "Individual 23/30: Fitness = 0.7974\n",
      "Feature subset evaluated: ROC AUC = 0.8163\n",
      "Individual 24/30: Fitness = 0.8163\n",
      "Feature subset evaluated: ROC AUC = 0.8156\n",
      "Individual 25/30: Fitness = 0.8156\n",
      "Feature subset evaluated: ROC AUC = 0.8138\n",
      "Individual 26/30: Fitness = 0.8138\n",
      "Feature subset evaluated: ROC AUC = 0.8161\n",
      "Individual 27/30: Fitness = 0.8161\n",
      "Feature subset evaluated: ROC AUC = 0.8017\n",
      "Individual 28/30: Fitness = 0.8017\n",
      "Feature subset evaluated: ROC AUC = 0.8181\n",
      "Individual 29/30: Fitness = 0.8181\n",
      "Feature subset evaluated: ROC AUC = 0.8138\n",
      "Individual 30/30: Fitness = 0.8138\n",
      "\n",
      "Best fitness in generation 22: 0.8209\n",
      "Current best features: ['V53', 'id_18', 'id_32', 'V79', 'V113', 'V328', 'id_28', 'V49', 'id_31', 'V154', 'V70', 'V60', 'card6', 'V77', 'V135', 'V148', 'V151', 'V162', 'V166', 'V236', 'V242', 'V254', 'V267', 'V281', 'V283', 'V310', 'V317', 'V329', 'id_11', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 23/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 1/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8206\n",
      "Individual 2/30: Fitness = 0.8206\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 3/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 4/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 5/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 6/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8195\n",
      "Individual 7/30: Fitness = 0.8195\n",
      "Feature subset evaluated: ROC AUC = 0.8189\n",
      "Individual 8/30: Fitness = 0.8189\n",
      "Feature subset evaluated: ROC AUC = 0.8188\n",
      "Individual 9/30: Fitness = 0.8188\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 10/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 11/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8186\n",
      "Individual 12/30: Fitness = 0.8186\n",
      "Feature subset evaluated: ROC AUC = 0.8182\n",
      "Individual 13/30: Fitness = 0.8182\n",
      "Feature subset evaluated: ROC AUC = 0.8181\n",
      "Individual 14/30: Fitness = 0.8181\n",
      "Feature subset evaluated: ROC AUC = 0.8180\n",
      "Individual 15/30: Fitness = 0.8180\n",
      "Feature subset evaluated: ROC AUC = 0.8001\n",
      "Individual 16/30: Fitness = 0.8001\n",
      "Feature subset evaluated: ROC AUC = 0.8184\n",
      "Individual 17/30: Fitness = 0.8184\n",
      "Feature subset evaluated: ROC AUC = 0.8080\n",
      "Individual 18/30: Fitness = 0.8080\n",
      "Feature subset evaluated: ROC AUC = 0.8055\n",
      "Individual 19/30: Fitness = 0.8055\n",
      "Feature subset evaluated: ROC AUC = 0.8178\n",
      "Individual 20/30: Fitness = 0.8178\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 21/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8137\n",
      "Individual 22/30: Fitness = 0.8137\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 23/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8196\n",
      "Individual 24/30: Fitness = 0.8196\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 25/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8102\n",
      "Individual 26/30: Fitness = 0.8102\n",
      "Feature subset evaluated: ROC AUC = 0.7893\n",
      "Individual 27/30: Fitness = 0.7893\n",
      "Feature subset evaluated: ROC AUC = 0.8123\n",
      "Individual 28/30: Fitness = 0.8123\n",
      "Feature subset evaluated: ROC AUC = 0.8188\n",
      "Individual 29/30: Fitness = 0.8188\n",
      "Feature subset evaluated: ROC AUC = 0.8115\n",
      "Individual 30/30: Fitness = 0.8115\n",
      "\n",
      "Best fitness in generation 23: 0.8210\n",
      "Current best features: ['V42', 'id_18', 'id_32', 'V79', 'V113', 'V328', 'id_28', 'id_31', 'V154', 'V70', 'V2', 'V123', 'V60', 'card6', 'V77', 'V127', 'V135', 'V148', 'V151', 'V166', 'V236', 'V242', 'V257', 'V283', 'V310', 'V317', 'V329', 'id_11', 'id_20', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 24/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 1/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 2/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8206\n",
      "Individual 3/30: Fitness = 0.8206\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 4/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 5/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 6/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 7/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 8/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8196\n",
      "Individual 9/30: Fitness = 0.8196\n",
      "Feature subset evaluated: ROC AUC = 0.8195\n",
      "Individual 10/30: Fitness = 0.8195\n",
      "Feature subset evaluated: ROC AUC = 0.8189\n",
      "Individual 11/30: Fitness = 0.8189\n",
      "Feature subset evaluated: ROC AUC = 0.8188\n",
      "Individual 12/30: Fitness = 0.8188\n",
      "Feature subset evaluated: ROC AUC = 0.8188\n",
      "Individual 13/30: Fitness = 0.8188\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 14/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 15/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.7851\n",
      "Individual 16/30: Fitness = 0.7851\n",
      "Feature subset evaluated: ROC AUC = 0.8059\n",
      "Individual 17/30: Fitness = 0.8059\n",
      "Feature subset evaluated: ROC AUC = 0.8143\n",
      "Individual 18/30: Fitness = 0.8143\n",
      "Feature subset evaluated: ROC AUC = 0.8003\n",
      "Individual 19/30: Fitness = 0.8003\n",
      "Feature subset evaluated: ROC AUC = 0.8138\n",
      "Individual 20/30: Fitness = 0.8138\n",
      "Feature subset evaluated: ROC AUC = 0.8029\n",
      "Individual 21/30: Fitness = 0.8029\n",
      "Feature subset evaluated: ROC AUC = 0.8153\n",
      "Individual 22/30: Fitness = 0.8153\n",
      "Feature subset evaluated: ROC AUC = 0.8196\n",
      "Individual 23/30: Fitness = 0.8196\n",
      "Feature subset evaluated: ROC AUC = 0.8054\n",
      "Individual 24/30: Fitness = 0.8054\n",
      "Feature subset evaluated: ROC AUC = 0.7937\n",
      "Individual 25/30: Fitness = 0.7937\n",
      "Feature subset evaluated: ROC AUC = 0.7952\n",
      "Individual 26/30: Fitness = 0.7952\n",
      "Feature subset evaluated: ROC AUC = 0.8102\n",
      "Individual 27/30: Fitness = 0.8102\n",
      "Feature subset evaluated: ROC AUC = 0.8175\n",
      "Individual 28/30: Fitness = 0.8175\n",
      "Feature subset evaluated: ROC AUC = 0.8130\n",
      "Individual 29/30: Fitness = 0.8130\n",
      "Feature subset evaluated: ROC AUC = 0.8190\n",
      "Individual 30/30: Fitness = 0.8190\n",
      "\n",
      "Best fitness in generation 24: 0.8210\n",
      "Current best features: ['V42', 'id_18', 'id_32', 'V79', 'V113', 'V328', 'id_28', 'id_31', 'V154', 'V70', 'V2', 'V123', 'V60', 'card6', 'V77', 'V127', 'V135', 'V148', 'V151', 'V166', 'V236', 'V242', 'V257', 'V283', 'V310', 'V317', 'V329', 'id_11', 'id_20', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 25/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 1/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 2/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8206\n",
      "Individual 3/30: Fitness = 0.8206\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 4/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 5/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 6/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 7/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 8/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8196\n",
      "Individual 9/30: Fitness = 0.8196\n",
      "Feature subset evaluated: ROC AUC = 0.8196\n",
      "Individual 10/30: Fitness = 0.8196\n",
      "Feature subset evaluated: ROC AUC = 0.8195\n",
      "Individual 11/30: Fitness = 0.8195\n",
      "Feature subset evaluated: ROC AUC = 0.8190\n",
      "Individual 12/30: Fitness = 0.8190\n",
      "Feature subset evaluated: ROC AUC = 0.8189\n",
      "Individual 13/30: Fitness = 0.8189\n",
      "Feature subset evaluated: ROC AUC = 0.8188\n",
      "Individual 14/30: Fitness = 0.8188\n",
      "Feature subset evaluated: ROC AUC = 0.8188\n",
      "Individual 15/30: Fitness = 0.8188\n",
      "Feature subset evaluated: ROC AUC = 0.8188\n",
      "Individual 16/30: Fitness = 0.8188\n",
      "Feature subset evaluated: ROC AUC = 0.8132\n",
      "Individual 17/30: Fitness = 0.8132\n",
      "Feature subset evaluated: ROC AUC = 0.8114\n",
      "Individual 18/30: Fitness = 0.8114\n",
      "Feature subset evaluated: ROC AUC = 0.8180\n",
      "Individual 19/30: Fitness = 0.8180\n",
      "Feature subset evaluated: ROC AUC = 0.8070\n",
      "Individual 20/30: Fitness = 0.8070\n",
      "Feature subset evaluated: ROC AUC = 0.8047\n",
      "Individual 21/30: Fitness = 0.8047\n",
      "Feature subset evaluated: ROC AUC = 0.8200\n",
      "Individual 22/30: Fitness = 0.8200\n",
      "Feature subset evaluated: ROC AUC = 0.8134\n",
      "Individual 23/30: Fitness = 0.8134\n",
      "Feature subset evaluated: ROC AUC = 0.8102\n",
      "Individual 24/30: Fitness = 0.8102\n",
      "Feature subset evaluated: ROC AUC = 0.8179\n",
      "Individual 25/30: Fitness = 0.8179\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 26/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8208\n",
      "Individual 27/30: Fitness = 0.8208\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 28/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8071\n",
      "Individual 29/30: Fitness = 0.8071\n",
      "Feature subset evaluated: ROC AUC = 0.8189\n",
      "Individual 30/30: Fitness = 0.8189\n",
      "\n",
      "Best fitness in generation 25: 0.8210\n",
      "Current best features: ['V42', 'id_18', 'id_32', 'V79', 'V113', 'V328', 'id_28', 'id_31', 'V154', 'V70', 'V2', 'V123', 'V60', 'card6', 'V77', 'V127', 'V135', 'V148', 'V151', 'V166', 'V236', 'V242', 'V257', 'V283', 'V310', 'V317', 'V329', 'id_11', 'id_20', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 26/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 1/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 2/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 3/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 4/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8208\n",
      "Individual 5/30: Fitness = 0.8208\n",
      "Feature subset evaluated: ROC AUC = 0.8206\n",
      "Individual 6/30: Fitness = 0.8206\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 7/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 8/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 9/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 10/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8200\n",
      "Individual 11/30: Fitness = 0.8200\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 12/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8196\n",
      "Individual 13/30: Fitness = 0.8196\n",
      "Feature subset evaluated: ROC AUC = 0.8196\n",
      "Individual 14/30: Fitness = 0.8196\n",
      "Feature subset evaluated: ROC AUC = 0.8195\n",
      "Individual 15/30: Fitness = 0.8195\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 16/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.7996\n",
      "Individual 17/30: Fitness = 0.7996\n",
      "Feature subset evaluated: ROC AUC = 0.8196\n",
      "Individual 18/30: Fitness = 0.8196\n",
      "Feature subset evaluated: ROC AUC = 0.8122\n",
      "Individual 19/30: Fitness = 0.8122\n",
      "Feature subset evaluated: ROC AUC = 0.8159\n",
      "Individual 20/30: Fitness = 0.8159\n",
      "Feature subset evaluated: ROC AUC = 0.7986\n",
      "Individual 21/30: Fitness = 0.7986\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 22/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8165\n",
      "Individual 23/30: Fitness = 0.8165\n",
      "Feature subset evaluated: ROC AUC = 0.8042\n",
      "Individual 24/30: Fitness = 0.8042\n",
      "Feature subset evaluated: ROC AUC = 0.8125\n",
      "Individual 25/30: Fitness = 0.8125\n",
      "Feature subset evaluated: ROC AUC = 0.8096\n",
      "Individual 26/30: Fitness = 0.8096\n",
      "Feature subset evaluated: ROC AUC = 0.8144\n",
      "Individual 27/30: Fitness = 0.8144\n",
      "Feature subset evaluated: ROC AUC = 0.8158\n",
      "Individual 28/30: Fitness = 0.8158\n",
      "Feature subset evaluated: ROC AUC = 0.8075\n",
      "Individual 29/30: Fitness = 0.8075\n",
      "Feature subset evaluated: ROC AUC = 0.8173\n",
      "Individual 30/30: Fitness = 0.8173\n",
      "\n",
      "Best fitness in generation 26: 0.8210\n",
      "Current best features: ['id_32', 'V79', 'V113', 'V328', 'V195', 'V49', 'id_31', 'V154', 'V70', 'V40', 'V2', 'card6', 'V147', 'V148', 'V166', 'V180', 'V242', 'V257', 'V259', 'V283', 'V290', 'V306', 'V310', 'V314', 'V329', 'V331', 'id_11', 'id_17', 'id_20', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 27/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 1/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 2/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 3/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 4/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 5/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8208\n",
      "Individual 6/30: Fitness = 0.8208\n",
      "Feature subset evaluated: ROC AUC = 0.8206\n",
      "Individual 7/30: Fitness = 0.8206\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 8/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 9/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 10/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 11/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8200\n",
      "Individual 12/30: Fitness = 0.8200\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 13/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 14/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8196\n",
      "Individual 15/30: Fitness = 0.8196\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 16/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.7975\n",
      "Individual 17/30: Fitness = 0.7975\n",
      "Feature subset evaluated: ROC AUC = 0.8131\n",
      "Individual 18/30: Fitness = 0.8131\n",
      "Feature subset evaluated: ROC AUC = 0.8121\n",
      "Individual 19/30: Fitness = 0.8121\n",
      "Feature subset evaluated: ROC AUC = 0.8163\n",
      "Individual 20/30: Fitness = 0.8163\n",
      "Feature subset evaluated: ROC AUC = 0.8149\n",
      "Individual 21/30: Fitness = 0.8149\n",
      "Feature subset evaluated: ROC AUC = 0.8115\n",
      "Individual 22/30: Fitness = 0.8115\n",
      "Feature subset evaluated: ROC AUC = 0.8108\n",
      "Individual 23/30: Fitness = 0.8108\n",
      "Feature subset evaluated: ROC AUC = 0.8198\n",
      "Individual 24/30: Fitness = 0.8198\n",
      "Feature subset evaluated: ROC AUC = 0.7700\n",
      "Individual 25/30: Fitness = 0.7700\n",
      "Feature subset evaluated: ROC AUC = 0.8201\n",
      "Individual 26/30: Fitness = 0.8201\n",
      "Feature subset evaluated: ROC AUC = 0.8182\n",
      "Individual 27/30: Fitness = 0.8182\n",
      "Feature subset evaluated: ROC AUC = 0.7963\n",
      "Individual 28/30: Fitness = 0.7963\n",
      "Feature subset evaluated: ROC AUC = 0.8167\n",
      "Individual 29/30: Fitness = 0.8167\n",
      "Feature subset evaluated: ROC AUC = 0.7978\n",
      "Individual 30/30: Fitness = 0.7978\n",
      "\n",
      "Best fitness in generation 27: 0.8210\n",
      "Current best features: ['id_32', 'V79', 'V113', 'V328', 'V195', 'V49', 'id_31', 'V154', 'V70', 'V40', 'V2', 'card6', 'V147', 'V148', 'V166', 'V180', 'V242', 'V257', 'V259', 'V283', 'V290', 'V306', 'V310', 'V314', 'V329', 'V331', 'id_11', 'id_17', 'id_20', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 28/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 1/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 2/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 3/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 4/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 5/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 6/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8208\n",
      "Individual 7/30: Fitness = 0.8208\n",
      "Feature subset evaluated: ROC AUC = 0.8206\n",
      "Individual 8/30: Fitness = 0.8206\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 9/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 10/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 11/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 12/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8201\n",
      "Individual 13/30: Fitness = 0.8201\n",
      "Feature subset evaluated: ROC AUC = 0.8200\n",
      "Individual 14/30: Fitness = 0.8200\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 15/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8093\n",
      "Individual 16/30: Fitness = 0.8093\n",
      "Feature subset evaluated: ROC AUC = 0.8187\n",
      "Individual 17/30: Fitness = 0.8187\n",
      "Feature subset evaluated: ROC AUC = 0.8156\n",
      "Individual 18/30: Fitness = 0.8156\n",
      "Feature subset evaluated: ROC AUC = 0.8000\n",
      "Individual 19/30: Fitness = 0.8000\n",
      "Feature subset evaluated: ROC AUC = 0.8159\n",
      "Individual 20/30: Fitness = 0.8159\n",
      "Feature subset evaluated: ROC AUC = 0.8018\n",
      "Individual 21/30: Fitness = 0.8018\n",
      "Feature subset evaluated: ROC AUC = 0.8143\n",
      "Individual 22/30: Fitness = 0.8143\n",
      "Feature subset evaluated: ROC AUC = 0.8138\n",
      "Individual 23/30: Fitness = 0.8138\n",
      "Feature subset evaluated: ROC AUC = 0.8118\n",
      "Individual 24/30: Fitness = 0.8118\n",
      "Feature subset evaluated: ROC AUC = 0.8199\n",
      "Individual 25/30: Fitness = 0.8199\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 26/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8122\n",
      "Individual 27/30: Fitness = 0.8122\n",
      "Feature subset evaluated: ROC AUC = 0.8075\n",
      "Individual 28/30: Fitness = 0.8075\n",
      "Feature subset evaluated: ROC AUC = 0.8077\n",
      "Individual 29/30: Fitness = 0.8077\n",
      "Feature subset evaluated: ROC AUC = 0.8179\n",
      "Individual 30/30: Fitness = 0.8179\n",
      "\n",
      "Best fitness in generation 28: 0.8210\n",
      "Current best features: ['id_32', 'V79', 'V113', 'V328', 'V195', 'V49', 'id_31', 'V154', 'V70', 'V40', 'V2', 'card6', 'V147', 'V148', 'V166', 'V180', 'V242', 'V257', 'V259', 'V283', 'V290', 'V306', 'V310', 'V314', 'V329', 'V331', 'id_11', 'id_17', 'id_20', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 29/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 1/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 2/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 3/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 4/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 5/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 6/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8208\n",
      "Individual 7/30: Fitness = 0.8208\n",
      "Feature subset evaluated: ROC AUC = 0.8206\n",
      "Individual 8/30: Fitness = 0.8206\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 9/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 10/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 11/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 12/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 13/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8201\n",
      "Individual 14/30: Fitness = 0.8201\n",
      "Feature subset evaluated: ROC AUC = 0.8200\n",
      "Individual 15/30: Fitness = 0.8200\n",
      "Feature subset evaluated: ROC AUC = 0.8186\n",
      "Individual 16/30: Fitness = 0.8186\n",
      "Feature subset evaluated: ROC AUC = 0.7969\n",
      "Individual 17/30: Fitness = 0.7969\n",
      "Feature subset evaluated: ROC AUC = 0.8043\n",
      "Individual 18/30: Fitness = 0.8043\n",
      "Feature subset evaluated: ROC AUC = 0.8134\n",
      "Individual 19/30: Fitness = 0.8134\n",
      "Feature subset evaluated: ROC AUC = 0.8119\n",
      "Individual 20/30: Fitness = 0.8119\n",
      "Feature subset evaluated: ROC AUC = 0.8115\n",
      "Individual 21/30: Fitness = 0.8115\n",
      "Feature subset evaluated: ROC AUC = 0.8149\n",
      "Individual 22/30: Fitness = 0.8149\n",
      "Feature subset evaluated: ROC AUC = 0.8074\n",
      "Individual 23/30: Fitness = 0.8074\n",
      "Feature subset evaluated: ROC AUC = 0.8139\n",
      "Individual 24/30: Fitness = 0.8139\n",
      "Feature subset evaluated: ROC AUC = 0.8147\n",
      "Individual 25/30: Fitness = 0.8147\n",
      "Feature subset evaluated: ROC AUC = 0.8080\n",
      "Individual 26/30: Fitness = 0.8080\n",
      "Feature subset evaluated: ROC AUC = 0.8127\n",
      "Individual 27/30: Fitness = 0.8127\n",
      "Feature subset evaluated: ROC AUC = 0.8231\n",
      "Individual 28/30: Fitness = 0.8231\n",
      "Feature subset evaluated: ROC AUC = 0.8106\n",
      "Individual 29/30: Fitness = 0.8106\n",
      "Feature subset evaluated: ROC AUC = 0.8064\n",
      "Individual 30/30: Fitness = 0.8064\n",
      "\n",
      "Best fitness in generation 29: 0.8231\n",
      "Current best features: ['V42', 'id_18', 'id_32', 'V79', 'V113', 'V328', 'id_28', 'id_31', 'V154', 'V70', 'V123', 'V60', 'card6', 'V77', 'V102', 'V135', 'V148', 'V151', 'V236', 'V242', 'V257', 'V281', 'V283', 'V307', 'V310', 'V317', 'V329', 'id_11', 'id_26', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "\n",
      "Generation 30/30\n",
      "Evaluating fitness for each individual:\n",
      "Feature subset evaluated: ROC AUC = 0.8231\n",
      "Individual 1/30: Fitness = 0.8231\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 2/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 3/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 4/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 5/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 6/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Individual 7/30: Fitness = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8208\n",
      "Individual 8/30: Fitness = 0.8208\n",
      "Feature subset evaluated: ROC AUC = 0.8206\n",
      "Individual 9/30: Fitness = 0.8206\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 10/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 11/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 12/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 13/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Individual 14/30: Fitness = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8201\n",
      "Individual 15/30: Fitness = 0.8201\n",
      "Feature subset evaluated: ROC AUC = 0.8127\n",
      "Individual 16/30: Fitness = 0.8127\n",
      "Feature subset evaluated: ROC AUC = 0.8135\n",
      "Individual 17/30: Fitness = 0.8135\n",
      "Feature subset evaluated: ROC AUC = 0.8159\n",
      "Individual 18/30: Fitness = 0.8159\n",
      "Feature subset evaluated: ROC AUC = 0.8047\n",
      "Individual 19/30: Fitness = 0.8047\n",
      "Feature subset evaluated: ROC AUC = 0.8130\n",
      "Individual 20/30: Fitness = 0.8130\n",
      "Feature subset evaluated: ROC AUC = 0.8113\n",
      "Individual 21/30: Fitness = 0.8113\n",
      "Feature subset evaluated: ROC AUC = 0.8215\n",
      "Individual 22/30: Fitness = 0.8215\n",
      "Feature subset evaluated: ROC AUC = 0.8197\n",
      "Individual 23/30: Fitness = 0.8197\n",
      "Feature subset evaluated: ROC AUC = 0.8183\n",
      "Individual 24/30: Fitness = 0.8183\n",
      "Feature subset evaluated: ROC AUC = 0.7986\n",
      "Individual 25/30: Fitness = 0.7986\n",
      "Feature subset evaluated: ROC AUC = 0.8220\n",
      "Individual 26/30: Fitness = 0.8220\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 27/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 28/30: Fitness = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8180\n",
      "Individual 29/30: Fitness = 0.8180\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Individual 30/30: Fitness = 0.8210\n",
      "\n",
      "Best fitness in generation 30: 0.8231\n",
      "Current best features: ['V42', 'id_18', 'id_32', 'V79', 'V113', 'V328', 'id_28', 'id_31', 'V154', 'V70', 'V123', 'V60', 'card6', 'V77', 'V102', 'V135', 'V148', 'V151', 'V236', 'V242', 'V257', 'V281', 'V283', 'V307', 'V310', 'V317', 'V329', 'id_11', 'id_26', 'Screen_Width']\n",
      "Creating new population...\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Generating new individual...\n",
      "New individual created! Happy birthday!\n",
      "Feature subset evaluated: ROC AUC = 0.8231\n",
      "Feature subset evaluated: ROC AUC = 0.8220\n",
      "Feature subset evaluated: ROC AUC = 0.8215\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8209\n",
      "Feature subset evaluated: ROC AUC = 0.8208\n",
      "Feature subset evaluated: ROC AUC = 0.8206\n",
      "Feature subset evaluated: ROC AUC = 0.8205\n",
      "Feature subset evaluated: ROC AUC = 0.8167\n",
      "Feature subset evaluated: ROC AUC = 0.8047\n",
      "Feature subset evaluated: ROC AUC = 0.8020\n",
      "Feature subset evaluated: ROC AUC = 0.7855\n",
      "Feature subset evaluated: ROC AUC = 0.8183\n",
      "Feature subset evaluated: ROC AUC = 0.8120\n",
      "Feature subset evaluated: ROC AUC = 0.8111\n",
      "Feature subset evaluated: ROC AUC = 0.7943\n",
      "Feature subset evaluated: ROC AUC = 0.8168\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "Feature subset evaluated: ROC AUC = 0.8121\n",
      "Feature subset evaluated: ROC AUC = 0.8119\n",
      "Feature subset evaluated: ROC AUC = 0.8163\n",
      "Feature subset evaluated: ROC AUC = 0.7910\n",
      "Feature subset evaluated: ROC AUC = 0.8210\n",
      "\n",
      "Final Selected Features:\n",
      "1. V42\n",
      "2. id_18\n",
      "3. id_32\n",
      "4. V79\n",
      "5. V113\n",
      "6. V328\n",
      "7. id_28\n",
      "8. id_31\n",
      "9. V154\n",
      "10. V70\n",
      "11. V123\n",
      "12. V60\n",
      "13. card6\n",
      "14. V77\n",
      "15. V102\n",
      "16. V135\n",
      "17. V148\n",
      "18. V151\n",
      "19. V236\n",
      "20. V242\n",
      "21. V257\n",
      "22. V281\n",
      "23. V283\n",
      "24. V307\n",
      "25. V310\n",
      "26. V317\n",
      "27. V329\n",
      "28. id_11\n",
      "29. id_26\n",
      "30. Screen_Width\n",
      "\n",
      "Total features selected: 30\n"
     ]
    }
   ],
   "source": [
    "def run_genetic_algorithm(X_data, y_data, population_size=30, n_generations=30, subset_size=30):\n",
    "    n_features = X_data.shape[1]\n",
    "    feature_names = X_data.columns.tolist()\n",
    "    \n",
    "    # Initialize population - each individual is a sorted list of feature indices\n",
    "    # Each individual represents a potential feature subset, encoded as sorted indices for consistency\n",
    "    population = []\n",
    "    for _ in range(population_size):\n",
    "        subset = random.sample(range(n_features), subset_size) # Randomly select 'subset_size' features from total\n",
    "        subset.sort() # Sorting ensures reproducibility and simplifies comparison\n",
    "        population.append(subset)\n",
    "    \n",
    "    def fitness(individual):\n",
    "        # Extract the selected features from the dataset\n",
    "        X_subset = X_data.iloc[:, individual]\n",
    "        \n",
    "        # Perform a single train/validation split (stratified to preserve class imbalance)\n",
    "        X_train_subset, X_val_subset, y_train_subset, y_val_subset = train_test_split(\n",
    "            X_subset, y_data, test_size=0.2, random_state=42, stratify=y_data\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            # Use LinearSVC with class weights to handle imbalance, wrapped in CalibratedClassifierCV for probability outputs\n",
    "            base_model = LinearSVC(class_weight=class_weights_dict)\n",
    "            model = CalibratedClassifierCV(base_model)\n",
    "            \n",
    "            # Simple fit without evaluation set or early stopping\n",
    "            model.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Get validation roc auc for imbalanced data\n",
    "            roc_auc = roc_auc_score(y_val_subset, model.predict_proba(X_val_subset)[:, 1])\n",
    "            print(f\"Feature subset evaluated: ROC AUC = {roc_auc:.4f}\")\n",
    "            return roc_auc\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in fitness evaluation: {e}\")\n",
    "            return 0.0  # Return worst fitness on error\n",
    "    \n",
    "    # Creates a child by merging features from both parents and selecting a random subset\n",
    "    def crossover(p1, p2, subset_size):\n",
    "        combined = list(set(p1) | set(p2))  # Union of features\n",
    "        if len(combined) > subset_size:\n",
    "            child = sorted(random.sample(combined, subset_size))  # Ensure correct size\n",
    "        else:\n",
    "            child = sorted(combined)  # Keep all if below subset_size\n",
    "        return child\n",
    "\n",
    "    # Mutation replaces a random index in child if random.threshold is met\n",
    "    def mutation(individual, n_features, subset_size):\n",
    "        if random.random() < 0.1:  # 10% chance of mutation\n",
    "            i = random.randrange(subset_size)\n",
    "            available_features = set(range(n_features)) - set(individual)  # Exclude existing features\n",
    "            if available_features:  \n",
    "                new_feature = random.choice(list(available_features))\n",
    "                individual[i] = new_feature\n",
    "                individual.sort()\n",
    "        return individual\n",
    "\n",
    "    # GA evolution loop\n",
    "    # Iteratively evolve the population through selection, crossover, and mutation to optimize feature subset\n",
    "    for i in range(n_generations):\n",
    "        print(f\"\\nGeneration {i+1}/{n_generations}\")\n",
    "        # Evaluate fitness of population\n",
    "        print(\"Evaluating fitness for each individual:\")\n",
    "        scored_population = []\n",
    "        for idx, ind in enumerate(population):\n",
    "            fitness_score = fitness(ind)\n",
    "            scored_population.append((fitness_score, ind))\n",
    "            print(f\"Individual {idx+1}/{len(population)}: Fitness = {fitness_score:.4f}\")\n",
    "        \n",
    "        scored_population.sort(key=lambda x: x[0], reverse=True)\n",
    "        best_subset = scored_population[0][1]\n",
    "        print(f\"\\nBest fitness in generation {i+1}: {scored_population[0][0]:.4f}\")\n",
    "        print(\"Current best features:\", [feature_names[i] for i in best_subset])\n",
    "        \n",
    "        # Selection: truncation selection (pick top half as survivors)\n",
    "        survivors = scored_population[: population_size // 2]\n",
    "        \n",
    "        # Then randomly select two parents (p1 & p2) from survivors for crossover + mutation\n",
    "        print(\"Creating new population...\")\n",
    "        new_pop = [s[1] for s in survivors]\n",
    "        while len(new_pop) < population_size:\n",
    "            print(\"Generating new individual...\")\n",
    "            \n",
    "            p1 = random.choice(survivors)[1]\n",
    "            p2 = random.choice(survivors)[1]\n",
    "            child = crossover(p1, p2, subset_size)\n",
    "            child = mutation(child, n_features, subset_size)\n",
    "            \n",
    "            child = list(set(child))  # remove duplicates if any\n",
    "            while len(child) < subset_size:  # if duplicates reduced size\n",
    "                child.append(random.randrange(n_features))\n",
    "            child.sort()\n",
    "            new_pop.append(child)\n",
    "            \n",
    "            print(\"New individual created! Happy birthday!\")\n",
    "        population = new_pop\n",
    "        # print(\"Current best:\", max([(fitness(ind), ind) for ind in population], key=lambda x: x[0])[1])\n",
    "    \n",
    "    best = max([(fitness(ind), ind) for ind in population], key=lambda x: x[0])[1]\n",
    "    print(\"\\nFinal Selected Features:\")\n",
    "    for idx, feature_idx in enumerate(best, 1):\n",
    "        print(f\"{idx}. {feature_names[feature_idx]}\")\n",
    "    print(f\"\\nTotal features selected: {len(best)}\")\n",
    "    return best\n",
    "\n",
    "y_train = y_train.values.ravel()\n",
    "best_features = run_genetic_algorithm(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got:\n",
    "\n",
    "Final Selected Features:\n",
    "1. V42\n",
    "2. id_18\n",
    "3. id_32\n",
    "4. V79\n",
    "5. V113\n",
    "6. V328\n",
    "7. id_28\n",
    "8. id_31\n",
    "9. V154\n",
    "10. V70\n",
    "11. V123\n",
    "12. V60\n",
    "13. card6\n",
    "14. V77\n",
    "15. V102\n",
    "16. V135\n",
    "17. V148\n",
    "18. V151\n",
    "19. V236\n",
    "20. V242\n",
    "21. V257\n",
    "22. V281\n",
    "23. V283\n",
    "24. V307\n",
    "25. V310\n",
    "26. V317\n",
    "27. V329\n",
    "28. id_11\n",
    "29. id_26\n",
    "30. Screen_Width\n",
    "\n",
    "Total features selected: 30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save best features selected to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train_scaled.columns\n",
    "selected_feature_names = [feature_names[i] for i in best_features]\n",
    "\n",
    "ga_feature_mapping = {\n",
    "    'indices': best_features,\n",
    "    'names': selected_feature_names\n",
    "}\n",
    "\n",
    "# Export the GA feature information\n",
    "with open('ga_selected_features_for_svm.json', 'w') as f:\n",
    "    json.dump(ga_feature_mapping, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best features\n",
    "with open('ga_selected_features_for_svm.json', 'r') as f:\n",
    "    feature_mapping = json.load(f)\n",
    "\n",
    "best_features = feature_mapping['indices']\n",
    "best_feature_names = feature_mapping['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final features: [16, 36, 47, 48, 57, 58, 73, 111, 127, 138, 153, 155, 164, 213, 225, 238, 249, 252, 327, 331, 343, 366, 368, 382, 385, 392, 401, 421, 430, 431]\n",
      "Model ROC AUC with selected features: 0.8176732643762479\n"
     ]
    }
   ],
   "source": [
    "X_train_ga = X_train_scaled.iloc[:, best_features]\n",
    "X_val_ga = X_val_scaled.iloc[:, best_features]\n",
    "base_model = LinearSVC(class_weight=class_weights_dict)\n",
    "model = CalibratedClassifierCV(base_model)\n",
    "model.fit(X_train_ga, y_train)\n",
    "y_pred = model.predict_proba(X_val_ga)[:, 1]\n",
    "print(\"Final features:\", best_features)\n",
    "print(\"Model ROC AUC with selected features:\", roc_auc_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model test results to evaluate on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ga = X_test.iloc[:, best_features]\n",
    "y_pred_svm_ga_test = model.predict_proba(X_test_ga)\n",
    "fraud_probs = y_pred_svm_ga_test[:, 1]\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'TransactionID': transaction_ids,\n",
    "    'isFraud': fraud_probs\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submissions/svm_ga.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle results: ...; ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparative Analysis: GA vs. PCA, ICA, and SVD on SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To benchmark the Genetic Algorithm's performance, we compare it with three dimensionality reduction techniques: PCA, ICA, and SVD. Each method was applied to reduce the feature space to 30 dimensions (or features, in GAs case), followed by training an SVM model. Below are the Kaggle public and private leaderboard scores:\n",
    "\n",
    "- **PCA**: Public = 0.768107, Private = 0.809067\n",
    "- **ICA**: Public = 0.798548, Private = 0.837181\n",
    "- **SVD**: Public = 0.798845, Private = 0.837388\n",
    "- **GA**: Public = ..., Private = ...\n",
    "\n",
    "... ANALITICS ...\n",
    "\n",
    "### Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot comparing methods\n",
    "methods = ['PCA', 'ICA', 'SVD', 'GA']\n",
    "public_scores = [0.768107, 0.798548, 0.798845, ...]\n",
    "private_scores = [0.809067, 0.837181, 0.837388, ...]\n",
    "\n",
    "x = np.arange(len(methods))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(x - width/2, public_scores, width, label='Public Score', color='skyblue')\n",
    "ax.bar(x + width/2, private_scores, width, label='Private Score', color='salmon')\n",
    "ax.set_ylabel('Kaggle Score')\n",
    "ax.set_title('Performance Comparison Across Methods')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(methods)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical Insights\n",
    "\n",
    "... INSIGHTS ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSO and ACO for SVM hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write smth ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pso_for_svm_hyperparams(X_train_ga, y_train, X_test_ga, y_test, n_particles=10, n_iterations=5):\n",
    "    \"\"\"\n",
    "    Runs Particle Swarm Optimization (PSO) to find optimal hyperparameters for LinearSVC.\n",
    "\n",
    "    Args:\n",
    "        X_train_ga: Training features selected by GA.\n",
    "        y_train: Training target variable (flattened if needed).\n",
    "        X_test_ga: Testing features selected by GA.\n",
    "        y_test: Testing target variable (flattened if needed).\n",
    "        n_particles: Number of particles in the swarm.\n",
    "        n_iterations: Number of iterations for PSO.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (best_params_dict, best_score)\n",
    "               - best_params_dict: Dictionary containing the best hyperparameter set found.\n",
    "               - best_score: The best AUC score achieved by PSO.\n",
    "    \"\"\"\n",
    "    print(f\"Starting PSO with {n_particles} particles and {n_iterations} iterations...\")\n",
    "\n",
    "    # Flatten y_train and y_test if needed\n",
    "    y_train = y_train.values.ravel() if len(y_train.shape) > 1 else y_train\n",
    "    y_test = y_test.values.ravel() if len(y_test.shape) > 1 else y_test\n",
    "\n",
    "    # Define parameter bounds for PSO\n",
    "    param_bounds_pso = {\n",
    "        'C': (0.001, 100.0),          # params[0] Regularization parameter\n",
    "        'max_iter': (100, 5000),      # params[1] Integer, maximum iterations\n",
    "    }\n",
    "    param_keys = list(param_bounds_pso.keys())\n",
    "\n",
    "    # Define the objective function for PSO\n",
    "    def objective_function_pso(params):\n",
    "        C = params[param_keys.index('C')]\n",
    "        max_iter = int(round(params[param_keys.index('max_iter')]))\n",
    "\n",
    "        svm_params = {\n",
    "            'C': C,\n",
    "            'max_iter': max_iter,\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Use CalibratedClassifierCV to get probabilities\n",
    "            base_model = LinearSVC(**svm_params, class_weight=class_weights_dict)\n",
    "            model = CalibratedClassifierCV(base_model)\n",
    "            model.fit(X_train_ga, y_train)\n",
    "            y_pred = model.predict_proba(X_test_ga)[:, 1]\n",
    "            auc = roc_auc_score(y_test, y_pred)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Exception during SVM training/evaluation: {e}\")\n",
    "            print(f\"Params causing issue: {svm_params}\")\n",
    "            auc = 0.0\n",
    "        return auc\n",
    "\n",
    "    # Extract bounds for pyswarm\n",
    "    lb = [param_bounds_pso[k][0] for k in param_keys]\n",
    "    ub = [param_bounds_pso[k][1] for k in param_keys]\n",
    "\n",
    "    # Run PSO\n",
    "    best_params_pso_vals, best_score_pso = pso(objective_function_pso, lb, ub, swarmsize=n_particles, maxiter=n_iterations)\n",
    "\n",
    "    # Process results\n",
    "    best_params_pso_dict = {\n",
    "        'C': best_params_pso_vals[param_keys.index('C')],\n",
    "        'max_iter': int(round(best_params_pso_vals[param_keys.index('max_iter')]))\n",
    "    }\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(\"PSO Finished.\")\n",
    "    print(f\"Best ROC AUC score found by PSO: {best_score_pso:.6f}\")\n",
    "    print(\"Best SVM Parameters:\")\n",
    "    for key, val in best_params_pso_dict.items():\n",
    "        print(f\"  {key}: {val}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    return best_params_pso_dict, best_score_pso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PSO with 10 particles and 20 iterations...\n",
      "Stopping search: maximum iterations reached --> 20\n",
      "------------------------------\n",
      "PSO Finished.\n",
      "Best Accuracy score found by PSO: 0.969867\n",
      "Best SVM Parameters:\n",
      "  C: 49.4297286891903\n",
      "  max_iter: 4270\n",
      "------------------------------\n",
      "Final accuracy with optimized SVM: 0.969867\n"
     ]
    }
   ],
   "source": [
    "X_train_ga = X_train_scaled.iloc[:, best_features]\n",
    "X_val_ga = X_val_scaled.iloc[:, best_features]\n",
    "X_test_ga = X_test.iloc[:, best_features]\n",
    "\n",
    "# Run PSO\n",
    "best_params_pso, best_score_pso = run_pso_for_svm_hyperparams(X_train_ga, y_train, X_val_ga, y_val, n_particles=10, n_iterations=20)\n",
    "\n",
    "# Train final model with best parameters\n",
    "final_model = CalibratedClassifierCV(LinearSVC(**best_params_pso, class_weight=class_weights_dict))\n",
    "final_model.fit(X_train_ga, y_train.ravel())\n",
    "y_pred = final_model.predict_proba(X_val_ga)[:, 1]\n",
    "acc = roc_auc_score(y_val, y_pred)\n",
    "print(f\"Final ROC AUC with optimized SVM: {acc:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got:\n",
    "\n",
    "PSO Finished.\n",
    "\n",
    "Best Accuracy score found by PSO: ...\n",
    "\n",
    "Best SVM Parameters:\n",
    "  - C: ...\n",
    "  - max_iter: ...\n",
    "------------------------------\n",
    "Final accuracy with optimized SVM: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pso = X_test.iloc[:, best_features]\n",
    "y_pred_svm_pso_test = final_model.predict_proba(X_test_pso)\n",
    "fraud_probs = y_pred_svm_pso_test[:, 1]\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'TransactionID': transaction_ids,\n",
    "    'isFraud': fraud_probs\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submissions/svm_ga_pso.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle results: ...; ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ACO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACO_HyperparameterOptimizer:\n",
    "    def __init__(self, param_grid, objective_function, n_ants, n_iterations,\n",
    "                 alpha=1.0, beta=1.0, rho=0.1, Q=1.0, min_pheromone=0.01):\n",
    "        self.param_grid = param_grid\n",
    "        self.objective_function = objective_function\n",
    "        self.n_ants = n_ants\n",
    "        self.n_iterations = n_iterations\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.rho = rho\n",
    "        self.Q = Q\n",
    "        self.min_pheromone = min_pheromone\n",
    "        self.param_names = list(self.param_grid.keys())\n",
    "        self.pheromones = self._initialize_pheromones()\n",
    "        self.global_best_score = -np.inf\n",
    "        self.global_best_params = None\n",
    "\n",
    "    def _initialize_pheromones(self):\n",
    "        pheromones = {}\n",
    "        initial_pheromone = 1.0\n",
    "        for param, values in self.param_grid.items():\n",
    "            pheromones[param] = {value: initial_pheromone for value in values}\n",
    "        return pheromones\n",
    "\n",
    "    def _select_next_node(self, param_name):\n",
    "        pheromone_values = self.pheromones[param_name]\n",
    "        choices = list(pheromone_values.keys())\n",
    "        current_pheromones = np.array([pheromone_values[choice] for choice in choices])\n",
    "        selection_probs = current_pheromones ** self.alpha\n",
    "        prob_sum = np.sum(selection_probs)\n",
    "        if prob_sum == 0:\n",
    "            selection_probs = np.ones(len(choices)) / len(choices)\n",
    "        else:\n",
    "            selection_probs = selection_probs / prob_sum\n",
    "        chosen_value = np.random.choice(choices, p=selection_probs)\n",
    "        return chosen_value\n",
    "\n",
    "    def _construct_solution(self):\n",
    "        solution = {}\n",
    "        for param_name in self.param_names:\n",
    "            solution[param_name] = self._select_next_node(param_name)\n",
    "        return solution\n",
    "\n",
    "    def _update_pheromones(self, ant_solutions, ant_scores):\n",
    "        # Evaporation\n",
    "        for param_name, values in self.pheromones.items():\n",
    "            for value in values:\n",
    "                self.pheromones[param_name][value] *= (1.0 - self.rho)\n",
    "                self.pheromones[param_name][value] = max(self.pheromones[param_name][value], self.min_pheromone)\n",
    "        \n",
    "        # Deposition\n",
    "        for i in range(self.n_ants):\n",
    "            solution = ant_solutions[i]\n",
    "            score = ant_scores[i]\n",
    "            if score > -np.inf:\n",
    "                delta_pheromone = self.Q * score\n",
    "                for param_name, value in solution.items():\n",
    "                    if param_name in self.pheromones and value in self.pheromones[param_name]:\n",
    "                        self.pheromones[param_name][value] += delta_pheromone\n",
    "                    else:\n",
    "                        print(f\"Warning: Skipping update for {param_name}={value} - not in pheromone trails\")\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"Starting ACO: {self.n_iterations} iterations, {self.n_ants} ants/iteration.\")\n",
    "        for iteration in range(self.n_iterations):\n",
    "            ant_solutions = []\n",
    "            ant_scores = []\n",
    "            for ant in range(self.n_ants):\n",
    "                solution = self._construct_solution()\n",
    "                try:\n",
    "                    score = self.objective_function(solution.copy())\n",
    "                    if score is None or not np.isfinite(score):\n",
    "                        score = -np.inf\n",
    "                except Exception as e:\n",
    "                    print(f\"Error evaluating solution: {solution}\")\n",
    "                    print(f\"Exception: {e}\")\n",
    "                    score = -np.inf\n",
    "                ant_solutions.append(solution)\n",
    "                ant_scores.append(score)\n",
    "                if score > self.global_best_score:\n",
    "                    self.global_best_score = score\n",
    "                    self.global_best_params = solution\n",
    "                    print(f\"Iteration {iteration+1}, Ant {ant+1}: New best score! -> {self.global_best_score:.6f}\")\n",
    "            self._update_pheromones(ant_solutions, ant_scores)\n",
    "            avg_score = np.mean([s for s in ant_scores if s > -np.inf]) if any(s > -np.inf for s in ant_scores) else -np.inf\n",
    "            print(f\"Iteration {iteration+1}/{self.n_iterations} finished. Avg Score: {avg_score:.6f}. Best Score so far: {self.global_best_score:.6f}\")\n",
    "        print(\"-\" * 30)\n",
    "        print(\"ACO Finished.\")\n",
    "        if self.global_best_params:\n",
    "            print(f\"Best score found: {self.global_best_score:.6f}\")\n",
    "            print(\"Best parameters found:\")\n",
    "            for param, value in self.global_best_params.items():\n",
    "                print(f\"  {param}: {value}\")\n",
    "        else:\n",
    "            print(\"No valid solution found.\")\n",
    "        return self.global_best_params, self.global_best_score\n",
    "\n",
    "def run_aco_for_svm_hyperparams(X_train_ga, y_train, X_test_ga, y_test,\n",
    "                                n_ants=10, n_iterations=5,\n",
    "                                alpha=1.0, beta=1.0, rho=0.1, Q=1.0):\n",
    "    # Flatten y_train and y_test if needed\n",
    "    y_train = y_train.values.ravel() if len(y_train.shape) > 1 else y_train\n",
    "    y_test = y_test.values.ravel() if len(y_test.shape) > 1 else y_test\n",
    "\n",
    "    # Define parameter grid for ACO\n",
    "    param_grid_aco = {\n",
    "        'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "        'max_iter': [100, 500, 1000, 2000, 5000]\n",
    "    }\n",
    "\n",
    "    # Define objective function for ACO\n",
    "    def objective_function_aco(params):\n",
    "        svm_params = params.copy()\n",
    "        try:\n",
    "            base_model = LinearSVC(**svm_params, class_weight=class_weights_dict)\n",
    "            model = CalibratedClassifierCV(base_model)\n",
    "            model.fit(X_train_ga, y_train)\n",
    "            y_pred = model.predict_proba(X_test_ga)[:, 1]\n",
    "            auc = roc_auc_score(y_test, y_pred)\n",
    "            if not np.isfinite(auc):\n",
    "                auc = 0.0\n",
    "        except Exception as e:\n",
    "            print(f\"Error in objective function: {e}\")\n",
    "            auc = 0.0\n",
    "        return auc\n",
    "\n",
    "    # Instantiate and run ACO\n",
    "    aco_optimizer = ACO_HyperparameterOptimizer(\n",
    "        param_grid=param_grid_aco,\n",
    "        objective_function=objective_function_aco,\n",
    "        n_ants=n_ants,\n",
    "        n_iterations=n_iterations,\n",
    "        alpha=alpha,\n",
    "        beta=beta,\n",
    "        rho=rho,\n",
    "        Q=Q\n",
    "    )\n",
    "\n",
    "    best_params_aco, best_score_aco = aco_optimizer.run()\n",
    "    return best_params_aco, best_score_aco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ACO: 20 iterations, 10 ants/iteration.\n",
      "Iteration 1, Ant 1: New best score! -> 0.969875\n",
      "Iteration 1, Ant 7: New best score! -> 0.969892\n",
      "Iteration 1/20 finished. Avg Score: 0.969873. Best Score so far: 0.969892\n",
      "Iteration 2/20 finished. Avg Score: 0.969870. Best Score so far: 0.969892\n",
      "Iteration 3/20 finished. Avg Score: 0.969872. Best Score so far: 0.969892\n",
      "Iteration 4/20 finished. Avg Score: 0.969867. Best Score so far: 0.969892\n",
      "Iteration 5/20 finished. Avg Score: 0.969868. Best Score so far: 0.969892\n",
      "Iteration 6/20 finished. Avg Score: 0.969867. Best Score so far: 0.969892\n",
      "Iteration 7/20 finished. Avg Score: 0.969869. Best Score so far: 0.969892\n",
      "Iteration 8/20 finished. Avg Score: 0.969867. Best Score so far: 0.969892\n",
      "Iteration 9/20 finished. Avg Score: 0.969870. Best Score so far: 0.969892\n",
      "Iteration 10/20 finished. Avg Score: 0.969867. Best Score so far: 0.969892\n",
      "Iteration 11/20 finished. Avg Score: 0.969867. Best Score so far: 0.969892\n",
      "Iteration 12/20 finished. Avg Score: 0.969870. Best Score so far: 0.969892\n",
      "Iteration 13/20 finished. Avg Score: 0.969867. Best Score so far: 0.969892\n",
      "Iteration 14/20 finished. Avg Score: 0.969870. Best Score so far: 0.969892\n",
      "Iteration 15/20 finished. Avg Score: 0.969867. Best Score so far: 0.969892\n",
      "Iteration 16/20 finished. Avg Score: 0.969868. Best Score so far: 0.969892\n",
      "Iteration 17/20 finished. Avg Score: 0.969871. Best Score so far: 0.969892\n",
      "Iteration 18/20 finished. Avg Score: 0.969867. Best Score so far: 0.969892\n",
      "Iteration 19/20 finished. Avg Score: 0.969872. Best Score so far: 0.969892\n",
      "Iteration 20/20 finished. Avg Score: 0.969868. Best Score so far: 0.969892\n",
      "------------------------------\n",
      "ACO Finished.\n",
      "Best score found: 0.969892\n",
      "Best parameters found:\n",
      "  C: 0.001\n",
      "  max_iter: 5000\n",
      "Final Accuracy with optimized SVM: 0.970408\n"
     ]
    }
   ],
   "source": [
    "best_params_aco, best_score_aco = run_aco_for_svm_hyperparams(X_train_ga, y_train, X_val_ga, y_val, n_ants=10, n_iterations=20)\n",
    "\n",
    "# Train final model with best parameters\n",
    "final_model = CalibratedClassifierCV(LinearSVC(**best_params_aco, random_state=42), cv=3)\n",
    "final_model.fit(X_train_ga, y_train.ravel())\n",
    "y_pred = final_model.predict_proba(X_val_ga)[:, 1]\n",
    "acc = roc_auc_score(y_val, y_pred)\n",
    "print(f\"Final ROC AUC with optimized SVM: {acc:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got:\n",
    "\n",
    "ACO Finished.\n",
    "\n",
    "Best score found: ...\n",
    "\n",
    "Best parameters found:\n",
    "  - C: ...\n",
    "  - max_iter: ...\n",
    "\n",
    "Final Accuracy with optimized SVM: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save test results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_aco = X_test.iloc[:, best_features]\n",
    "y_pred_svm_aco_test = final_model.predict_proba(X_test_pso)\n",
    "fraud_probs = y_pred_svm_aco_test[:, 1]\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'TransactionID': transaction_ids,\n",
    "    'isFraud': fraud_probs\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submissions/svm_ga_aco.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle results: ...; ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of results for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... ANALYTICS ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since SVM did not show any significant improvements with nature-inspired algorithms, we decided to test CatBoostClassifier with these algorithms. CatBoost has much more hyperparameters for tuning, so PSO and ACO can show improvements here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.read_csv(\"data/preprocessed_train.csv\")\n",
    "X_val_scaled = pd.read_csv(\"data/preprocessed_val.csv\")\n",
    "y_train = pd.read_csv(\"data/y_train.csv\")\n",
    "y_val = pd.read_csv(\"data/y_val.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"data/test_for_model_eval.csv\")\n",
    "X_test = X_test.drop(columns=[\"TransactionID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_flat = y_train.values.ravel()\n",
    "y_val_flat = y_val.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accounting for severe class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_train to numpy array (since it's read as DataFrame)\n",
    "y_train_array = y_train['isFraud'].values\n",
    "\n",
    "# Get unique classes and compute weights\n",
    "unique_classes = np.unique(y_train_array)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=unique_classes,\n",
    "    y=y_train_array\n",
    ")\n",
    "\n",
    "# Create dictionary of class weights\n",
    "class_weights_dict = dict(zip(unique_classes, class_weights))\n",
    "class_weights_dict = {int(k): float(v) for k, v in class_weights_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=30)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_val_pca = pca.transform(X_val_scaled)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6599149\ttotal: 18.1ms\tremaining: 9.04s\n",
      "100:\tlearn: 0.4532001\ttotal: 2.02s\tremaining: 7.98s\n",
      "200:\tlearn: 0.4251124\ttotal: 4.57s\tremaining: 6.79s\n",
      "300:\tlearn: 0.4037742\ttotal: 6.98s\tremaining: 4.61s\n",
      "400:\tlearn: 0.3869200\ttotal: 9.67s\tremaining: 2.39s\n",
      "499:\tlearn: 0.3725436\ttotal: 12.5s\tremaining: 0us\n",
      "CatBoost Training ROC AUC: 0.8802487906628617\n"
     ]
    }
   ],
   "source": [
    "model_cat = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    class_weights=class_weights_dict,\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")\n",
    "model_cat.fit(X_train_pca, y_train_flat)\n",
    "y_pred_cat = model_cat.predict_proba(X_val_pca)[:, 1]\n",
    "\n",
    "print(\"CatBoost Validation ROC AUC:\", roc_auc_score(y_val_flat, y_pred_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cbm_pca_test = final_model.predict_proba(X_test_pca)\n",
    "fraud_probs = y_pred_cbm_pca_test[:, 1]\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'TransactionID': transaction_ids,\n",
    "    'isFraud': fraud_probs\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submissions/cbm_pca.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle results: 0.821966; 0.872178\n",
    "#### Validation result: 0.8802"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/decomposition/_fastica.py:127: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ica = FastICA(n_components=30, random_state=42)\n",
    "X_train_ica = ica.fit_transform(X_train_scaled)\n",
    "X_val_ica = ica.transform(X_val_scaled)\n",
    "X_test_ica = ica.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6646346\ttotal: 51.7ms\tremaining: 25.8s\n",
      "100:\tlearn: 0.4558086\ttotal: 5.96s\tremaining: 23.5s\n",
      "200:\tlearn: 0.4220783\ttotal: 11.3s\tremaining: 16.8s\n",
      "300:\tlearn: 0.3973726\ttotal: 16.1s\tremaining: 10.6s\n",
      "400:\tlearn: 0.3779469\ttotal: 21.1s\tremaining: 5.21s\n",
      "499:\tlearn: 0.3611849\ttotal: 26.4s\tremaining: 0us\n",
      "CatBoost Training ROC AUC: 0.8059361564671323\n"
     ]
    }
   ],
   "source": [
    "model_cat = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    class_weights=class_weights_dict,\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")\n",
    "model_cat.fit(X_train_ica, y_train_flat)\n",
    "y_pred_cat = model_cat.predict(X_val_ica)\n",
    "\n",
    "print(\"CatBoost Training ROC AUC:\", roc_auc_score(y_val_flat, y_pred_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred_cbm_ica_test = final_model.predict_proba(X_test_ica)\n",
    "fraud_probs = y_pred_cbm_ica_test[:, 1]\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'TransactionID': transaction_ids,\n",
    "    'isFraud': fraud_probs\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submissions/cbm_ica.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle results: 0.818411; 0.875235\n",
    "#### Validation result: 0.8059"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=30, random_state=42)\n",
    "X_train_svd = svd.fit_transform(X_train_scaled)\n",
    "X_val_svd = svd.transform(X_val_scaled)\n",
    "X_test_svd = svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6596783\ttotal: 46.9ms\tremaining: 23.4s\n",
      "100:\tlearn: 0.4532107\ttotal: 5s\tremaining: 19.8s\n",
      "200:\tlearn: 0.4249120\ttotal: 9.5s\tremaining: 14.1s\n",
      "300:\tlearn: 0.4043511\ttotal: 14s\tremaining: 9.26s\n",
      "400:\tlearn: 0.3873599\ttotal: 18.5s\tremaining: 4.56s\n",
      "499:\tlearn: 0.3728342\ttotal: 23.1s\tremaining: 0us\n",
      "CatBoost Training ROC AUC: 0.7972073659401346\n"
     ]
    }
   ],
   "source": [
    "model_cat = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    class_weights=class_weights_dict,\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")\n",
    "model_cat.fit(X_train_svd, y_train_flat)\n",
    "y_pred_cat = model_cat.predict(X_val_svd)\n",
    "\n",
    "print(\"CatBoost Training ROC AUC:\", roc_auc_score(y_val_flat, y_pred_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred_cbm_svd_test = final_model.predict_proba(X_test_svd)\n",
    "fraud_probs = y_pred_cbm_svd_test[:, 1]\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'TransactionID': transaction_ids,\n",
    "    'isFraud': fraud_probs\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submissions/cbm_svd.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle results: 0.446137; 0.452396 ? recalculate\n",
    "#### Validation result: 0.7972"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algorithm for CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.read_csv(\"data/preprocessed_train.csv\")\n",
    "X_val_scaled = pd.read_csv(\"data/preprocessed_val.csv\")\n",
    "y_train = pd.read_csv(\"data/y_train.csv\")\n",
    "y_val = pd.read_csv(\"data/y_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_genetic_algorithm(X_data, y_data, population_size=30, n_generations=30, subset_size=30):\n",
    "    n_features = X_data.shape[1]\n",
    "    feature_names = X_data.columns.tolist()\n",
    "    \n",
    "    # Initialize population - each individual is a sorted list of feature indices\n",
    "    population = []\n",
    "    for _ in range(population_size):\n",
    "        subset = random.sample(range(n_features), subset_size)\n",
    "        subset.sort()\n",
    "        population.append(subset)\n",
    "    \n",
    "    def fitness(individual):\n",
    "        X_subset = X_data.iloc[:, individual]\n",
    "        \n",
    "        # Manual train/test split instead of cross-validation\n",
    "        X_train_subset, X_val_subset, y_train_subset, y_val_subset = train_test_split(\n",
    "            X_subset, y_data, test_size=0.2, random_state=42, stratify=y_data\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            model = CatBoostClassifier(\n",
    "                iterations=100,  # Reduce from 500 to speed up GA\n",
    "                learning_rate=0.1,\n",
    "                depth=6,\n",
    "                class_weights=class_weights_dict,\n",
    "                random_seed=42,\n",
    "                verbose=0        # Turn off verbosity completely            \n",
    "            )\n",
    "            \n",
    "            # Use a simple fit instead of cross_val_score\n",
    "            model.fit(X_train_subset, y_train_subset, \n",
    "                     eval_set=(X_val_subset, y_val_subset),\n",
    "                     early_stopping_rounds=20,\n",
    "                     verbose=False)\n",
    "            \n",
    "            # Get validation ROC AUC\n",
    "            auc = roc_auc_score(y_val_subset, model.predict_proba(X_val_subset)[:, 1])\n",
    "            print(f\"Feature subset evaluated: roc_auc = {auc:.4f}\")\n",
    "            return auc\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in fitness evaluation: {e}\")\n",
    "            return 0.0  # Return worst fitness on error\n",
    "    \n",
    "    # Creates a child by merging features from both parents and selecting a random subset\n",
    "    def crossover(p1, p2, subset_size):\n",
    "        combined = list(set(p1) | set(p2))  # Union of features\n",
    "        if len(combined) > subset_size:\n",
    "            child = sorted(random.sample(combined, subset_size))  # Ensure correct size\n",
    "        else:\n",
    "            child = sorted(combined)  # Keep all if below subset_size\n",
    "        return child\n",
    "\n",
    "    # Mutation replaces a random index in child if random.threshold is met\n",
    "    def mutation(individual, n_features, subset_size):\n",
    "        if random.random() < 0.1:  # 10% chance of mutation\n",
    "            i = random.randrange(subset_size)\n",
    "            available_features = set(range(n_features)) - set(individual)  # Exclude existing features\n",
    "            if available_features:  \n",
    "                new_feature = random.choice(list(available_features))\n",
    "                individual[i] = new_feature\n",
    "                individual.sort()\n",
    "        return individual\n",
    "\n",
    "\n",
    "    for i in range(n_generations):\n",
    "        print(f\"\\nGeneration {i+1}/{n_generations}\")\n",
    "        # Evaluate fitness of population\n",
    "        print(\"Evaluating fitness for each individual:\")\n",
    "        scored_population = []\n",
    "        for idx, ind in enumerate(population):\n",
    "            fitness_score = fitness(ind)\n",
    "            scored_population.append((fitness_score, ind))\n",
    "            print(f\"Individual {idx+1}/{len(population)}: Fitness = {fitness_score:.4f}\")\n",
    "        \n",
    "        scored_population.sort(key=lambda x: x[0], reverse=True)\n",
    "        best_subset = scored_population[0][1]\n",
    "        print(f\"\\nBest fitness in generation {i+1}: {scored_population[0][0]:.4f}\")\n",
    "        print(\"Current best features:\", [feature_names[i] for i in best_subset])\n",
    "        \n",
    "        # Selection: truncation selection (pick top half as survivors)\n",
    "        survivors = scored_population[: population_size // 2]\n",
    "        \n",
    "        # Then randomly select two parents (p1 & p2) from survivors for crossover + mutation\n",
    "        print(\"Creating new population...\")\n",
    "        new_pop = [s[1] for s in survivors]\n",
    "        while len(new_pop) < population_size:\n",
    "            print(\"Generating new individual...\")\n",
    "            \n",
    "            p1 = random.choice(survivors)[1]\n",
    "            p2 = random.choice(survivors)[1]\n",
    "            child = crossover(p1, p2, subset_size)\n",
    "            child = mutation(child, n_features, subset_size)\n",
    "            \n",
    "            child = list(set(child))  # remove duplicates if any\n",
    "            while len(child) < subset_size:  # if duplicates reduced size\n",
    "                child.append(random.randrange(n_features))\n",
    "            child.sort()\n",
    "            new_pop.append(child)\n",
    "            \n",
    "            print(\"New individual created! Happy birthday!\")\n",
    "        population = new_pop\n",
    "        print(\"Current best:\", max([(fitness(ind), ind) for ind in population], key=lambda x: x[0])[1])\n",
    "    \n",
    "    best = max([(fitness(ind), ind) for ind in population], key=lambda x: x[0])[1]\n",
    "    print(\"\\nFinal Selected Features:\")\n",
    "    for idx, feature_idx in enumerate(best, 1):\n",
    "        print(f\"{idx}. {feature_names[feature_idx]}\")\n",
    "    print(f\"\\nTotal features selected: {len(best)}\")\n",
    "    return best\n",
    "\n",
    "best_features = run_genetic_algorithm(X_train_scaled, y_train)\n",
    "X_train_ga = X_train_scaled.iloc[:, best_features]\n",
    "X_test_ga = X_test_scaled.iloc[:, best_features]\n",
    "model = CatBoostClassifier(\n",
    "            iterations=500,\n",
    "            learning_rate=0.1,\n",
    "            depth=6,\n",
    "            class_weights=class_weights_dict,\n",
    "            random_seed=42,\n",
    "            verbose=100\n",
    "        )\n",
    "model.fit(X_train_ga, y_train)\n",
    "y_pred = model.predict_proba(X_test_ga)[:, 1]\n",
    "print(\"Final features:\", best_features)\n",
    "print(\"Model ROC AUC with selected features:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total features selected: 30\n",
    "\n",
    "Final features: [16, 36, 43, 63, 71, 99, 104, 138, 153, 161, 169, 171, 175, 182, 186, 191, 251, 270, 275, 281, 314, 325, 328, 348, 355, 358, 397, 400, 419, 428] - change\n",
    "\n",
    "Model accuracy with selected features: 0.8880177464693332"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature count: 433\n",
      "GA-selected feature count: 30\n",
      "Training data shape after GA selection: (472432, 30)\n",
      "Testing data shape after GA selection: (506691, 30)\n",
      "\n",
      "GA-selected features:\n",
      "1. V42\n",
      "2. id_18\n",
      "3. V141\n",
      "4. card4\n",
      "5. V251\n",
      "6. V111\n",
      "7. V107\n",
      "8. V70\n",
      "9. V123\n",
      "10. V260\n",
      "11. TransactionDT\n",
      "12. card1\n",
      "13. addr1\n",
      "14. C4\n",
      "15. C8\n",
      "16. C13\n",
      "17. V150\n",
      "18. V171\n",
      "19. V179\n",
      "20. V186\n",
      "21. V222\n",
      "22. V234\n",
      "23. V237\n",
      "24. V263\n",
      "25. V270\n",
      "26. V273\n",
      "27. V322\n",
      "28. V326\n",
      "29. id_09\n",
      "30. id_22\n"
     ]
    }
   ],
   "source": [
    "# Use GA selected feature indices\n",
    "best_features = [16, 36, 43, 63, 71, 99, 104, 138, 153, 161, 169, 171, 175, 182, 186, 191, 251, 270, 275, 281, 314, 325, 328, 348, 355, 358, 397, 400, 419, 428]\n",
    "\n",
    "# Extract data with only selected features from GA\n",
    "X_train_ga = X_train_scaled.iloc[:, best_features]\n",
    "X_val_ga = X_val_scaled.iloc[:, best_features]\n",
    "X_test_ga = X_test.iloc[:, best_features]\n",
    "\n",
    "print(f\"Original feature count: {X_train_scaled.shape[1]}\")\n",
    "print(f\"GA-selected feature count: {X_train_ga.shape[1]}\")\n",
    "print(f\"Training data shape after GA selection: {X_train_ga.shape}\")\n",
    "print(f\"Testing data shape after GA selection: {X_test_ga.shape}\")\n",
    "\n",
    "# Display feature names selected by GA\n",
    "print(\"\\nGA-selected features:\")\n",
    "feature_names = X_train_scaled.columns\n",
    "selected_feature_names = [feature_names[i] for i in best_features]\n",
    "for i, feature in enumerate(selected_feature_names, 1):\n",
    "    print(f\"{i}. {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model with GA selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6603437\ttotal: 27.9ms\tremaining: 13.9s\n",
      "100:\tlearn: 0.4633426\ttotal: 2.63s\tremaining: 10.4s\n",
      "200:\tlearn: 0.4286210\ttotal: 5.26s\tremaining: 7.83s\n",
      "300:\tlearn: 0.4055292\ttotal: 7.84s\tremaining: 5.18s\n",
      "400:\tlearn: 0.3884742\ttotal: 10.7s\tremaining: 2.65s\n",
      "499:\tlearn: 0.3737480\ttotal: 13.2s\tremaining: 0us\n",
      "CatBoost Training Accuracy: 0.8851136248179632\n"
     ]
    }
   ],
   "source": [
    "y_train_flat = y_train.values.ravel()\n",
    "y_test_flat = y_test.values.ravel()\n",
    "\n",
    "baseline_model_ga = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    class_weights=class_weights_dict,\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")\n",
    "baseline_model_ga.fit(X_train_ga, y_train_flat)\n",
    "y_pred_cat = baseline_model_ga.predict_proba(X_test_ga)\n",
    "\n",
    "print(\"CatBoost Training ROC AUC:\", roc_auc_score(y_test_flat, y_pred_cat))\n",
    "baseline_model_ga.save_model('models/baseline_model.cbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cbm_ga_test = final_model.predict_proba(X_test_ga)\n",
    "fraud_probs = y_pred_cbm_ga_test[:, 1]\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'TransactionID': transaction_ids,\n",
    "    'isFraud': fraud_probs\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submissions/cbm_ga.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle results: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of GA results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... comparison with other methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSO and ACO for CatBoost hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pso_for_catboost_hyperparams(X_train_ga, y_train, X_test_ga, y_test, n_particles=10, n_iterations=5):\n",
    "    \"\"\"\n",
    "    Runs Particle Swarm Optimization (PSO) to find optimal hyperparameters for CatBoost using the provided training and testing data (already filtered by GA features).\n",
    "\n",
    "    Args:\n",
    "        X_train_ga: Training features (pandas DataFrame or numpy array) selected by GA.\n",
    "        y_train: Training target variable.\n",
    "        X_test_ga: Testing features (pandas DataFrame or numpy array) selected by GA.\n",
    "        y_test: Testing target variable.\n",
    "        n_particles: Number of particles in the swarm.\n",
    "        n_iterations: Number of iterations for PSO.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (best_params_dict, best_score)\n",
    "               - best_params_dict: Dictionary containing the best hyperparameter set found.\n",
    "               - best_score: The best AUC score achieved by PSO.\n",
    "    \"\"\"\n",
    "    print(f\"Starting PSO with {n_particles} particles and {n_iterations} iterations...\")\n",
    "\n",
    "    # Mapping for categorical parameters (indices):\n",
    "    grow_policy_map = ['SymmetricTree', 'Depthwise', 'Lossguide']\n",
    "    bootstrap_type_map = ['Bayesian', 'Bernoulli', 'MVS']\n",
    "    leaf_estimation_method_map = ['Newton', 'Gradient']\n",
    "    boosting_type_map = ['Ordered', 'Plain']\n",
    "\n",
    "    param_bounds_pso = {\n",
    "        # Key order must match the order in objective_function_pso's params array\n",
    "        'learning_rate': (0.01, 0.3),             # params[0]\n",
    "        'depth': (3, 10),                         # params[1] Integer\n",
    "        'l2_leaf_reg': (1.0, 10.0),               # params[2]\n",
    "        'iterations': (100, 1000),                # params[3] Integer\n",
    "        'grow_policy_idx': (0, len(grow_policy_map) - 1), # params[4] Integer index\n",
    "        'max_leaves': (4, 64),                    # params[5] Integer\n",
    "        'min_data_in_leaf': (1, 50),              # params[6] Integer\n",
    "        'random_strength': (0.1, 5.0),            # params[7]\n",
    "        'bagging_temperature': (0.0, 1.0),        # params[8]\n",
    "        'bootstrap_type_idx': (0, len(bootstrap_type_map) - 1), # params[9] Integer index\n",
    "        'subsample': (0.5, 1.0),                  # params[10] Used only if bootstrap_type is not Bayesian\n",
    "        'rsm': (0.5, 1.0),                        # params[11] aka colsample_bylevel\n",
    "        'leaf_estimation_method_idx': (0, len(leaf_estimation_method_map) - 1), # params[12] Integer index\n",
    "        'leaf_estimation_iterations': (1, 10),    # params[13] Integer\n",
    "        'boosting_type_idx': (0, len(boosting_type_map) - 1), # params[14] Integer index\n",
    "        'one_hot_max_size': (2, 30),              # params[15] Integer\n",
    "        'early_stopping_rounds': (10, 50)         # params[16] Integer, used in fit\n",
    "    }\n",
    "\n",
    "    # Ordered list of keys corresponding to the parameter order\n",
    "    param_keys = list(param_bounds_pso.keys())\n",
    "\n",
    "    # Define the objective function for PSO\n",
    "    def objective_function_pso(params):\n",
    "        # --- Parameter Extraction and Mapping ---\n",
    "        depth = int(round(params[param_keys.index('depth')]))\n",
    "        iterations = int(round(params[param_keys.index('iterations')]))\n",
    "        grow_policy_idx = int(round(params[param_keys.index('grow_policy_idx')]))\n",
    "        max_leaves = int(round(params[param_keys.index('max_leaves')]))\n",
    "        min_data_in_leaf = int(round(params[param_keys.index('min_data_in_leaf')]))\n",
    "        bootstrap_type_idx = int(round(params[param_keys.index('bootstrap_type_idx')]))\n",
    "        leaf_estimation_method_idx = int(round(params[param_keys.index('leaf_estimation_method_idx')]))\n",
    "        leaf_estimation_iterations = int(round(params[param_keys.index('leaf_estimation_iterations')]))\n",
    "        boosting_type_idx = int(round(params[param_keys.index('boosting_type_idx')]))\n",
    "        one_hot_max_size = int(round(params[param_keys.index('one_hot_max_size')]))\n",
    "        early_stopping_rounds = int(round(params[param_keys.index('early_stopping_rounds')]))\n",
    "        \n",
    "        grow_policy = grow_policy_map[grow_policy_idx]\n",
    "        bootstrap_type = bootstrap_type_map[bootstrap_type_idx]\n",
    "        leaf_estimation_method = leaf_estimation_method_map[leaf_estimation_method_idx]\n",
    "        boosting_type = boosting_type_map[boosting_type_idx]\n",
    "        \n",
    "        # --- Adjust incompatible parameters ---\n",
    "        # max_leaves is valid only with Lossguide tree growing. If not Lossguide, do not include max_leaves.\n",
    "        if grow_policy != \"Lossguide\":\n",
    "            max_leaves = None\n",
    "        # Ordered boosting is supported only for symmetric trees; change to Plain if needed.\n",
    "        if boosting_type == \"Ordered\" and grow_policy != \"SymmetricTree\":\n",
    "            boosting_type = \"Plain\"\n",
    "        \n",
    "        # --- Build CatBoost Params ---\n",
    "        cb_params = {\n",
    "            'learning_rate': params[param_keys.index('learning_rate')],\n",
    "            'depth': depth,\n",
    "            'l2_leaf_reg': params[param_keys.index('l2_leaf_reg')],\n",
    "            'iterations': iterations,\n",
    "            'grow_policy': grow_policy,\n",
    "            **({'max_leaves': max_leaves} if max_leaves is not None else {}),\n",
    "            'min_data_in_leaf': min_data_in_leaf,\n",
    "            'random_strength': params[param_keys.index('random_strength')],\n",
    "            'bootstrap_type': bootstrap_type,\n",
    "            'rsm': params[param_keys.index('rsm')],\n",
    "            'leaf_estimation_method': leaf_estimation_method,\n",
    "            'leaf_estimation_iterations': leaf_estimation_iterations,\n",
    "            'boosting_type': boosting_type,\n",
    "            'one_hot_max_size': one_hot_max_size,\n",
    "            'loss_function': 'Logloss',\n",
    "            'eval_metric': 'AUC',\n",
    "            'verbose': 0,\n",
    "            'random_state': 42,\n",
    "            'class_weights': class_weights_dict # For class imbalance\n",
    "        }\n",
    "        \n",
    "        # Handle parameter dependencies for bootstrap_type\n",
    "        if bootstrap_type == 'Bayesian':\n",
    "            cb_params['bagging_temperature'] = params[param_keys.index('bagging_temperature')]\n",
    "        elif bootstrap_type in ['Bernoulli', 'MVS']:\n",
    "            cb_params['subsample'] = params[param_keys.index('subsample')]\n",
    "        \n",
    "        # --- Train and Evaluate ---\n",
    "        model = CatBoostClassifier(**cb_params)\n",
    "        try:\n",
    "            model.fit(X_train_ga, y_train,\n",
    "                      eval_set=(X_test_ga, y_test),\n",
    "                      early_stopping_rounds=early_stopping_rounds,\n",
    "                      verbose=0)\n",
    "            y_pred_proba = model.predict_proba(X_test_ga)[:, 1]\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Exception during model training/evaluation: {e}\")\n",
    "            print(f\"Params causing issue: {cb_params}\")\n",
    "            auc = 0.0\n",
    "        return auc\n",
    "\n",
    "    # Extract bounds for pyswarm\n",
    "    lb = [param_bounds_pso[k][0] for k in param_keys]\n",
    "    ub = [param_bounds_pso[k][1] for k in param_keys]\n",
    "\n",
    "    # Run PSO\n",
    "    best_params_pso_vals, best_score_pso = pso(objective_function_pso, lb, ub, swarmsize=n_particles, maxiter=n_iterations)\n",
    "\n",
    "    # --- Process Results ---\n",
    "    # Map best_params_pso_vals back to dictionary\n",
    "    best_params_pso_dict = {}\n",
    "    for i, key in enumerate(param_keys):\n",
    "        val = best_params_pso_vals[i]\n",
    "        if key in ['depth', 'iterations', 'grow_policy_idx', 'max_leaves', 'min_data_in_leaf',\n",
    "                   'bootstrap_type_idx', 'leaf_estimation_method_idx', 'leaf_estimation_iterations',\n",
    "                   'boosting_type_idx', 'one_hot_max_size', 'early_stopping_rounds']:\n",
    "            best_params_pso_dict[key] = int(round(val))\n",
    "        else:\n",
    "            best_params_pso_dict[key] = val\n",
    "\n",
    "    # Map indices back for categorical features\n",
    "    best_params_pso_dict['grow_policy'] = grow_policy_map[best_params_pso_dict['grow_policy_idx']]\n",
    "    best_params_pso_dict['bootstrap_type'] = bootstrap_type_map[best_params_pso_dict['bootstrap_type_idx']]\n",
    "    best_params_pso_dict['leaf_estimation_method'] = leaf_estimation_method_map[best_params_pso_dict['leaf_estimation_method_idx']]\n",
    "    best_params_pso_dict['boosting_type'] = boosting_type_map[best_params_pso_dict['boosting_type_idx']]\n",
    "\n",
    "    # Store the early stopping rounds value separately as it's used in fit, not constructor\n",
    "    best_early_stopping_rounds = best_params_pso_dict['early_stopping_rounds']\n",
    "\n",
    "    # Remove index keys and early stopping rounds from the main dict\n",
    "    keys_to_remove = ['grow_policy_idx', 'bootstrap_type_idx', 'leaf_estimation_method_idx', 'boosting_type_idx', 'early_stopping_rounds']\n",
    "    for key in keys_to_remove:\n",
    "       best_params_pso_dict.pop(key, None)\n",
    "\n",
    "    # Handle conditional subsample: Remove if not needed, ensure exists if needed\n",
    "    if best_params_pso_dict['bootstrap_type'] not in ['Bernoulli', 'MVS']:\n",
    "        best_params_pso_dict.pop('subsample', None)\n",
    "    elif 'subsample' not in best_params_pso_dict:\n",
    "         # If needed but missing (e.g., boundary issue), assign a default or average\n",
    "         best_params_pso_dict['subsample'] = np.mean(param_bounds_pso['subsample'])\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(\"PSO Finished.\")\n",
    "    print(f\"Best AUC score found by PSO: {best_score_pso:.6f}\")\n",
    "    print(\"Best CatBoost Parameters (excluding early_stopping_rounds):\")\n",
    "    for key, val in best_params_pso_dict.items():\n",
    "        print(f\"  {key}: {val}\")\n",
    "    print(f\"Best early_stopping_rounds: {best_early_stopping_rounds}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Add early stopping rounds back for potential direct use later if needed\n",
    "    best_params_pso_dict_final = best_params_pso_dict.copy()\n",
    "    best_params_pso_dict_final['early_stopping_rounds'] = best_early_stopping_rounds\n",
    "\n",
    "    return best_params_pso_dict_final, best_score_pso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ACO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACO_HyperparameterOptimizer:\n",
    "    \"\"\"\n",
    "    Ant Colony Optimization for Hyperparameter Tuning.\n",
    "\n",
    "    Attributes:\n",
    "        param_grid (dict): Dictionary where keys are hyperparameter names\n",
    "                           and values are lists of discrete values to explore.\n",
    "        objective_function (callable): A function that takes a dictionary of\n",
    "                                      hyperparameters and returns a score to maximize.\n",
    "        n_ants (int): Number of ants (solutions generated per iteration).\n",
    "        n_iterations (int): Number of optimization iterations.\n",
    "        alpha (float): Pheromone influence factor.\n",
    "        beta (float): Heuristic influence factor (currently unused, set to 1).\n",
    "        rho (float): Pheromone evaporation rate (0 < rho <= 1).\n",
    "        Q (float): Pheromone deposit constant.\n",
    "        min_pheromone (float): Minimum pheromone level to prevent stagnation.\n",
    "        pheromones (dict): Nested dictionary storing pheromone levels for each parameter choice.\n",
    "        global_best_score (float): Best score found across all iterations.\n",
    "        global_best_params (dict): Hyperparameter set corresponding to the best score.\n",
    "    \"\"\"\n",
    "    def __init__(self, param_grid, objective_function, n_ants, n_iterations,\n",
    "                 alpha=1.0, beta=1.0, rho=0.1, Q=1.0, min_pheromone=0.01):\n",
    "        \"\"\"\n",
    "        Initializes the ACO optimizer.\n",
    "        \"\"\"\n",
    "        self.param_grid = param_grid\n",
    "        self.objective_function = objective_function\n",
    "        self.n_ants = n_ants\n",
    "        self.n_iterations = n_iterations\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta  # Heuristic factor (often kept simple for HP tuning)\n",
    "        self.rho = rho    # Evaporation rate\n",
    "        self.Q = Q        # Pheromone deposit constant\n",
    "        self.min_pheromone = min_pheromone # Minimum pheromone level\n",
    "\n",
    "        self.param_names = list(self.param_grid.keys())\n",
    "        self.pheromones = self._initialize_pheromones()\n",
    "\n",
    "        self.global_best_score = -np.inf\n",
    "        self.global_best_params = None\n",
    "\n",
    "    def _initialize_pheromones(self):\n",
    "        \"\"\"\n",
    "        Initializes pheromone trails with a constant value for all parameter choices.\n",
    "        \"\"\"\n",
    "        pheromones = {}\n",
    "        initial_pheromone = 1.0 # Start with a neutral pheromone level\n",
    "        for param, values in self.param_grid.items():\n",
    "            pheromones[param] = {value: initial_pheromone for value in values}\n",
    "        return pheromones\n",
    "\n",
    "    def _select_next_node(self, param_name):\n",
    "        \"\"\"\n",
    "        Selects a value for a given parameter based on pheromone levels.\n",
    "        Uses a probabilistic choice mechanism influenced by pheromones.\n",
    "        \"\"\"\n",
    "        pheromone_values = self.pheromones[param_name]\n",
    "        choices = list(pheromone_values.keys())\n",
    "        current_pheromones = np.array([pheromone_values[choice] for choice in choices])\n",
    "\n",
    "        # Heuristic information (tau^alpha * eta^beta)\n",
    "        # For hyperparameter tuning, heuristic info (eta) is often uniform (beta=0 or eta=1)\n",
    "        # unless prior knowledge exists. We'll use beta=1 but eta=1 implicitly.\n",
    "        selection_probs = current_pheromones ** self.alpha # * (heuristic ** self.beta)\n",
    "\n",
    "        # Handle potential division by zero if all probs are zero (e.g., early stage)\n",
    "        prob_sum = np.sum(selection_probs)\n",
    "        if prob_sum == 0:\n",
    "            # If sum is zero, choose uniformly\n",
    "            selection_probs = np.ones(len(choices)) / len(choices)\n",
    "        else:\n",
    "            selection_probs = selection_probs / prob_sum\n",
    "\n",
    "        # Choose a value based on calculated probabilities\n",
    "        chosen_value = np.random.choice(choices, p=selection_probs)\n",
    "        return chosen_value\n",
    "\n",
    "    def _construct_solution(self):\n",
    "        \"\"\"\n",
    "        Constructs a complete hyperparameter set (solution) for a single ant.\n",
    "        \"\"\"\n",
    "        solution = {}\n",
    "        for param_name in self.param_names:\n",
    "            solution[param_name] = self._select_next_node(param_name)\n",
    "        return solution\n",
    "\n",
    "    def _update_pheromones(self, ant_solutions, ant_scores):\n",
    "        \"\"\"\n",
    "        Updates pheromone levels based on evaporation and deposition from ant solutions.\n",
    "        \"\"\"\n",
    "        # 1. Evaporation\n",
    "        for param, values in self.pheromones.items():\n",
    "            for value in values:\n",
    "                self.pheromones[param][value] *= (1.0 - self.rho)\n",
    "                # Enforce minimum pheromone level\n",
    "                self.pheromones[param][value] = max(self.pheromones[param][value], self.min_pheromone)\n",
    "\n",
    "        # 2. Deposition\n",
    "        # Deposit pheromone based on the quality of solutions found\n",
    "        # More sophisticated strategies exist (e.g., only best ant deposits, elitism)\n",
    "        # Here, all ants deposit based on their score\n",
    "        for i in range(self.n_ants):\n",
    "            solution = ant_solutions[i]\n",
    "            score = ant_scores[i]\n",
    "\n",
    "            # Normalize score or use directly? Depends on score range.\n",
    "            # Assuming score is something like AUC (0 to 1), direct use might be okay.\n",
    "            # We use Q as a scaling factor.\n",
    "            if score > -np.inf: # Only deposit if the evaluation was successful\n",
    "                delta_pheromone = self.Q * score # Simple proportional deposit\n",
    "\n",
    "                for param_name, value in solution.items():\n",
    "                    # Check if the parameter/value exists (it should)\n",
    "                    if param_name in self.pheromones and value in self.pheromones[param_name]:\n",
    "                        self.pheromones[param_name][value] += delta_pheromone\n",
    "                    else:\n",
    "                        # This case should ideally not happen if grid is consistent\n",
    "                         print(f\"Warning: Parameter '{param_name}' or value '{value}' not found in pheromone trails during deposition.\")\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Executes the ACO optimization process.\n",
    "        \"\"\"\n",
    "        print(f\"Starting ACO: {self.n_iterations} iterations, {self.n_ants} ants/iteration.\")\n",
    "        print(f\"Params: alpha={self.alpha}, beta={self.beta}, rho={self.rho}, Q={self.Q}\")\n",
    "\n",
    "        for iteration in range(self.n_iterations):\n",
    "            ant_solutions = []\n",
    "            ant_scores = []\n",
    "\n",
    "            # Generate solutions for all ants\n",
    "            for ant in range(self.n_ants):\n",
    "                solution = self._construct_solution()\n",
    "                try:\n",
    "                    score = self.objective_function(solution.copy()) # Pass a copy\n",
    "                    if score is None or not np.isfinite(score):\n",
    "                       # Handle cases where objective function fails or returns invalid score\n",
    "                       print(f\"Warning: Objective function returned invalid score ({score}) for params: {solution}. Assigning low score.\")\n",
    "                       score = -np.inf\n",
    "                except Exception as e:\n",
    "                    print(f\"Error evaluating solution: {solution}\")\n",
    "                    print(f\"Exception: {e}\")\n",
    "                    score = -np.inf # Penalize errors heavily\n",
    "\n",
    "                ant_solutions.append(solution)\n",
    "                ant_scores.append(score)\n",
    "\n",
    "                # Update global best if current ant is better\n",
    "                if score > self.global_best_score:\n",
    "                    self.global_best_score = score\n",
    "                    self.global_best_params = solution\n",
    "                    print(f\"Iteration {iteration+1}, Ant {ant+1}: New best score! -> {self.global_best_score:.6f}\")\n",
    "\n",
    "            # Update pheromone trails based on the iteration's results\n",
    "            self._update_pheromones(ant_solutions, ant_scores)\n",
    "\n",
    "            avg_score = np.mean([s for s in ant_scores if s > -np.inf]) if any(s > -np.inf for s in ant_scores) else -np.inf\n",
    "            print(f\"Iteration {iteration+1}/{self.n_iterations} finished. Avg Score: {avg_score:.6f}. Best Score so far: {self.global_best_score:.6f}\")\n",
    "\n",
    "        print(\"-\" * 30)\n",
    "        print(\"ACO Finished.\")\n",
    "        if self.global_best_params:\n",
    "            print(f\"Best score found: {self.global_best_score:.6f}\")\n",
    "            print(\"Best parameters found:\")\n",
    "            for param, value in self.global_best_params.items():\n",
    "                print(f\"  {param}: {value}\")\n",
    "        else:\n",
    "            print(\"ACO did not find a valid solution.\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        return self.global_best_params, self.global_best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_aco_for_catboost_hyperparams(X_train_ga, y_train, X_test_ga, y_test,\n",
    "                                     n_ants=10, n_iterations=5,\n",
    "                                     alpha=1.0, beta=1.0, rho=0.1, Q=1.0): # Add ACO params\n",
    "    \"\"\"\n",
    "    Runs Ant Colony Optimization (ACO) using the implemented class to find\n",
    "    optimal hyperparameters for CatBoost using the provided GA-filtered data.\n",
    "\n",
    "    Args:\n",
    "        X_train_ga: Training features (pandas DataFrame or numpy array) selected by GA.\n",
    "        y_train: Training target variable.\n",
    "        X_test_ga: Testing features (pandas DataFrame or numpy array) selected by GA.\n",
    "        y_test: Testing target variable.\n",
    "        n_ants (int): Number of ants (solutions per iteration).\n",
    "        n_iterations (int): Number of iterations for ACO.\n",
    "        alpha (float): Pheromone influence factor for ACO.\n",
    "        beta (float): Heuristic influence factor for ACO (currently unused).\n",
    "        rho (float): Pheromone evaporation rate for ACO.\n",
    "        Q (float): Pheromone deposit constant for ACO.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        tuple: (best_params_dict, best_score)\n",
    "               - best_params_dict: Dictionary containing the best hyperparameter set found.\n",
    "               - best_score: The best AUC score achieved by ACO.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Define Parameter Grid (same as before) ---\n",
    "    param_grid_aco = {\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2, 0.3],\n",
    "        'depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'l2_leaf_reg': [1.0, 3.0, 5.0, 7.0, 10.0],\n",
    "        'iterations': [100, 200, 300, 500, 700, 1000],\n",
    "        'grow_policy': ['SymmetricTree', 'Depthwise', 'Lossguide'],\n",
    "        'max_leaves': [8, 16, 32, 64],\n",
    "        'min_data_in_leaf': [1, 5, 10, 20, 50],\n",
    "        'random_strength': [0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "        'bagging_temperature': [0.0, 0.2, 0.5, 0.8, 1.0],\n",
    "        'bootstrap_type': ['Bayesian', 'Bernoulli', 'MVS'],\n",
    "        'subsample': [0.6, 0.7, 0.8, 0.9, 1.0], # Used only if bootstrap_type is not Bayesian\n",
    "        'rsm': [0.6, 0.7, 0.8, 0.9, 1.0], # colsample_bylevel\n",
    "        'leaf_estimation_method': ['Newton', 'Gradient'],\n",
    "        'leaf_estimation_iterations': [1, 3, 5, 10],\n",
    "        'boosting_type': ['Ordered', 'Plain'],\n",
    "        'one_hot_max_size': [2, 10, 20, 30],\n",
    "        'early_stopping_rounds': [10, 20, 30, 50], # Used in fit\n",
    "        'class_weights': class_weights_dict\n",
    "    }\n",
    "\n",
    "    # --- Define Objective Function (same as before) ---\n",
    "    def objective_function_aco(params):\n",
    "        # params is a dictionary constructed by the ACO framework for one ant\n",
    "        cb_params = params.copy()\n",
    "        early_stopping_rounds = cb_params.pop('early_stopping_rounds', 30) # Default if missing\n",
    "\n",
    "        # Handle parameter dependencies\n",
    "        bootstrap_type = cb_params.get('bootstrap_type', 'Bayesian')\n",
    "        if bootstrap_type == 'Bayesian':\n",
    "            # Keep bagging_temperature only for Bayesian bootstrap\n",
    "            if 'bagging_temperature' not in cb_params:\n",
    "                cb_params['bagging_temperature'] = 0.5  # default value\n",
    "            if 'subsample' in cb_params:\n",
    "                cb_params.pop('subsample')\n",
    "        else:\n",
    "            # For Bernoulli and MVS, use subsample and remove bagging_temperature\n",
    "            if 'bagging_temperature' in cb_params:\n",
    "                cb_params.pop('bagging_temperature')\n",
    "            if 'subsample' not in cb_params:\n",
    "                cb_params['subsample'] = 0.8  # default value\n",
    "\n",
    "        cb_params.update({\n",
    "            'loss_function': 'Logloss',\n",
    "            'eval_metric': 'AUC',\n",
    "            'verbose': 0,\n",
    "            'random_state': 42\n",
    "        })\n",
    "\n",
    "        model = CatBoostClassifier(**cb_params)\n",
    "        try:\n",
    "            model.fit(X_train_ga, y_train,\n",
    "                    eval_set=(X_test_ga, y_test),\n",
    "                    early_stopping_rounds=early_stopping_rounds,\n",
    "                    verbose=0)\n",
    "            y_pred_proba = model.predict_proba(X_test_ga)[:, 1]\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            if not np.isfinite(auc):\n",
    "                auc = 0.0\n",
    "        except Exception as e:\n",
    "            auc = 0.0\n",
    "\n",
    "        return auc\n",
    "\n",
    "    # --- Instantiate and Run ACO ---\n",
    "    aco_optimizer = ACO_HyperparameterOptimizer(\n",
    "        param_grid=param_grid_aco,\n",
    "        objective_function=objective_function_aco,\n",
    "        n_ants=n_ants,\n",
    "        n_iterations=n_iterations,\n",
    "        alpha=alpha,\n",
    "        beta=beta,\n",
    "        rho=rho,\n",
    "        Q=Q\n",
    "    )\n",
    "\n",
    "    best_params_aco, best_score_aco = aco_optimizer.run() # Run the optimization\n",
    "\n",
    "    # --- Process and Return Results ---\n",
    "    # The run method already prints results. We just return them.\n",
    "    # Note: best_params_aco will include 'early_stopping_rounds' if found.\n",
    "    return best_params_aco, best_score_aco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run PSO and ACO optimizations using GA-selected features\n",
    "\n",
    "Now we'll run both PSO and ACO optimization algorithms on the same feature set selected by GA. This ensures fair comparison between optimization methods while benefiting from the dimension reduction provided by GA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PSO optimization on GA-selected features\n",
    "print(\"Starting PSO optimization on GA-selected features...\")\n",
    "best_pso_params, best_pso_score = run_pso_for_catboost_hyperparams(\n",
    "    X_train_ga, y_train, X_test_ga, y_test,\n",
    "    n_particles=10,\n",
    "    n_iterations=20\n",
    ")\n",
    "\n",
    "# Fix incompatible parameters in PSO results\n",
    "if 'grow_policy' in best_pso_params and best_pso_params['grow_policy'] != 'Lossguide' and 'boosting_type' in best_pso_params and best_pso_params['boosting_type'] == 'Ordered':\n",
    "    print(\"Warning: Ordered boosting not supported for non-symmetric trees. Changing boosting_type to 'Plain'\")\n",
    "    best_pso_params['boosting_type'] = 'Plain'\n",
    "\n",
    "# Fix bootstrap type and bagging temperature incompatibility\n",
    "if 'bootstrap_type' in best_pso_params and best_pso_params['bootstrap_type'] != 'Bayesian' and 'bagging_temperature' in best_pso_params:\n",
    "    print(\"Warning: Bagging temperature only available for Bayesian bootstrap. Removing parameter.\")\n",
    "    best_pso_params.pop('bagging_temperature', None)\n",
    "\n",
    "# Run ACO optimization on the same GA-selected features\n",
    "print(\"\\nStarting ACO optimization on GA-selected features...\")\n",
    "best_aco_params, best_aco_score = run_aco_for_catboost_hyperparams(\n",
    "    X_train_ga, y_train, X_test_ga, y_test,\n",
    "    n_ants=10,\n",
    "    n_iterations=20,\n",
    "    alpha=1.0,\n",
    "    beta=1.0,\n",
    "    rho=0.1,\n",
    "    Q=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Needs Update\n",
    "\n",
    "PSO Finished.\n",
    "Best AUC score found by PSO: 0.706496\n",
    "Best CatBoost Parameters (excluding early_stopping_rounds):\n",
    "  learning_rate: 0.01\n",
    "  depth: 3\n",
    "  l2_leaf_reg: 2.89086081049249\n",
    "  iterations: 100\n",
    "  max_leaves: 34\n",
    "  min_data_in_leaf: 42\n",
    "  random_strength: 3.040765804548009\n",
    "  bagging_temperature: 0.7262563991935348\n",
    "  subsample: 0.5208110746308559\n",
    "  rsm: 0.9052587769528273\n",
    "  leaf_estimation_iterations: 3\n",
    "  one_hot_max_size: 12\n",
    "  grow_policy: SymmetricTree\n",
    "  bootstrap_type: Bernoulli\n",
    "  leaf_estimation_method: Gradient\n",
    "  boosting_type: Plain\n",
    "Best early_stopping_rounds: 36\n",
    "------------------------------\n",
    "\n",
    "ACO Finished.\n",
    "Best score found: 0.937932\n",
    "Best parameters found:\n",
    "  learning_rate: 0.3\n",
    "  depth: 9\n",
    "  l2_leaf_reg: 7.0\n",
    "  iterations: 1000\n",
    "  grow_policy: Lossguide\n",
    "  max_leaves: 64\n",
    "  min_data_in_leaf: 20\n",
    "  random_strength: 0.1\n",
    "  bagging_temperature: 0.8\n",
    "  bootstrap_type: Bayesian\n",
    "  subsample: 0.7\n",
    "  rsm: 0.9\n",
    "  leaf_estimation_method: Newton\n",
    "  leaf_estimation_iterations: 10\n",
    "  boosting_type: Plain\n",
    "  one_hot_max_size: 30\n",
    "  early_stopping_rounds: 20\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train and evaluate final models with optimized parameters on GA-selected features\n",
    "\n",
    "Both PSO and ACO have determined optimal hyperparameters for CatBoost. We'll now train final models with these parameters using only the GA-selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6651351\tbest: 0.6651351 (0)\ttotal: 14.9ms\tremaining: 1.48s\n",
      "99:\ttest: 0.7679732\tbest: 0.7679732 (99)\ttotal: 1.42s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.767973236\n",
      "bestIteration = 99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train final model with PSO hyperparameters on GA-selected features\n",
    "ps0_params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'depth': 3,\n",
    "    'l2_leaf_reg': 2.89086081049249,\n",
    "    'iterations': 100,\n",
    "    'min_data_in_leaf': 42,\n",
    "    'random_strength': 3.040765804548009,\n",
    "    'subsample': 0.5208110746308559,\n",
    "    'rsm': 0.9052587769528273,\n",
    "    'leaf_estimation_iterations': 3,\n",
    "    'one_hot_max_size': 12,\n",
    "    'grow_policy': 'SymmetricTree',\n",
    "    'bootstrap_type': 'Bernoulli',\n",
    "    'leaf_estimation_method': 'Gradient',\n",
    "    'boosting_type': 'Plain'\n",
    "}\n",
    "final_esr_pso = 36\n",
    "final_model_pso = CatBoostClassifier(\n",
    "    **ps0_params,\n",
    "    random_state=42,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC'\n",
    ")\n",
    "final_model_pso.fit(\n",
    "    X_train_ga, y_train,\n",
    "    eval_set=(X_test_ga, y_test),\n",
    "    early_stopping_rounds=final_esr_pso,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "final_model_pso.save_model('final_model_pso.cbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6156219\tbest: 0.6156219 (0)\ttotal: 46ms\tremaining: 45.9s\n",
      "100:\ttest: 0.8928422\tbest: 0.8928422 (100)\ttotal: 8.67s\tremaining: 1m 17s\n",
      "200:\ttest: 0.9129015\tbest: 0.9129519 (197)\ttotal: 16.7s\tremaining: 1m 6s\n",
      "300:\ttest: 0.9220474\tbest: 0.9220474 (300)\ttotal: 24.2s\tremaining: 56.2s\n",
      "400:\ttest: 0.9268324\tbest: 0.9268822 (399)\ttotal: 31.4s\tremaining: 47s\n",
      "500:\ttest: 0.9312946\tbest: 0.9313299 (498)\ttotal: 38.8s\tremaining: 38.7s\n",
      "600:\ttest: 0.9348440\tbest: 0.9348440 (600)\ttotal: 46s\tremaining: 30.6s\n",
      "700:\ttest: 0.9366149\tbest: 0.9366353 (698)\ttotal: 53.3s\tremaining: 22.7s\n",
      "800:\ttest: 0.9386975\tbest: 0.9386975 (800)\ttotal: 1m\tremaining: 14.9s\n",
      "900:\ttest: 0.9399880\tbest: 0.9400223 (899)\ttotal: 1m 7s\tremaining: 7.38s\n",
      "999:\ttest: 0.9415066\tbest: 0.9415066 (999)\ttotal: 1m 14s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9415065692\n",
      "bestIteration = 999\n",
      "\n",
      "\n",
      "Training complete for both PSO and ACO optimized models using GA-selected features.\n"
     ]
    }
   ],
   "source": [
    "# Train final model with ACO hyperparameters on GA-selected features\n",
    "aco_params = {\n",
    "    'learning_rate': 0.3,\n",
    "    'depth': 9,\n",
    "    'l2_leaf_reg': 7.0,\n",
    "    'iterations': 1000,\n",
    "    'grow_policy': 'Lossguide',\n",
    "    'max_leaves': 64,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'random_strength': 0.1,\n",
    "    'bagging_temperature': 0.8,\n",
    "    'bootstrap_type': 'Bayesian',\n",
    "    'rsm': 0.9,\n",
    "    'leaf_estimation_method': 'Newton',\n",
    "    'leaf_estimation_iterations': 10,\n",
    "    'boosting_type': 'Plain',\n",
    "    'one_hot_max_size': 30\n",
    "}\n",
    "final_esr_aco = 20\n",
    "final_model_aco = CatBoostClassifier(\n",
    "    **aco_params,\n",
    "    random_state=42,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC'\n",
    ")\n",
    "final_model_aco.fit(\n",
    "    X_train_ga, y_train,\n",
    "    eval_set=(X_test_ga, y_test),\n",
    "    early_stopping_rounds=final_esr_aco,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "final_model_aco.save_model('final_model_aco.cbm')\n",
    "print(\"\\nTraining complete for both PSO and ACO optimized models using GA-selected features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of CatBoost & NIC Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance analysis for GA-selected features\n",
    "\n",
    "Let's analyze which of the GA-selected features are most important according to our optimized models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Most Important GA-Selected Features:\n",
      "      feature  pso_importance  aco_importance  avg_importance\n",
      "        card1        0.126489       24.342434       12.234461\n",
      "         V186       21.733241        1.682403       11.707822\n",
      "          C13        2.151638       14.108944        8.130291\n",
      "        addr1        2.219835       13.340503        7.780169\n",
      "TransactionDT        0.160361       15.319888        7.740124\n",
      "           C8       11.618578        2.638107        7.128342\n",
      "         V273       12.775883        1.350997        7.063440\n",
      "         V263       12.755645        0.621487        6.688566\n",
      "          V49        1.866770       10.629125        6.247947\n",
      "           C4        8.009132        1.839801        4.924467\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(12, 8))\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train_ga.columns,\n",
    "    'pso_importance': final_model_pso.get_feature_importance(),\n",
    "    'aco_importance': final_model_aco.get_feature_importance()\n",
    "})\n",
    "\n",
    "# Sort by average importance\n",
    "feature_importance['avg_importance'] = (feature_importance['pso_importance'] + \n",
    "                                       feature_importance['aco_importance']) / 2\n",
    "feature_importance = feature_importance.sort_values('avg_importance', ascending=False)\n",
    "\n",
    "# Reshape for seaborn\n",
    "plot_data = pd.melt(\n",
    "    feature_importance, \n",
    "    id_vars=['feature'], \n",
    "    value_vars=['pso_importance', 'aco_importance'],\n",
    "    var_name='model', \n",
    "    value_name='importance'\n",
    ")\n",
    "plot_data['model'] = plot_data['model'].map({'pso_importance': 'PSO', 'aco_importance': 'ACO'})\n",
    "\n",
    "# Top 15 features\n",
    "top_features = feature_importance.head(15)['feature'].tolist()\n",
    "plot_data_top = plot_data[plot_data['feature'].isin(top_features)]\n",
    "\n",
    "# Plot\n",
    "sns.barplot(\n",
    "    data=plot_data_top, \n",
    "    x='importance', \n",
    "    y='feature', \n",
    "    hue='model',\n",
    "    palette=['#2ecc71', '#e74c3c']\n",
    ")\n",
    "plt.title('Top 15 Important Features (GA-selected)', fontsize=14)\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.legend(title='')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the top features and their importance scores\n",
    "print(\"\\nTop 10 Most Important GA-Selected Features:\")\n",
    "print(feature_importance[['feature', 'pso_importance', 'aco_importance', 'avg_importance']].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare PSO, ACO, and baseline results on GA-selected features\n",
    "\n",
    "Now we'll do a comprehensive comparison of all three approaches: baseline CatBoost, PSO-optimized CatBoost, and ACO-optimized CatBoost, all using the same GA-selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models on GA-selected features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance Comparison on GA-Selected Features:\n",
      "          accuracy  precision  recall      f1     auc  avg_precision\n",
      "Baseline    0.8851     0.1976  0.7459  0.3124  0.9031         0.5265\n",
      "PSO         0.9650     0.0000  0.0000  0.0000  0.7680         0.2660\n",
      "ACO         0.9822     0.9039  0.5488  0.6829  0.9415         0.7456\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Improvement Summary on GA-Selected Features:\n",
      "\n",
      "PSO vs Baseline:\n",
      "  accuracy: 0.0799 absolute improvement (9.03% relative improvement)\n",
      "  precision: -0.1976 absolute improvement (-100.00% relative improvement)\n",
      "  recall: -0.7459 absolute improvement (-100.00% relative improvement)\n",
      "  f1: -0.3124 absolute improvement (-100.00% relative improvement)\n",
      "  auc: -0.1351 absolute improvement (-14.96% relative improvement)\n",
      "  avg_precision: -0.2605 absolute improvement (-49.48% relative improvement)\n",
      "\n",
      "ACO vs Baseline:\n",
      "  accuracy: 0.0971 absolute improvement (10.97% relative improvement)\n",
      "  precision: 0.7063 absolute improvement (357.46% relative improvement)\n",
      "  recall: -0.1972 absolute improvement (-26.44% relative improvement)\n",
      "  f1: 0.3705 absolute improvement (118.58% relative improvement)\n",
      "  auc: 0.0384 absolute improvement (4.26% relative improvement)\n",
      "  avg_precision: 0.2191 absolute improvement (41.61% relative improvement)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "# Evaluate all three models\n",
    "print(\"Evaluating models on GA-selected features:\")\n",
    "\n",
    "# Get predictions for all models\n",
    "y_pred_baseline = baseline_model_ga.predict(X_test_ga)\n",
    "y_pred_pso = final_model_pso.predict(X_test_ga)\n",
    "y_pred_aco = final_model_aco.predict(X_test_ga)\n",
    "\n",
    "y_pred_proba_baseline = baseline_model_ga.predict_proba(X_test_ga)[:, 1]\n",
    "y_pred_proba_pso = final_model_pso.predict_proba(X_test_ga)[:, 1]\n",
    "y_pred_proba_aco = final_model_aco.predict_proba(X_test_ga)[:, 1]\n",
    "\n",
    "# Calculate metrics for all models\n",
    "models = {\n",
    "    'Baseline': (y_pred_baseline, y_pred_proba_baseline),\n",
    "    'PSO': (y_pred_pso, y_pred_proba_pso),\n",
    "    'ACO': (y_pred_aco, y_pred_proba_aco)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, (y_pred, y_pred_proba) in models.items():\n",
    "    results[name] = {\n",
    "        'accuracy': metrics.accuracy_score(y_test, y_pred),\n",
    "        'precision': metrics.precision_score(y_test, y_pred),\n",
    "        'recall': metrics.recall_score(y_test, y_pred),\n",
    "        'f1': metrics.f1_score(y_test, y_pred),\n",
    "        'auc': metrics.roc_auc_score(y_test, y_pred_proba),\n",
    "        'avg_precision': metrics.average_precision_score(y_test, y_pred_proba)\n",
    "    }\n",
    "\n",
    "# Display results as a table\n",
    "comparison_df = pd.DataFrame(results).T\n",
    "comparison_df = comparison_df.round(4)\n",
    "print(\"\\nPerformance Comparison on GA-Selected Features:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# ROC curves comparison\n",
    "plt.figure(figsize=(10, 8))\n",
    "for name, (_, y_pred_proba) in models.items():\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{name} (AUC = {auc:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison (GA-Selected Features)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "for name, (_, y_pred_proba) in models.items():\n",
    "    precision, recall, _ = metrics.precision_recall_curve(y_test, y_pred_proba)\n",
    "    avg_precision = metrics.average_precision_score(y_test, y_pred_proba)\n",
    "    plt.plot(recall, precision, lw=2, label=f'{name} (AP = {avg_precision:.4f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves (GA-Selected Features)')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary of improvements\n",
    "print(\"\\nImprovement Summary on GA-Selected Features:\")\n",
    "baseline_metrics = results['Baseline']\n",
    "for name in ['PSO', 'ACO']:\n",
    "    print(f\"\\n{name} vs Baseline:\")\n",
    "    for metric, value in results[name].items():\n",
    "        improvement = value - baseline_metrics[metric]\n",
    "        improvement_pct = (improvement / baseline_metrics[metric]) * 100\n",
    "        print(f\"  {metric}: {improvement:.4f} absolute improvement ({improvement_pct:.2f}% relative improvement)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare GA-selected features for final model deployment\n",
    "\n",
    "Let's save the final optimized model and export the list of GA-selected features for future use. This ensures we can reproduce the exact same preprocessing pipeline when deploying the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model based on AUC is: ACO\n",
      "\n",
      "Final model saved as 'fraud_detection_best_model.cbm'\n",
      "GA-selected features saved to 'ga_selected_features.json'\n",
      "\n",
      "Created utility function 'predict_fraud()' for easy model deployment\n"
     ]
    }
   ],
   "source": [
    "# Determine the best model based on AUC score\n",
    "best_model_name = max(results, key=lambda x: results[x]['auc'])\n",
    "print(f\"The best model based on AUC is: {best_model_name}\")\n",
    "\n",
    "# Create a reference dictionary with GA feature indices and their names\n",
    "ga_feature_mapping = {\n",
    "    'indices': best_features,\n",
    "    'names': selected_feature_names\n",
    "}\n",
    "\n",
    "# Export the GA feature information\n",
    "import json\n",
    "with open('ga_selected_features.json', 'w') as f:\n",
    "    json.dump(ga_feature_mapping, f, indent=4)\n",
    "\n",
    "# Save the best model\n",
    "if best_model_name == 'PSO':\n",
    "    best_model = final_model_pso\n",
    "elif best_model_name == 'ACO':\n",
    "    best_model = final_model_aco\n",
    "else:\n",
    "    best_model = baseline_model_ga\n",
    "\n",
    "best_model.save_model('fraud_detection_best_model.cbm')\n",
    "\n",
    "print(f\"\\nFinal model saved as 'fraud_detection_best_model.cbm'\")\n",
    "print(f\"GA-selected features saved to 'ga_selected_features.json'\")\n",
    "\n",
    "# Function to preprocess and predict using the saved model\n",
    "def predict_fraud(new_data, feature_mapping_path='ga_selected_features.json', model_path='fraud_detection_best_model.cbm'):\n",
    "    \"\"\"\n",
    "    Predict fraud using the saved model and GA-selected features\n",
    "    \n",
    "    Args:\n",
    "        new_data: DataFrame with the same columns as the original training data\n",
    "        feature_mapping_path: Path to the saved GA feature mapping\n",
    "        model_path: Path to the saved model\n",
    "        \n",
    "    Returns:\n",
    "        Fraud predictions (1 for fraud, 0 for not fraud)\n",
    "    \"\"\"\n",
    "    # Load feature mapping\n",
    "    with open(feature_mapping_path, 'r') as f:\n",
    "        feature_mapping = json.load(f)\n",
    "    \n",
    "    feature_names = feature_mapping['names']\n",
    "    \n",
    "    # Select only the GA-selected features\n",
    "    if all(name in new_data.columns for name in feature_names):\n",
    "        X_new = new_data[feature_names]\n",
    "    else:\n",
    "        indices = feature_mapping['indices']\n",
    "        X_new = new_data.iloc[:, indices]\n",
    "    \n",
    "    # Load model and predict\n",
    "    model = CatBoostClassifier()\n",
    "    model.load_model(model_path)\n",
    "    \n",
    "    return model.predict(X_new)\n",
    "\n",
    "print(\"\\nCreated utility function 'predict_fraud()' for easy model deployment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
